{"./":{"url":"./","title":"Introduction","keywords":"","body":"数据结构和算法、数据库、其他 推荐书籍的博客 怎样花两年时间去面试一个人 - 刘未鹏 书籍推荐 - 四火的唠叨 读书推荐 - 博主16年毕业 读书推荐 - 学习资源推荐 程序员可能必读书单推荐（一） 我的书单 - 潘建锋 推荐书籍 《Head First 设计模式》，豆瓣9.2，行文极其浅显易懂，例子有趣幽默 《编程之美》，豆瓣8.5，为什么常居畅销榜？因为它透露了雇主眼中明确清晰的需求 《程序员修炼之道》，豆瓣9.1 《重构》，豆瓣9.0 《七周七并发》，豆瓣7.5，书里介绍了七种并发编程的模型，能让我开阔眼界 《Clean Code》和《Clean Architecture》，豆瓣8.6 《设计数据密集型应用》，DDIA，豆瓣9.7，不仅仅讲数据库 《计算机程序的构造和解释》，SICP，豆瓣9.6，能更清晰地理解函数式编程 《深入理解LINUX网络技术内幕》，ULNI、豆瓣8.3，Go夜读-第68期网络知识十全大补丸 《Understanding the Linux Virtual Memory Manager》，ULVMM、豆瓣9.7 Linux内核开发进阶书籍推荐，LKD->ULK->LDD->ULNI->ULVMM "},"docs/common-algorithms.html":{"url":"docs/common-algorithms.html","title":"数据结构、数组排序、堆操作","keywords":"","body":"数据结构、数组排序、堆操作 资料 计算机科学常见算法复杂度 数据结构 数据排序 （为什么冒泡排序最优复杂度是O(n)） 堆操作 大O复杂度 "},"docs/data-structure-and-algorithm.html":{"url":"docs/data-structure-and-algorithm.html","title":"数据结构和算法之美","keywords":"","body":"数据结构与算法之美 资料 数据结构与算法之美 - 极客时间 常用的十个结构：数组、链表、栈、队列、散列表、二叉树、二叉堆、跳表、图、前缀树。 常用的十个算法：递归、排序、二分查找、哈希算法、图的搜索、字符串匹配、贪心算法、分治算法、回溯算法、动态规划。 算法复杂度： 最好情况 最坏情况 平均情况：例如有N种情况，则将N种情况的耗时相加再除以N 均摊时间：它的分析方法叫摊还分析，暂时不学。 数组、链表、栈、队列、散列表、二叉树、二叉堆、跳表 数组：支持随机访问，基于数组下标的访问是O(1)，插入和删除则需要搬迁内存 链表：单向链表、双向链表、循环链表。给单向链表增加一个fake头节点可以简化代码逻辑。 栈：可以用数组实现（需要支持动态扩容），也可以用链表实现（比数组更占内存）。 队列：同样可以用数组、链表实现 普通队列 双端队列 优先队列：优先级高的先出（可以用二叉堆实现） 散列表：解决哈希冲突的两个办法： 开放寻址法：当前位置i被占用，则检查i+1，i+1被占用，则检查i+2 链表法 散列表如何实现工业级，以java的HashMap举例： 初始容量为16 当元素个数超过当前容量的75%时，自动扩容成2倍大小（此时有新旧两个散列表，当数据全部迁移后删除旧表） 当链表长度 > 8，转成红黑树，当长度 二叉树： 满二叉树：叶子都是全的 完全二叉树：用数组存储节点的时候都是连续的，不需要用null来填空节点 二叉查找树(二叉排序树)：左边所有节点 二叉查找树的自平衡问题：树在一个分支上无限延长，导致搜索节点的复杂度退化成O(n) 自平衡的方式：红黑树、AVL树 散列表CURD是O(n)，平衡二叉查找树的CURD是O(log n)，为什么还会用二叉查找树？ 二叉查找树在O(n)时间内即可打印排序好的数据 散列表扩容缩容时性能不稳定 散列表的哈希冲突严重时，O(n)不一定快于二叉查找树的O(log n) 散列表的实现需要关注扩容、缩容、哈希算法、哈希冲突，而二叉查找树主要关注自平衡 红黑树是基于23树的，理解了23树就理解了红黑树 二叉堆：必须是完全二叉树，父节点必须>=或 插入节点O(log n)：新节点先插入小顶推最后一个位置，若 删除节点O(log n)：用小顶推最后一个位置的节点替换删除节点，若 > 子节点最小的那个则交换 构建小顶堆O(log n)：先构建成完全二叉树，从底层第一个非叶子节点开始，若 > 子节点最小的那个则交换 二叉堆的三个应用： 优先级队列：大顶堆，堆顶元素就是优先级最高的 求TopK：先建一个小顶堆，每次insert的时候和堆顶元素对比，小就忽略，大则加入 求50%位的值：一个小顶堆和一个大顶堆，每次insert的时候和小顶堆堆顶元素比较，小则insert，大则insert大顶堆 跳表：比红黑树的优秀的地方： find、insert、delete 两者都是O(log n)，但zrank、zrange跳表依然是O(log n) 跳表的代码比红黑树容易理解，好实现 递归、排序、二分查找、哈希算法、图的搜索 递归：斐波那契数列：F(n)=F(n-1)+F(n-2) 排序： O(n^2)：冒泡、插入、选择。其中选择排序最好最坏都是O(n^2)，且是不稳定排序。希尔排序是插入排序的优化版本。 O(n*log n)：归并、快排、堆排。其中归并的缺点是空间复杂度是O(n)，快排和堆排的缺点是非稳定排序。 堆排不如快排原因1：排序过程中快排对元素的访问是局部顺序访问的，而堆排是随机的 堆排不如快排原因2：相同的逆序度，快排元素交换的次数比堆排少（因为堆排建堆的时候破坏了有序度） O(n)：计数、桶、基数。 计数：元素必需是整数。若元素个数是n，最大值-最小值=m，最好是m 桶：元素可以是整数、小数，由于桶之间的等区间的，若第一个桶有n-1个元素，最后一个桶有1个元素，则时间复杂度是O(n*log n) 基数：元素必须是整数或者ASCII字符。需要基于计数排序。若元素位数较多，n比较小，性能反而不佳。vs快排 排序在c语言中的通用实现qsort：数据量小用归并；数据量大用快排，快排时区间元素 二分查找的局限性： 必须是顺序表结构，同时意味着需要连续内存 必须是有序数据 二分查找对比散列表和二叉树：其中二分查找和二叉树查找都是O(n) 二分查找的优点在于不需要额外存储，缺点是需要连续内存 二分查找不适合数据频繁更新的场景，而散列表和二叉树可以 二分查找适合近似查找，如查找大于K的第一个元素，散列表和二叉树就比较难实现了 哈希算法的6个常见应用： 安全加密 唯一标识：检查图片是否在现有图库中存在 数据校验：下载完后对比哈希值 散列函数 负载均衡：通过哈希值取模保证会话粘滞（session sticky） 数据分片：通过哈希值取模保证分片数据在指定的机器 一致性哈希算法：保证加入新的机器节点后，现有的映射关系不变 图的搜索： 深度优先遍历、广度优先遍历也称为暴力搜索算法，适合图不大的算法 A星寻路算法属于高级算法 图、前缀树 图的基本概念： 无向图：比如微信好友，i是j的好友，则j也是i的好友 有向图：比如微博粉丝，i是j的粉丝，但j不是i的粉丝 带权图：比如QQ的好友亲密度，i与j是好友，他们之间的亲密度是80% 图的存储方式： 邻接矩阵：数组A[i][j]=1表示i是j的粉丝，A[j][i]=0表示j不是i的粉丝 邻接表：数组+链表，要查i关注的所有人，先查数组A[i]，再遍历链表。若要查i的所有粉丝，则再建一个逆邻接表。邻接表也能表示带权图。 图的遍历（顶点个数是n，边数是e）： 深度优先遍历（Depth First Search）：空间复杂度O(n)，时间复杂度O(e) 广度优先遍历（Breadth First Search）：空间复杂度O(n)，时间复杂度O(e) 图中两点之间的最短路径： Dijkstra单源最短路径算法：单源的意思是仅求两点之间的距离，时间复杂度O(n^2)，空间复杂度O(n) Floyd多源最短路径算法：多源的意思是求出所有点之间的距离，时间复杂度是O(n^3)，空间复杂度O(n^2)，因为它用的邻接矩阵 前缀树：属于多叉树，同一节点下的子节点按顺序排列（加快查找） 前缀树不如散列表的地方1：字符串的字符集不能太大，否则空间消耗大、查询慢 前缀树不如散列表的地方2：字符串的前缀重合比较多，否则空间消耗大 前缀树不如散列表的地方3：因为业务场景不同，没有通用的实现库，需要自己实现前缀树 前缀树不如散列表的地方4：使用了指针，内存不连续，对缓存不友好 前缀树的优点：查询前缀匹配的所有集合 字符串匹配、贪心算法、分治算法、回溯算法、动态规划 字符串匹配（主串长度m，模式串长度n） BF算法（Brute Force）：从主串位置0开始匹配，失败在从位置1开始匹配。最坏复杂度O(mn) RK算法：基于BF，只不过每次匹配的时候是匹配的哈希值。最坏复杂度O(m+n) KMP算法：从主串位置0开始匹配，失败则根据模式串的特点跳过k个位置开始匹配。最坏复杂度O(m+n)，空间复杂度O(n) 贪心算法：例如找零问题，有1元、10元、100元的纸币，张数分别是c1、c10、c100，支付K元最少要用多少纸币？ 分治思想的案例： 快速排序算法 合并排序算法 桶排序算法 基数排序算法 二分查找算法 利用递归树求解算法复杂度 分布式数据库的分片技术 回溯算法：深度优先搜索算法利用的是回溯算法思想 动态规划的例子1：求斐波那契的第n个元素 方法1是递归：F(n) = F(n - 1) + F(n - 2) 方法2是动态规划：for (i=2; i 动态规划的例子2：金矿n=5、工人w=10（400金需5人；500金需5人；200金需3人；300金需4人；350金需3人） 方法1是递归：F(n,w) = MAX(F(n-1,w), F(n-1,w-第n个金矿所需人数)+第n个金矿的黄金) 方法2是动态规划：在表格中依次算出1个金矿10个工人的结果，2个金矿10个工人的结果…… 动态规划的例子3：物品n=5，背包承重w=9，物品依次重2，2，4，6，3 方法1是递归：F(n,w) = MAX(F(n-1,w), F(n-1,w-items[n-1])+items[n-1]) 方法2是动态规划：在表格中依次算出1个物品承重9的结果，2个物品承重9的结果…… 高级篇 位图：一千万个int32，存储需要40MB 使用位图，数据范围是0~1亿，则需12MB 使用位图，数据范围是0~10亿，则需120MB 布隆过滤器：解决位图存储稀疏数据的问题 insert时使用K个哈希函数，把位图K个位置置1 search时使用K个哈希函数，查找对应位置是否为1 朴素贝叶斯算法： 先算p1=W1~Wn同时出现且短信是垃圾短信的概率 * 垃圾短信的百分比 再算p2=W1~Wn同时出现且短信是非垃圾短信的概率 * 非垃圾短信的百分比 如果p1是p2的很多倍（比如10倍），我们才确信这条短信是垃圾短信 （Wn出现在短信中且短信是垃圾短信的概率，假设垃圾短信有y个，包含Wn的有x个，那么概率就是x/y） 向量空间(欧几里得距离)：音乐推荐算法 以用户为单位：向量是(歌曲1、歌曲2、……、歌曲n)，距离越近表示两用户口味相近 以歌曲为单位：向量是(用户1、用户2、……、用户m)，距离越近表示歌曲的用户群相近，也即歌曲类别相近 B树：每个节点的子节点个数不能小于 m/2 的 m叉树，每个节点都存储数据。 B+树：只有叶子节点存储数据，且用双向链表连接。只有单链表为什么不行？ 插入节点会变复杂 select id from t order by id asc 遍历单链表即可，desc则还需要一次内存倒排。 构建索引常用的数据结构 散列表：增删改查时间复杂度是O(1)，适合做内存KV数据库 红黑树：增删改查时间复杂度是O(logn)，Ext文件系统，对磁盘块的索引就是红黑树 B+树：适合构建在磁盘上的索引，树的高度低于红黑树，可以减少磁盘IO的次数 跳表：Redis的有序集合 位图和布隆过滤器：可以作为辅助索引存储在内存，加速数据查找的效率 并行算法： 并行排序：归并是先分好16个区对应16个线程，最后主线程合并结果。快排是主线程先排好16个区对应16个线程，线程结束后即可。 并行查找：将散列表分成16个，针对性的扩容缩容，查找时并发16个线程查找 并行字符串匹配：将主串切成16个，并发16个线程匹配 实战篇 redis的常用数据结构： sds相比char的优点有：阅读redis代码（一）—— SDS数据结构 获取字符长度的复杂度是O(1) 提供API可以安全的处理字符串 修改N次字符串最多需要N次内存分配 可以保存任何二进制数据，char类型遇到0x00就会终止 ziplist、listpack相当于一个双向链表，内存连续，且比定长数组更节约内存，压缩列表 - Redis 设计与实现 ziplist包含头信息(11B)、entry数组[每个entry包含prevlen(1B~5B)、encoding+length(1B~5B)、content] ziplist的增删改查都是O(n)，缺点是会出现级联更新（例如某entry的长度从254，则nextEntry的prevlen的内存空间也会改变） listpack包含头信息(7B)，entry数据[每个entry包含encoding(1B~5B)、content、length(1B~5B)]，Redis 数据结构的设计与实现 qucklist是一个双向链表，节点是ziplist（每个ziplist不能超过8K） skiplist是zset的基础数据结构，成员对象是sds，成员分值是long dict是hash的基础数据结构，有2个ht，扩容时会用到ht[1] dict渐进式rehash： rehash时查询操作同时查2个ht，ht[0]数据都搬移道ht[1]后，ht[0]=ht[1]，ht[1]=null 每次增删改查操作时，迁移一部分数据，定时任务每次迁移一部分数据 zipmap是内存连续的键值对 结构：\"foo\"\"bar\"\"hello\"\"world\" 实例：\\x02\\x03foo\\x03\\x00bar\\x05hello\\x05\\x00world\\xff 虽然查询效率是O(n)，但是在数据量小的时候效率并不差且节约内存 intset是set的结构之一，当set元素都是整型且不超过512个就用intset intset用于有序、无重复地保存多个整数值，因为可以二分查找所以效率是O(log n) Hash，单值长度>64或者元素数量>512，用【dict】，否则用【ziplist】。ziplist的entry数组是k1、v1、k2、v2、…… List，单值长度>64或者元素数量>512，用【linkedlist】或【quicklist】，否则用【ziplist】。quicklist需要版本>=3.2。 Zset，单值长度>64或者元素数量>128，用【skiplist】，否则用【ziplist】。ziplist的entry数组是member1、score1、…… Set，元素都是整型或者元素数量 Disruptor 是java的一个并发编程框架，一个高效的并发内存消息队列 普通的循环队列，为了线程安全，在push和pop的时候需要加锁。 Disruptor循环队列，每个生产者(线程)预先申请N个元素空间，然后可以无锁写，因而速度快。消费者同理。 微服务的鉴权、限流： 鉴权之精准匹配：散列表，时间复杂度O(1) 鉴权之前缀匹配：前缀树，时间复杂度O(log n) 鉴权之模糊匹配：数组+回溯算法 限流之固定时间窗口：变量1存时间，变量2存请求量 限流之滑动时间窗口：假设限流1分钟100次，建N=101的循环队列，每次有新请求，先删除超过1分钟的元素，再检查能否push 短网址之ID生成器： 母发号器+N个子发号器，母发号器只批量发号给子发号器，客户端从子发号器取ID N个发号器，例如0号发号器只发尾号为0的，1号发号器只发尾号为1的…… "},"docs/sword-finger-offer.html":{"url":"docs/sword-finger-offer.html","title":"剑指Offer","keywords":"","body":"剑指Offer 资料 "},"docs/redis5-source.html":{"url":"docs/redis5-source.html","title":"Redis 5设计与源码分析","keywords":"","body":"Redis 5设计与源码分析（我分析的源码是redis 2.9） 第9章 命令处理周期 一个数据库有16个redisDb redisDb的key只能是字符串，value是robj(redisObject)结构体 robj的type、encode对应的map定义在redis.h的182行 客户端结构体redisClient 服务的结构体redisServer redisServer.commands由populateCommandTable方法初始化（把redisCommandTable数组变成dict） 程序运行流程之server初始化： initServerConfig：初始化配置 loadServerConfig：加载并解析配置文件 initServer：初始化服务端内部变量（支持的客户端数量4064） aeCreateEventLoop：创建事件循环eventLoop（每个客户端一个aeFileEvent、一个aeFiredEvent） aeFileEvent：文件事件 aeFiredEvent：已就绪的文件事件 其中aeApiCreate()调用epoll_create创建了epoll 程序运行流程之启动监听： listenToPort：创建socket并启动监听（IO多路复用模式，socket读写必须是非阻塞的） aeCreateFileEvent：创建文件事件（即socket事件），处理函数是acceptTcpHandler aeCreateTimeEvent：创建时间事件（全局只有1个），处理函数是serverCron aeMain：开启事件循环，死循环执行aeProcessEvents()，它的功能如下： 调用epoll_wait阻塞等待文件事件的方式（设有超时） epoll_wait返回时，先处理触发的文件事件，再处理时间事件 aeCreateFileEvent的文件事件是监听新连接，acceptTcpHandler调用createClient生成新的文件事件 新的文件事件处理函数是readQueryFromClient 程序运行流程之命令处理过程： processInputBuffer：命令解析，解析结果放在redisClient的argc、argv processCommand： 如果是quit命令直接addReply并关闭客户端 如果lookupCommand找不到命令则addReplyErrorFormat，否则赋值redisClient的cmd 如果命令参数不合法则addReplyErrorFormat 如果需要auth认证单认证没有通过则addReply 如果maxmemory目录设置的内存超过限制则addReply 其他。。。 返回结果： 状态回复：addReply 错误回复：addReplyErrorFormat 整数回复：addReply 批量回复：多次addReplyMultiBulkLen和addReply 发送到客户端： 先写到输出缓冲区c->buf：_addReplyToBuffer() 如果不为空则写入输出链表c->reply： _addReplyObjectToList _addReplySdsToList _addReplyStringToList 把客户端加入到redisServer->clients_pending_write aeMain中的beforeSleep遍历clients_pending_write，并执行writeToClient 如果writeToClient一次性没有发送完，则创建可写事件 当可写事件触发后继续发送 typedef struct redisDb { int id; // 数据库号码，一般是0~15 dict *dict; // 数据库键空间，保存着数据库中的所有键值对 dict *expires; // 键的过期时间，字典的键为键，字典的值为过期事件 UNIX 时间戳 dict *blocking_keys; /* Keys with clients waiting for data (BLPOP) */ dict *ready_keys; /* 可以解除阻塞的键，Blocked keys that received a PUSH */ dict *watched_keys; // 正在被 WATCH 命令监视的键 long long avg_ttl; // 数据库的键的平均 TTL ，统计信息 } redisDb; typedef struct redisObject { unsigned type:4; // 类型：0字符串 1list 2set 3zset 4hash unsigned encoding:4; // 编码：0sds 1int 2dict 4linkedList 5ziplist 6intset 7skiplist 8sds unsigned lru:24; // 对象最后一次被访问的时间 int refcount; // 引用计数 void *ptr; // 指向实际值的指针 } robj; typedef struct redisClient { int fd; // 套接字描述符 redisDb *db; // 当前正在使用的数据库 robj *name; // 客户端的名字，set by CLIENT SETNAME time_t lastinteraction;// 最后依次交互的时间，据此判断超时 sds querybuf; // 查询缓冲区 size_t querybuf_peak; // 查询缓冲区长度峰值，Recent (100ms or more) peak of querybuf size struct redisCommand *cmd, *lastcmd; // 记录被客户端执行的命令 int argc; // 参数数量 robj **argv; // 参数对象数组 list *reply; // 回复链表 unsigned long reply_bytes; // 回复链表中对象的总大小 int sentlen; // 已发送字节，处理 short write 用 int bufpos; // 回复偏移量 char buf[16*1024]; // 回复缓冲区 } redisClient; struct redisServer { char *configfile; // 配置文件的绝对路径 int hz; // serverCron() 每秒调用的次数 redisDb *db; // 数据库 dict *commands; // 命令表（受到 rename 配置选项的作用） aeEventLoop *el; // 事件状态 int port; /* TCP listening port */ int tcp_backlog; /* TCP listen() backlog */ char *bindaddr[16]; /* Addresses we should bind to */ int bindaddr_count; /* Number of addresses in server.bindaddr[] */ int ipfd[16]; /* TCP socket file descriptors */ int ipfd_count; /* Used slots in ipfd[] */ list *clients; /* List of active clients */ list *clients_to_close; /* Clients to close asynchronously */ int maxidletime; /* 客户端最大空转时间，Client timeout in seconds */ }; 第10章 键的相关命令 读取redisDb的dict字典的命令： object refcount {key} object encoding {key} type {key} 读取redisDb的expires字典的命令： ttl {key} expire {key} {seconds} object encoding {key}的执行流程： readQueryFromClient processCommand会调用lookupCommand赋值c->cmd，并执行call(c) call(c)会执行c->cmd->proc，即实际的处理函数objectCommand objectCommand调用objectCommandLookupOrReply获取key对应的robj 根据robj->encoding字段返回描述 第11章 字符串的相关命令 c->cmd->proc对应的是setCommand（set命令） b processCommand set a 100 打印请求的三个参数：p c->argv[0]、p c->argv[1]、p *c->argv[0] 此时的100是字符串：p (char *)c->argv[2]->ptr b tryObjectEncoding 此时的100是字符串，tryObjectEncoding之后变成int，p *c->argv[2]的结果如下： {type = 0, encoding = 1, lru = 8272013, refcount = 2, ptr = 0x64} set a 10001然后重新debug一遍，p *c->argv[2]的结果如下： {type = 0, encoding = 1, lru = 8273125, refcount = 1, ptr = 0x2711} 说明10000以内的整数的robj是redis已经预分配好的，每次使用refcount++，10000以上的则把ptr指针当值用 第12章 散列表hash的相关命令 c->cmd->proc对应的是hsetCommand（hset命令） hset a key val hsetCommand()默认robj->ptr是ziplist，hashTypeTryConversion()判断是否转换成dict 然后调用hashTypeSet()设置key和val hashTypeSet()函数内部会判断robj->encoding以执行不同的逻辑 hashTypeXXX()函数和hashTypeSet()类似 第13章 列表list的相关命令 c->cmd->proc对应的是lpushCommand（lpush命令） 实现栈：lpush、lpop 实现队列：lpush、rpop lpush：lpushCommand()默认robj->ptr是ziplist，listTypeTryConversion()判断是否转换成linkedList bpop的实现流程： bpop {key} {timeout}。timeout=0表示无限期的阻塞 执行bpop后，设置c->bpop->timeout和c->bpop->keys，设置redisDb->blocking_keys，并阻塞 解除情况1：其他客户端执行了push命令，检测key在redisDb->blocking_keys内，找到对应的客户端，执行unblockingClient 解除情况2：serverCron定时遍历所有的客户端，检查c->bpop->timeout，发现超时则执行unblockingClient 第14章 无序集合set的相关命令 c->cmd->proc对应的是saddCommand（sadd命令） hsetCommand()判断元素的类型是否是整型，是则用intset、否则用dict typedef struct intset { uint32_t encoding; // 有三种：INTSET_ENC_INT16、INTSET_ENC_INT32、INTSET_ENC_INT64，支持升级、不支持降级 uint32_t length; // 元素个数 int8_t contents[]; // 一个单位占一个字节，根据encoding类型占用不同单元 } 第15章 有序集合zset的相关命令 zset的robj有两种类型：ziplist和zset 使用ziplist：元素按照score大小顺序存储，先存元素，再存score 使用zset：dict和skiplist的结合，为什么有序集合需要同时使用跳跃表和字典来实现？ 仅使用dict，单个元素的增删改是O(1)，但是ZRANK、ZRANGE需要O(N * logN) 仅使用skiplist，单个元素的增删改是O(logN)，ZRANK、ZRANGE需要O(logN) dict和skiplist的结合：zs->dict->ht[0].table[2]->key就是元素robj，zs->zsl下的节点zskiplistNode->robj就是元素robj 使用zset：用zadd更新同一个元素的score的流程： 从zs->dict查找元素是否存在，O(1) 在zs->zsl中先zslDelete，再zslInsert。（继续用元素robj，内存块不变），O(logN) 更新zs->dict中对应元素的分值指针，O(1) typedef struct zskiplistNode { robj *obj; // 成员对象 double score; // 分值 struct zskiplistNode *backward; // 后退指针 struct zskiplistLevel { struct zskiplistNode *forward; // 前进指针 unsigned int span; // 跨度 } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; // 表头节点和表尾节点 unsigned long length; // 表中节点的数量 int level; // 表中层数最大的节点的层数 } zskiplist; typedef struct zset { dict *dict; // 键为成员，值为分值 zskiplist *zsl; // 跳跃表，按分值排序成员 } zset; 第16章 GEO的相关命令 先把经纬度geohash，再geohash-int转成long long类型，再用zset结构存储 例如geoadd beijing 116.312 40.058 xierqi beijing是键名 xierqi是zset的元素 坐标geohash-int后的值是score 第17章 HyperLogLog 第18章 Stream 第19章 其他命令 事务 multi：开启事务 discard：放弃事务 exec：提交事务 watch：监听指定的key，如果key发生变化则事务不执行（相当于乐观锁） unwatch：取消监听 发布-订阅 subscribe {channelName}：订阅频道 publish {channelName} {message}：向频道发送消息 Lua脚本 eval \"Lua代码\" 事务和Lua脚本都可以实现原子性 第20章 持久化-RDB快照和AOF日志 RDB快照的触发方式 bgsave命令 save 60 1000：60秒内如果有1000个key发生变化则触发 RDB快照的文件结构，共九项： 固定为“REDIS”，5B RDB的版本号，4B 辅助字段对，如redis-server版本号 DB_NUM，一般是0~15 DB_DICT_SIZE，db_dict的哈希表大小，这样还原时可以直接扩容到此大小 EXPIRE_DICT_SIZE，expire_dict的哈希表大小，这样还原时可以直接扩容到此大小 KEY_VALUE_PAIRS，键值对内容 EOF结束标志，1B CHECK_SUM，8B AOF日志的写入模式 appendfsync=no，write后不强制fsync，由操作系统负责刷盘 appendfsync=always，每次write后都执行fsync appendfsync=everysec，每秒执行一次fsync AOF日志重写的触发方式 bgrewriteaof 配置自动重写规则，如aof文件大小比当前增长了100%时触发 AOF日志重写的两种方式 设置重写时间点，遍历时间点之前的数据生成aof命令日志，拼接上时间点之后产生的aof日志 设置重写时间点，遍历时间点之前的数据生成RDB快照，拼接上时间点之后产生的aof日志（即混合持久化） 第21章 主从复制 psync2协议解决了主服务器M宕机，从服务器A变为主服务器，从服务器B、C仍然可以从A这里进行“部分重同步” 从服务器的流程： 接收到slaveof命令后连接socket 发送ping包确保连接正常 发起密码验证（如果需要） 发送replconf命令同步信息 发送psync命令 接收RDB文件并载入 等待主服务器的同步命令请求 主服务器的流程： 监听并接收socket 回复ping包 回复密码验证 处理replconf命令： 从服务器的监听端口和IP（端口一般是6379） eof标识：从服务器支持无盘复制 psync2标识：从服务器支持psync2协议 从服务器的复制偏移量 处理psync命令： 如果可以部分重同步，发送+CONTINUE和后续命令 如果需要完全重同步，则先执行RDB快照。然后进行无盘复制或者先写硬盘，再发送 发送RDB文件 每次收到写命令，广播给从服务器 wireshark抓包：https://ryan4yin.space/posts/tcpdump-and-wireshark/ Kubernetes抓包：推荐直接使用 ksniff ssh root@localhost \"tcpdump -i lo -l -w -\" | wireshark -k -i - 第22章 哨兵和集群 哨兵的配置： 只需要配置Master节点，保证配置文件可写 与Master节点建立连接后，收集Slaves和其他哨兵的信息，并写入配置文件作持久化 哨兵的运行流程： 启动监听，默认端口是26379 建立命令连接、消息连接 命令连接： 定时10s：发送info命令收集Slaves的信息 定时1s：发送ping命令探测存活性 定时2s：publish消息给其他哨兵（选举用） 消息连接： 哨兵订阅Master和Slaves的消息，获知其他哨兵的信息 PS：哨兵针对Master和Slaves会建立命令连接和消息连接，针对其他哨兵只建立命令连接 哨兵确认节点下线： 主观下线：针对Master和Slaves，还有其他哨兵 主观下线：只针对Master 哨兵处理主从切换： 选出主哨兵 选择一台Slave作为主节点： 不能是主观下线状态 5s内没有回复ping，不能选 slave-priority=0，不能选 if 优先级高，选中 else if 复制的偏移量大，选中 else if runid最小，选中 集群的典型例子：三主三从 redis把键空间分成了16384个slot 主从节点都有这16384个slot的信息（slot对应的节点ip和port） 如果客户端请求节点，对应的键正好在该节点则直接服务，不在则返回MOVED slot IP:PORT 事实上客户端可以获取16384个slot信息并缓存 从节点默认不提供服务，只作为备份节点，若要提供读服务则要注意2点： 客户端先执行readonly 若键对应的节点是某主节点，则可以直接向它的从节点发起读请求 集群的主从切换：支持手动和自动 集群的副本漂移：例如三主四从，A节点挂了发生主从切换，A处没有从节点了，可以从其他地方挪一个过来 "},"docs/redis-in-depth.html":{"url":"docs/redis-in-depth.html","title":"Redis 深度历险","keywords":"","body":"Redis 深度历险 第1篇 基础和应用篇 5种基础的数据类型：string、list、hash、set、zset 分布式锁： 加锁的原子操作（设置key、设置过期时间） 释放锁的原子操作（匹配value、判断是否删除） 缺点1：T1执行时间超过了锁的过期时间，T2加锁成功并执行 缺点2：主节点刚加锁key还没有同步到从节点就挂了，并发生主从切换，此时T2加锁成功 延迟队列和位图 HyperLogLog的原理： N个随机整数、低位连续0的最大长度K：N = 2 ^ K 假设只有一个桶来存储，可能因为个别离群值导致误差 假设预置1024个桶，把N个整数分散到这1024个桶，最后对1024个桶求和，可以减少误差 redis的HyperLogLog有16384个桶，每个桶用6b存储K值，占用内存：16384 * 6 / 8 = 12K BloomFilter： 一个元素的指纹空间如果占8b，错误率约2%，最佳hash数量是8 * 0.7 一个元素的指纹空间如果占15b，错误率约0.1%，最佳hash数量是15 * 0.7 使用时先预置好内存（最大数据容量已确定），若后续数据量超过最大容量，则需要重建BloomFilter Redis-Cell：限流模块 GeoHash：地理位置 scan：分页扫描时，采用“高位进位加法”，保证了不受扩容缩容的影响而导致漏了key（但可能会重复） 第2篇 原理篇 线程IO模型：多路复用I/O模型Linux使用epoll、Unix使用kqueue 客户端管道：echo -e \"PING\\r\\nPING\\r\\nPING\\r\\n\"|nc localhost 6379 redis事务：redis禁止在multi和exec之间执行watch，必须在multi之前执行watch 订阅：subscribe阻塞循环读，读其他线程publish的消息 小对象压缩：ziplist和intset 第3篇 集群篇 主从模式下的wait {nums} {seconds}：一直阻塞直到nums个从节点同步到最新状态，最多等待seconds 哨兵：客户端连接哨兵节点获取master的地址和slaves的地址 codis的优点：分布式的问题借用的是zookeeper/etcd，因此代码简单 第4篇 扩展篇 stream不借用消费组： xread读取{nums}条消息，阻塞{seconds}，可以指定从某个消息id后读取 stream借用消费组： xgroup create {streamName} {groupName} xreadgroup {groupName} {consumerName} xack {streamName} {groupName} {messageID}，这里没有指定consumerName，默认是之前指定的consumerName 分布式锁redlock： 大多数机制：向多个节点加锁，大多数加锁成功则为成功 需考虑错误重试、时钟漂移 懒惰删除：异步线程删除 unlink：删除大key flushdb async AOF sync 第5篇 源码篇 SDS有两种类型： embeded：容量固定是44个字符串，因为jemalloc默认分配的大小是64B，robj(占19B)和embeded的SDS是内存连续的 raw：容量大于44个字符串 DICT的渐进式reahsh：访问的时候搬迁，定时任务搬迁 内存紧凑型： ziplist：prevlen可以是1B或5B，encoding可以是1B、2B、5B intset：length和encoding都是4B 快表：ziplist+双向链表，压缩深度如果是1，则首尾的ziplist不压缩，其他都压缩 跳表：zadd命令如果key已经存在，先删除再插入 listpack：{encoding, content, length}，注意计算整型值的时候是小端尾序 encoding已经包含了content的长度 length表示的是content+encoding的长度，使用varint编码 lru和lfu： lru：lru字段(3B)存储最后一次访问的秒时间戳，大约194天折返 lfu：lru字段分为lastDecrementTime(2B)和logisticCounter(1B) lastDecrementTime存储分时间戳，大约45天折返，只在检查淘汰的时候更新（并衰减logisticCounter） logisticCounter存储访问频次的对数值，每次访问key的时候更新 "},"docs/mysql-how-it-works.html":{"url":"docs/mysql-how-it-works.html","title":"MySQL 是怎样运行的","keywords":"","body":"MySQL 是怎样运行的 redo、undo、binlog 操作 redo undo Tx1 write(x, 1) x=1 x=0 Tx1 write(x, 2) x=2 x=1 Tx1 commit commit commit 1.如果只有undo日志，则是undo -> data落盘 -> commit标记 假如commit标记前，data没有落盘，此时宕机，data数据丢失 假如data落盘后，commit还没有标记就宕机，undo日志回滚此事务 因为要求必须在commit标记前让data落盘，所以性能很差 2.如果只有redo日志，则是redo -> commit标记 -> data落盘 假如commit标记后，data没有落盘，此时宕机，redo日志重放恢复 假如commit还没有标记，data就落盘了，此时宕机data中会存在事务未提交的数据 因为要求必须在commit标记后data才能落盘： 问题1，同一个page只要有一个事务还未提交，则不能落盘，需要大量内存维持这种场景 问题2，假设需要update大表的全部记录，此时产生大量的脏页且不能落盘 3.undo+redo：undo+redo -> commit标记 data可以随心所欲的落盘 undo在commit标记后，还不能删除，因为undo还充当mvcc的历史版本，但是可以删除ReadView链最小事务之后的undo 表空间 表空间：1个表对应1个表空间 段：好比一个师，1个索引有2个段（叶子节点段、非叶子节点段），开始表只有2个段，每加1个索引增加2个段，对应的描述是INODE Entry 区：好比一个团，1个区有64个物理连续的页，1MB，对应的描述是XDES Entry 碎片区：好比一个独立团，处于FREE、FREE_FRAG、FULL_FRAG状态的区直属于表空间 注意点1：如果给每个新表都分配一个区(1MB)太浪费，所以开始的数据页先放在公共的碎片区，当表有32个数据页后，开始分配一个区 注意点2：表空间默认只有1个INODE类型的页(最多85个INODE Entry)，不够可以新建，并由SEG_INODES_FULL链表、SEG_INODES_FREE链表维护 注意点3：每个段需要维护3个链表，它们的基节点信息在INODE Entry，每个表空间也维护3个链表，它们的基节点信息在File Space Header 独立表空间extent0前3页是固定的 FSP_HDR：存储256个XDES Entry和File Space Header IBUF_BITMAP：Change Buffer INODE：存储INODE Entry List 独立表空间extent0第0页的File Space Header 表空间的ID FREE链表的基节点 FREE_FRAG链表的基节点 FULL_FRAG链表的基节点 Next Unused Segment ID：表空间创建新的段时取值并自增 独立表空间extent256、extent512...前2页是固定的 XDES：存储256个XDES Entry IBUF_BITMAP：Change Buffer 系统表空间extent0前8页是固定的 FSP_HDR IBUF_BITMAP INODE Insert Buffer Header 存储Insert Buffer的头部信息 Insert Buffer Root 存储Insert Buffer的根页面 Transaction System 事务系统的相关信息 First Rollback Segment 第一个回滚段的页面 Data Dictionary Header 数据字典头部信息 系统表空间extent0的Data Dictionary Header页 Max Row ID：隐式row_id列的ID，所有库所有表共享。 Max Table ID：表的ID，所有库所有表共享。 Max Index ID：索引的ID，所有库所有表共享。 Max Space ID：表空间的ID，所有库所有表共享。 Root of SYS_TABLES clust index：本字段代表SYS_TABLES表聚簇索引的根页面的页号。 Root of SYS_TABLE_IDS sec index：本字段代表SYS_TABLES表为ID列建立的二级索引的根页面的页号。 Root of SYS_COLUMNS clust index：本字段代表SYS_COLUMNS表聚簇索引的根页面的页号。 Root of SYS_INDEXES clust index本字段代表SYS_INDEXES表聚簇索引的根页面的页号。 Root of SYS_FIELDS clust index：本字段代表SYS_FIELDS表聚簇索引的根页面的页号。 第11章 两表连接 内连接：from t1, t2 或 from t1 inner join t2。where 条件会过滤记录 左连接：from t1 left join t2 ON ... WHERE ...。where 条件会过滤记录，ON 条件不符合的记录仍然展示。 右连接：from t1 left join t2 ON ... WHERE ...。where 条件会过滤记录，ON 条件不符合的记录仍然展示。 驱动表查到的结果集先放到Join Buffer内(默认256K)，然后再到被驱动表查询 第12章 执行计划的成本计算 成本计算依赖的数据： 读取1个页面的成本是1 读取1条记录并检测是否满足条件的成本是0.2 table信息：Rows表示记录数，Data_length表示聚簇索引占用的字节 index信息：Cardinality表示不重复的记录数 IN查询估算记录数： eq_range_index_dive_limit限制内：使用index dive，基于索引来计算 eq_range_index_dive_limit限制外：使用index信息，IN查询的每个元素对应的记录数 = Rows / Cardinality 步骤1：找出所有可能使用的索引 步骤2：计算全表扫描的代价 I/O成本：Data_length / 16KB * 1 CPU成本：Rows * 0.2 步骤3：计算使用索引uk_key2的代价 访问二级索引I/O成本：因为只有一个扫描区间，所以是1 访问二级索引CPU成本：根据扫描区间的边界估算出记录数=95，所以是95 * 0.2 访问聚簇索引I/O成本：每次回表都算读取1个页面，所以是95 * 1 访问聚簇索引CPU成本：95 * 0.2 步骤4：计算使用索引idx_key1的代价 访问二级索引I/O成本：因为有三个单点区间，所以是3 访问二级索引CPU成本：估算出记录数=118，所以是118 * 0.2 访问聚簇索引I/O成本：118 * 1 访问聚簇索引CPU成本：118 * 0.2 步骤5：选出代价最低的方案 第13章 InnoDB的统计数据 mysql.innodb_table_stats：n_rows总记录数、cluster_index_size聚簇索引页面数、sum_of_other_index_sizes其他索引页面数 统计碎片区的页面数：INODE Entry存储有对应的页号 统计叶子节点段和非叶子节点段的页面数：INODE Entry存储有FREE、NOT_FULL、FULL链表的基节点，据此计算页面数 mysql.innodb_index_stats：size索引页面数、n_leaf_pages叶子节点页面数、n_diff_pfxxx不重复的记录数 统计数据如何更新：开启了自动更新后，数据每增长10%就算一次，根据配置的采样数采样统计 统计数据可以保存在内存或者磁盘，新版本都是在磁盘 innodb_stats_method配置：计算不重复的记录数时，每个null值都是重复值、每个null值都不同、忽略null值 第14章 子查询优化 子查询一般会出现在3个位置： select子句：select (select m2 from t2 limit 1) from子句：from (select m2 from t2) as tt on/where子句 子查询按照返回的结果分类： 标量子查询：where m1 = (select m2 from t2 limit 1) 行子查询：where (m1, n1) = (select m2, n2 from t2 limit 1) 列子查询：where m1 in (select m2 from t2) 表子查询：where (m1, n1) = (select m2, n2 from t2) 子查询按照与外层查询的关系分类： 不相关子查询：不依赖外层查询的值，上述SQL都是 相关子查询：where t1.m1 in (select t2.m2 from t2 where t2.n2 = t1.n1) 能转换成半连接的IN查询的条件： 不能是NOT IN 外层查询的其他搜索条件必须是AND，不能是OR 子查询必须是单一的查询，不能是由UNION连接起来的查询 子查询不能包含GROUP BY、HAVING语句或者聚集函数如MAX/MIN/COUNT/AVG/SUM IN查询的查询策略： 能转换成半连接的IN查询则按半连接的5种查询策略估算成本 能转换成EXISTS查询则先转换，转换成EXISTS也许能用到索引： 原始的：where key1 in (select key3 from s2 where common_field='a') or key2 > 1 转换后：where exists (select 1 from s2 where s2.common_field='a' and s2.key3=s1.key1) or key2 > 1 转换后的子查询，可以用到s2.key3的索引 都不能，则先把子查询变成物化表，再进行连接查询 子查询是不相关子查询：物化后子查询只执行一遍 子查询是相关子查询：物化后子查询可能执行多遍 IN查询原始SQL：select * from s1 where xxx in (select key1 from s2 where s2.xxx) IN查询半连接：select s1.* from s1 JOIN s2 ON s1.xxx = s2.key1 where s2.xxx IN查询半连接的5种查询策略，估算并选择成本最低的策略执行查询： Table Pollout：上述转换成半连接的SQL，如果s2.key1是主键或者唯一索引，则按内连接来查询即可 Duplicate Weedout：如果s2.key1不是主键或者唯一索引，在回表之前，还需要对主键记录去重 LooseScan：s2是驱动表并且s2正好用到了key1这个普通索引，可以在索引上跳过重复的key1值，再去被驱动表查询 Semi-join Materialization：先把子查询变成物化表，再进行连接查询 FirstMatch：对于关联子查询，依次取外层查询的一条记录，到子查询里FirstMatch，匹配到则放入结果集 第15章 EXPLAIN详解 CREATE TABLE single_table ( id INT NOT NULL AUTO_INCREMENT, key1 VARCHAR(100), key2 INT, key3 VARCHAR(100), key_part1 VARCHAR(100), key_part2 VARCHAR(100), key_part3 VARCHAR(100), common_field VARCHAR(100), PRIMARY KEY (id), KEY idx_key1 (key1), UNIQUE KEY idx_key2 (key2), KEY idx_key3 (key3), KEY idx_key_part(key_part1, key_part2, key_part3) ) Engine=InnoDB CHARSET=utf8; create table s1 like single_table; create table s2 like single_table; DELIMITER // create procedure insert_table(in max int(10)) begin declare i int default 0; repeat set i=i+1; insert into s1 values(NULL,i%100,i,i%10,i,MD5(i),RAND(),i); insert into s2 values(NULL,i%100,i,i%10,i,MD5(i),RAND(),i); insert into single_table values(NULL,i%100,i,i%10,i,MD5(i),RAND(),i); until i=max end repeat; end // call insert_table(5000); 1. select_type: * SIMPLE: EXPLAIN SELECT * FROM s1 INNER JOIN s2; // 不包含union或者子查询 * PRIMARY: EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2; // 包含union，最左边的table * UNION: EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2; // 包含union，除了最左边的table，其他都是UNION * UNION RESULT: EXPLAIN SELECT * FROM s1 UNION SELECT * FROM s2; // 使用了临时表来完成去重 * SUBQUERY: EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = 'a'; // 子查询不能转成半连接&&决定采用子查询物化的方案 * DEPENDENT SUBQUERY: EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2 WHERE s1.key2 = s2.key2) OR key3 = 'a'; // 子查询不能转成半连接&&决定采用子查询物化的方案 * DERIVED: EXPLAIN SELECT * FROM (select count(*) from s1 group by key1) as s; // 包含派生表，决定采用派生表物化的方案 * MATERIALIZED : EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2); // 包含子查询，决定采用子查询物化的方案 2. type * const: EXPLAIN SELECT * FROM s1 WHERE id = 5; // 主键或者唯一索引（唯一索引可以有多个null值，所以查null值不算） * eq_ref: EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.id = s2.id; // 连接查询、主键或者不为null的唯一索引 * ref: EXPLAIN SELECT * FROM s1 WHERE key1 = 'a'; // 通过普通索引等值查询，或者唯一索引查null值 * ref_or_null: EXPLAIN SELECT * FROM s1 WHERE key1 = 'a' OR key1 IS NULL; // null值都在索引的最左边。 * unique_subquery: EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.key1) OR key3 = 'a'; // IN查询转EXISTS，可用主键或者不为null的唯一索引 * index_subquery: EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT key3 FROM s2 where s1.key1 = s2.key1) OR key3 = 'a'; // IN查询转EXISTS，可用普通索引 * range: EXPLAIN SELECT * FROM s1 WHERE key1 IN ('a', 'b', 'c'); // in查询，>'3'（虽然各自的记录不是按照主键排序，但是记录数不多） 3. key_len: * int4字节、bigint8字节 * char和varchar：假设字符数是n，utf8就是3n，utf8mb4就是4n；允许null值就是3n+1；变长类型就是3n+2 4. ref(type属于const/eq_ref/ref/ref_or_null/unique_subquery/index_subquery时) * const: EXPLAIN SELECT * FROM s1 WHERE key1 = 'a'; * s1.id: EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s2.id = s1.id; * func: EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s2.key1 = UPPER(s1.key1); 5. rows(全表扫描或者扫描索引，扫描的行数) * EXPLAIN SELECT * FROM s1 WHERE key1 > 'z'; // 满足key1 > 'z'的条数有266 6. filtered * EXPLAIN SELECT * FROM s1 WHERE key1 > 'z' AND common_field = 'a'; // 266条记录有filtered%比例的记录满足common_field = 'a' * EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.key1 = s2.key1 WHERE s1.common_field = 'a'; // 驱动表s1的rows=9688，filtered=10，说明被驱动表要查询约968次 7. Extra * No tables used: EXPLAIN SELECT 1; * Impossible WHERE: EXPLAIN SELECT * FROM s1 WHERE 1 != 1; * No matching min/max row: EXPLAIN SELECT MIN(key1) FROM s1 WHERE key1 = 'abcdefg'; * Using index: EXPLAIN SELECT key1 FROM s1 WHERE key1 = 'a'; // 可用使用覆盖索引 * Using index condition: EXPLAIN SELECT * FROM s1 WHERE key1 > 'z' AND key1 LIKE '%a'; // 使用了索引下推 * Using where: 当搜索条件需要在Server层判断时 * Using join buffer (Block Nested Loop): EXPLAIN SELECT * FROM s1 INNER JOIN s2 ON s1.common_field = s2.common_field; // 不能用索引访问被驱动表时，利用Join Buffer提速 * Using intersect: EXPLAIN SELECT * FROM s1 WHERE key1 = '1' AND key3 = '1'; * Using union: EXPLAIN SELECT * FROM s1 WHERE key1 = '1' OR key3 = '1'; * Using sort_union: EXPLAIN SELECT * FROM s1 WHERE key1 '99'; // 先把主键排序再合并，再回表 * Using filesort: order by语句不能用到索引时，使用内存排序或者硬盘排序 * Using temporary: 包含DISTINCT、GROUP BY、UNION的子查询，需要借助临时表完成去重、排序等等 * Start temporary, End temporary: explain select * from s1 where key2 in (select key1 from s2 where key3 > '1'); // 半连接策略2，需要临时表来去重 * LooseScan: 半连接策略3 * FirstMatc: EXPLAIN SELECT * FROM s1 WHERE common_field IN (SELECT key1 FROM s2 where s1.key3 = s2.key3); // 半连接策略5 第16章 使用optimizer trace查询优化器具体工作 SET optimizer_trace=\"enabled=on\"; 执行SQL SELECT * FROM information_schema.OPTIMIZER_TRACE; 单表查询优化器具体工作： steps[4].rows_estimation.[0].range_analysis.table_scan：全表扫描的成本 steps[4].rows_estimation.[0].range_analysis.potential_range_indexes：可能使用到的索引 steps[4].rows_estimation.[0].range_analysis.analyzing_range_alternatives：可能使用到的索引的成本 steps[4].rows_estimation.[0].range_analysis.chosen_range_access_summary：最优方案总结 第17章 InnoDB的Buffer Pool show VARIABLES like 'innodbbuffer_pool%' innodb_buffer_pool_size：Buffer Pool的总大小 innodb_buffer_pool_instances：Buffer Pool的实例数 innodb_buffer_pool_chunk_size：Buffer Pool的每个实例下每个chunk的大小 Buffer Pool在Mysql启动时已经申请好了，用于缓存从硬盘读到的页： free链表，管理Buffer Pool未使用的页 flush链表，管理Buffer Pool已使用的、被修改的页 lru链表，主要用于淘汰已使用的、但是最近最少使用的页 第18章 事务 事务的四个特性： 原子性：强调要么不做，要么都做 隔离性：强调事务之间不能互相影响，如果操作同一个数据，有四个隔离级别 一致性：强调同一时刻，大家看到的数据一致 持久性：强调数据不能丢失 第19章 redo日志 redo日志的每个block大小是512KB，有三个部分 log block header log block body：存放redo记录 type：类型 space ID：表空间ID page number：页号 data：redo内容 log block trailer 一个事务可有多个SQL语句，一个SQL语句可有多个MTR，一个MTR可有多个redo记录 写入log buffer时：MTR作为一个不可分割的整体写入 崩溃恢复时：MTR作为一个不可分割的整体来处理 redo日志log buffer刷盘时机 log buffer空间不足（默认16MB） 事务提交（innodb_flush_log_at_trx_commit），=0异步刷，=1立即刷，=2写入os层 刷脏页时 后台线程，定时每秒刷一次 正常关闭mysql server 做checkpoint时 lsn：log sequence number，起始值是8707，写了多少字节的日志，就自增多少 redo硬盘日志前四个block记录了一些全局信息： LOG_CHECKPOINT_LSN：最后一次checkpoint的lsn，崩溃恢复从这个lsn开始 flush链表的lsn： 链表的每个节点都有2个属性，存储节点对应的页的最老lsn和最新lsn 当MTR写入log buffer时，会更新flush链表，同时更新上述2个属性 系统定时做checkpoint，即获取链表所有节点中最老的lsn，并更新LOG_CHECKPOINT_LSN 崩溃恢复的过程： 确定lsn起始点，lsn有三个关键的全局变量（这里取LOG_CHECKPOINT_LSN）： lsn：表示log buffer的最新lsn flushed_to_disk_lsn: 表示log buffer已经刷盘的最新lsn LOG_CHECKPOINT_LSN: 表示log buffer已经刷盘的、对应的脏页也刷盘的最新lsn 为了加快恢复速度，同一页的redo日志放一起执行 为了加快恢复速度，对于已经刷盘的页不作处理 第20章 undo日志 系统表空间的第5页Transaction System：存储了128个回滚段页的地址，8B（表空间id+页号） 每个回滚段页有1024个undo slot，4B（undo链表第一页的页号） undo链表第一页比其他undo页多了一个结构：Undo Segment Header undo链表第一页Undo Segment Header的TRX_UNDO_STATE属性： TRX_UNDO_ACTIVE：已有事务在使用 TRX_UNDO_CACHED：该链表可以重用 TRX_UNDO_TO_FREE：该链表不能被重用 TRX_UNDO_TO_PURGE：该链表不能被重用 undo链表第一页Undo Segment Header的TRX_UNDO_LAST_LOG属性：链表最后一个Undo Log Header的位置 一个事务分配undo链表的过程： 启动新事务后，找到系统表空间的第5页的128个回滚段页的地址，循环取出一个 找到回滚段页的1024个undo slot，寻找TRX_UNDO_CACHED状态的undo链表 没有，则寻找一个未被使用的undo slot，创建一个新的回滚段，同时标记undo slot 仍然没有，报错 一个事务最多分配4个Undo链表（即4个回滚段）： 针对普通表的insert undo链表 针对普通表的update undo链表 针对临时表的insert undo链表 针对临时表的update undo链表 事务提交后的处理过程： 若undo链表可以被重用（只使用了1页且不到3/4），标记为TRX_UNDO_CACHED 若undo链表不能被重用： 针对insert undo链表标记为TRX_UNDO_TO_FREE，随后链表被释放，并把undo slot标记为可用 针对update undo链表标记为TRX_UNDO_TO_PURGE，随后undo页挂到history链表，并把undo slot标记为可用 崩溃恢复的处理过程： 找到系统表空间的第5页的128个回滚段页的地址 找到每个回滚段页的1024个undo slot 若undo slot对应的undo链表第一页的状态是TRX_UNDO_ACTIVE，则说明事务还未提交就意外终止了 根据此undo链表第一页的TRX_UNDO_LAST_LOG属性，找到最后一个undo记录，执行回滚。 第21章 MVCC 事务的四大特性：原子性、隔离性、持久性、一致性 事务的四个问题：脏写、脏读、不可重复读、幻读 SQL的四个级别：读未提交、读提交、可重复读、可串行化。（一定不会出现脏写） mvcc两个知识点： 二级索引的delete是mark delete；update是mark delete并insert，参考 name字段无索引，事务1查询name='1'，事务2修改成name='2'并提交，事务1仍然能搜到name='1'，说明全表扫描时还需要扫描undo版本链。 mvcc读提交级别：解决了脏读（事务内每次select都是一个新的ReadView） mvcc可重复读级别：解决了不可重复读（事务内每次select都同一个ReadView） mvcc解决了部分幻读： 事务1根据条件查询出N条记录，事务2执行写操作，事务1再次查询查询出的记录不是N条 mvcc没有解决的幻读： 事务1先查询id=1的记录为空，事务2执行写操作，事务1执行insert id=1失败或者update id=1成功 事务1先查询id=1的记录非空，事务2执行写操作，事务1执行insert id=1成功或者update id=1失败 undo日志的回收过程： 在生成ReadView时，它的事务no等于当前系统中最大的事务no+1 在事务提交时，事务对应的一组undo日志的事务no等于当前系统中最大的事务no 由于history链表是按照事务提交的顺序排列undo日志的，所以是按照事务no排序的 ReadView按照创建时间连成了链表 后台线程执行purge时，先取ReadView链表最小的那个事务no（ReadView已提交） 每个回滚段有一个history链表，对比上一步的事务no，清理比它小的undo日志 （如果undo日志是delete类型，把对应的数据记录也删除掉） 第22章 锁 一致性读：利用mvcc的方式读 锁定读：在读取记录前加锁，S锁是lock in share mode，X锁是for update IS锁和IX锁：属于表级锁，仅仅是为了快速判断表内是否有行级锁 InnoDB的五个行级锁： Record Lock：只对记录本身加锁 Gap Lock：锁间隙 Next-Key Lock：锁记录和间隙 Insert Intention Lock：insert时碰到间隙锁而生成的锁 隐式锁：insert语句，其他事务想要在它的记录上加锁，需要先给此事务生成锁，再生成意向锁 可串行化级别下： autocommit=0，普通的select也会变成锁定读，从而保证了不会出现幻读 autocommit=1，因为只有一条select，不存在不可重复读和幻读，所以不需要锁定读 "},"docs/ddia.html":{"url":"docs/ddia.html","title":"DDIA","keywords":"","body":"Designing Data-Intensive Application 参考资料 我读 DDIA 第1章 可靠、可扩展与可维护的应用系统 设计数据系统会碰到的问题： 如何确保数据的正确性和完整性？ 系统降级时如何提供一致的良好表现？ 负载增加时系统如何扩展？ 友好的服务API如何设计？ 可靠性：安全的正确的执行，即使发生了某些错误也能正确运行 硬件故障：硬盘崩溃、内存故障、电网停电、网线断了等等 软件错误：特定输入导致的错误；CPU内存资源用尽；依赖的服务出现异常； 人为失误：以最小出错的方式设计系统 可扩展性：垂直扩展和水平扩展 可维护性：三个设计原则 可运维性，良好的可操作性使工作变得简单，从而关注于高附加值的任务 提供系统运行时的可观测性 支持自动化，与标准工具集成 避免绑定特定机器，允许机器停机维护 良好的文档和易于理解的操作模式 简单性 复杂性的表现：状态空间的膨胀；模块紧耦合；不一致的命名和术语；引入特殊框架 复杂性使得维护系统变得越来越困难，预算超支和进度滞后 好的设计抽象可以隐藏大量的设计细节，对外提供干净易懂的接口 可演化性：目标是可以轻松的修改数据系统，使其适应不断变化的需求 第2章 数据模型与查询语言 常见的三种数据模型：关系数据库、文档数据库、图数据库 关系数据库和文档数据库： 前者可以处理多对一和多对多，后者则不太方便 后者处理一对多效率高，前者则需要联接查询 文档数据库和图数据库 前者预期数据都来着同一文档，文档与其他文档的关联很少 后者则相反，预期所有的数据都可能互相关联 两者的共同点：不会对存储的数据强加一个模式，使得应用程序易于应对变化的需求 第3章 数据存储与检索 DDIA逐章精度小册学习【第三章】 CSV：123456,{\"name\":\"a\"}\\n42,{\"name\":\"b\"} Bitcask：在CSV的基础上，用内存存储hash索引：{123456:0, 42:20}；数据分段存储，老数据段压缩 Bitcask的缺点： hash索引很大，内存放不下，放硬盘性能又跟不上 不支持范围查询 SSTable：每个段的key在该段是唯一且已排序 写入时先写入内存中的红黑树，达到阈值就写入磁盘 内存索引记录每个段的开始key和结束key。查找某个Key时，去所有包含该Key的区间对应的文件二分查找即可。 记录log用于机器崩溃后恢复内存表 LSM-Tree：基于SSTable的优化 优化SSTable的key的查找：使用布隆过滤器 层级化组织SSTable：策略有大小分级和分层压缩 B-tree：与LSM-Tree一样，它也支持高效的点查和范围查。 TP(Transaction Processing)：事务处理 AP(Analytical Processing)：分析处理 数据仓库：与TP单独分开的数据库 数据模型有星状模型、雪花模型 列存储：分析的SQL有时扫描数十亿行，但只关注几个列。如果按行存储则需要读取所有无关的列 列压缩： product_sk列的原始数据是：69,69,31,29 位图编码：需要三个位图 69位图存储：1,1,0,0 31位图存储：0,0,1,0 29位图存储：0,0,0,1 游程编码：需要三个游程 69游程存储：0,2 // 两个1，后面都是0 31游程存储：2,1 // 两个0，一个1 29游程存储：3,1 // 三个0，一个1 列存储的写入：需要更新当前列，其他列为了保持下标对应，也需要更新 第4章 数据编码与演化 向后兼容：当前PB协议可以读取老版本的pb二进制 向前兼容：当前PB协议可以读取新版本的pb二进制 XML：字段类型只能是字符串 JSON：字段类型只分字符串和数值，但是没有进一步区分数值类型 Thrift和ProtoBuf都是二进制编码 Thrift有数组字段；ProtoBuf的数组是repeated，好处是optional字段可以改成repeated字段 向后兼容：新加的字段必须是optional 向前兼容：只能新加字段，不能删除和修改之前的字段(可修改相容的数据类型) Thrift和ProtoBuf修改相容的数据类型：int32改成int64 Avro没有使用字段标号，Client-Server在通信的握手阶段会先交换数据模式 相比Thrift和ProtoBuf，二进制数据不存储字段标号和字段类型，体积稍小 向后兼容：新代码读取旧数据，首先得到旧数据的写入模式，与当前模式映射，再解读数据 向前兼容：原理同上 映射规则：使用字段名来进行匹配；忽略多出的字段；对缺失字段填默认值 模式演化：只能添加或删除具有默认值的字段；只能修改Avro支持转换的类型 Avro如何从编码中获取写入模式： 如果一个大文件所有记录都使用相同模式编码，则在文件头包含一次写入模式即可。 数据库在编码时额外记录一个模式版本号，通过版本去查询对应的写入模式即可。 网络通讯时在一个session开始时交换模式，然后在整个session生命周期内都用此模式。 Avro可以动态解析数据；Thrift和ProtoBuf需要先基于IDL生成代码(好处是可以做代码静态检查) 经由数据库的数据流： 问题：新加了一个字段X，新版本进程把字段X设置为8，旧版本进程不能识别字段X而把值覆盖为空 alter table时不允许增加既没有默认值、也不允许为空的列。 经由服务的数据流：RESTful和RPC RESTful使用JSON，比较容易添加新的字段来进行演进和兼容；RPC根据编码格式的兼容性规则进行演变； RESTful常将将版本号做到HTTP请求头中；RPC一般提供客户端SDK，升级比较麻烦 经由消息传递的数据流 如果消费者暂时不可用，可以充当暂存系统。 当消费者宕机重启后，自动地重新发送消息。 生产者不必知道消费者 IP 和端口。 能将一条消息发送给多个消费者。 将生产者和消费者解耦。 第5章 数据复制 数据冗余的好处： 降低延迟：可以在地理上同时接近不同地区的用户。 提高可用性：当系统部分故障时仍然能够正常提供服务。 提高读吞吐：可以水平扩展。 常用的冗余控制算法有： 单领导者（single leader） 多领导者（multi-leader） 无领导者（leaderless） 数据库冗余问题在学术界不是一个新问题了，但在工业界，大部分人都是新手 单领导者（single leader） 新增副本 主副本在本地做一致性快照。 将快照复制到从副本节点。 从副本应用快照，并请求快照点之后的变更日志。 当从副本赶上主副本进度后，就可以正常跟随主副本了。 从副本宕机：追赶恢复 落后的多就拉取快照+日志；落后的少就拉取缺失日志。 主副本宕机：故障转移的步骤 确认主副本故障。 选择新的主副本。选择数据尽可能新的从副本 让系统感知新主副本。 主副本宕机：会遇到的问题 新老主副本数据冲突。新主副本没有同步完所有的日志，老主副本重新上线 新老主副本角色冲突。老主副本重新上线后认为它才是主副本，即发生脑裂 超时阈值选取。过小可能会发生主从频繁切换；过大则使得服务器长时间不可用 日志复制：基于语句的复制 非确定性函数问题：NOW()、RAND() 使用自增列，或依赖于现有数据。不同的执行顺序导致副本不一致。 有副作用（触发器、存储过程、自定义函数）的语句 日志复制：传输预写日志（WAL） 因为WAL日志和存储引擎绑定，需要注意版本升级的兼容性问题 日志复制：逻辑日志复制，与存储引擎无关（例如MySQL的binlog） 对于插入行：日志需包含所有列值。 对于删除行：日志需要包含待删除行标识，如主键 对于更新行：要更新的列值 日志复制：基于触发器的复制 由应用层来决策，性能较差且更易出错；但是给了用户更多的灵活性。 复制滞后问题 读你所写：刚insert到主副本就去读从副本，但是从副本还没有数据 按内容分类。读自己的资料时，从主副本读取；但读其他人资料时，可以向从副本读。 按时间分类。近期内有过改动的数据，从主副本读，其他的，向从副本读。 利用时间戳。查询时带上上次insert返回的时间戳，从同步时间大于此时间戳的副本读 单调读：读取副本A时能查询到记录，读取副本B时查不到 只从一个副本读数据。 利用时间戳。同上 一致前缀读：分区1先后记录A和B，分区2先后记录B和A 不分区。 让所有有因果关系的事件路由到一个分区。 副本滞后的终极解决方案：分布式事务 多领导者（multi-leader） 单个数据中心，多主模型意义不大。适合多主模型的有： 数据库横跨多个数据中心。可以就近写入 需要离线工作的客户端 协同编辑 处理写入冲突：冲突避免： 例如根据用户的地理位置来分配主副本 挑战1：用户从一个地点迁移到另一个地点 挑战2：数据中心损坏，导致路由变化 处理写入冲突：冲突收敛 给每个写入一个序号，并且后者胜。序号由外部系统生成 例如在Wiki的冲突中，合并后的标题为“B/C” 出现冲突时调用用户自定义的解决冲突策略的代码 处理写入冲突：界定冲突 有些冲突显而易见：并发写同一个Key。 有些冲突则更隐晦：例如预定一个会议室，用户A和用户B预定的时间有重叠。 三种复制拓扑： 环形拓扑。如果一个节点故障，则可能中断复制链路。 星型拓扑。中心节点负责接受并转发数据。如果中心节点故障，则会使得整个拓扑瘫痪。 全连接拓扑。每个主库都要把数据发给剩余主库。通信链路冗余度较高，能较好的容错。 需要用版本向量的策略，对多个副本的事件进行排序，解决因果一致性问题。 无领导者（leaderless） 读时修复和反熵过程 读时修复：在读取时发现旧的就顺手修了 反熵过程：后台进程持续进行扫描，寻找陈旧数据然后更新 Quorum读写：w+r>n可以保证读请求至少读到一个最新副本，n表示n个全量的副本 quorum一致性的局限 对于写写并发，如果处理冲突不当时。比如使用last-win策略，根据本地时间戳挑选时，可能由于时钟偏差造成数据丢失。 对于读写并发，写操作仅在部分节点成功就被读取，此时不能确定应当返回新值还是旧值。 如果写入节点数 虽然写入时，成功节点数=w，但中间有故障造成了一些副本宕机，导致成功副本数 # 放松的Quorum和提示转交 Dynamo实际上不需要系统保障所有的quorum节点可用。它使用一种“sloppy quorum”的策略。 简单来说，一份数据储存在ABC三个节点中。当A节点宕机或不可达时，就临时储存在D节点中。 D节点单独有一块区域存储这些本不属于自己的数据，并进行定时轮询。如果发现A节点可用，就将数据传输回去并删掉本地的副本。始终保持三个节点的数据副本。 （注意此处选择D不是任意的，应该是在环中最近一个健康节点，这样才能保证故障时读写数据能找到该节点）。 # 解决写写并发有两个方案 # 1.后者胜（Last-Write-Win） 后者胜（LWW，Last-Write-Win）的策略是，通过某种手段确定一种全局唯一的顺序，然后让后面的修改覆盖之前的修改。 如，为所有写入附加一个全局时间戳，如果对于某个key的写入有冲突，可以挑选具有最大时间戳的数据保留，并丢弃较早时间戳的写入。 LWW有不可重复读问题，客户端写入数据后迅速再读，会发现不是自己写入的数据。 # 2.单副本确定Happens-Before 服务器为每个键分配一个版本号V，每次该键有写入时，将V+1，并将版本号与写入的值一块保存。 当客户端读取该键时，服务器将返回所有未被覆盖的值以及最新的版本号。 客户端在进行下次写入时，必须包含之前读到的版本号Vx（说明基于哪个版本进行新的写入），并将读取的值合并到一块。 当服务器收到特定版本号Vx的写入时，可以用其值覆盖所有V≤Vx的值。 # 多副本确定Happens-Before：版本向量 第6章 数据分区 分片(分区)，Partition，有很多别称。通用的有Shard；具体到实际系统，HBase 中叫Region，BigTable中叫tablet 通常在分布式数据库中会有三级划分：数据集(如Database、Bucket)——分片(Partition)——数据条目(Row、KV) 分片时有一些基本要求 分片过程中要保证数据均匀，否则会有数据偏斜产生数据热点。 分片后需要保存路由信息，给一个KV条目，能知道去哪个机器上去查；稍差一些可以知道去哪几个机器上去找。 按键范围（Key Range）分区 优点：可快速的范围查询。如以时间戳为key，可获取一段时间内数据 缺点：数据分散不均匀，且容易造成热点。以时间戳为key，可能最新写入都被路由到最后一个分区节点 按键散列（Hash）分区 优缺点与范围分区相反 需要用元数据存储逻辑分片到物理节点的映射，如果使用一致性哈希，可实现半自动的增量式迁移 两种分区方式的小结 区别1：一个使用应用相关值（Key）分区，一个使用应用无关值（Hash(key)）分区 区别2：前者支持高效范围查询，后者可以均摊负载。 使用多个字段，组合使用两种方式，使用一个字段进行分区，使用另一个字段在分区内进行排序，兼取两者优点。 负载偏斜和热点消除 负载偏斜：如微博大V其发布的一条tweet，引起大量的comment，comment表以tweet_id哈希到同一个节点 热点消除：给tweet_id拼接0~99的随机数，最多分散到100个节点。（读取时需要进行结果合并） PS：最好能自动检测热点，自动拆分合并分区，以消除倾斜和热点。 次级索引：用户表(user_id,name)的主索引是user_id，有时候需要基于name建次级索引 次级索引-本地索引： 优点：更新数据时，只需要在该分区所在机器同时更新索引即可。 缺点：查询效率相对较低，所有基于索引的查询请求，都要发送到所有分区，并将结果合并。 次级索引-全局索引： 能避免索引查询时的scatter/gather操作，但维护起来较为复杂，因为每个数据的插入，可能会影响多个次级索引 全局索引多为异步更新。但由此会带来短暂（有时可能会比较长）的数据和索引不一致。 为了保证强一致性，需要引入跨分区的分布式事务（实现复杂度高，且会带来较大的性能损耗） 分片均衡-rebalancing 均衡后负载（存储、读写）在节点间均匀分布 均衡时不能禁止读写，并且尽量减小影响 尽量减少不必要的数据移动，尽量降低网络和磁盘IO 分片均衡-动态分区 范围分区的方案，存在数据不均匀的情况，因此可以才有动态分区的方法 开始，数据量很少，只有一个分区。 随着数据量不断增长，单个分区超过一定上界，则按尺寸一分为二，变成两个新的分区。 如果某个分区，数据删除过多，少于某个下界，则会和相邻分区合并。 分片均衡-静态分区 逻辑分区的数量是固定的，需要维护逻辑分区到物理节点的映射 请求路由的方案 每个节点都有全局路由表。客户端可以连接集群中任意一个节点 由一个专门的路由层来记录。客户端所有请求都打到路由层 让客户端感知分区到节点映射。客户端根据路由信息直接请求节点 第7章 事务 步步为营 剖析事务中最难的——隔离性 多对象事务：使用事务管理器，为每个事务分配一个唯一标识符。 单对象事务：例如你正在写入一个20KB的文档 如果发送了前10kb数据后，网络断开，数据库是否已经存储了这不完整的10k数据？ 如果该操作是正在覆盖一个老版本同id数据，覆盖一半时电源发生故障，数据库是否会存在一半旧值一半新值？ 如果有另一个客户端同时在读取该文档，是否会看到半更新状态？ 隔离级别 脏读&脏写 不可重复读 幻读 读未提交 √ √ √ 读已提交 √ √ 可重复读 √ 可串行化 . 注：RL:ReadLock; WL:WriteLock；UL:Unlock // 脏读：事务2读到了事务1未提交的值 事务1：--W(x=5)--->rollback 事务2：----->R(x=5)--->commit // 脏写：最终结果是x=6, y=5。但期望的是要么xy都等于5，要么都等于6 事务1：--W(x=5)--------W(y=5)--->commit 事务2：----W(x=6)--W(y=6)->commit // 不可重复读：在读已提交级别下，事务1两次读到的x不一样 事务1：RL(x),R(x=4),UL(x)-------------------------->RL(x),R(x=5),UL(x)--->commit 事务2：-------------------WL(x),W(x=5)-->commit,UL(x) // 单对象，会发生更新丢失。（本来x最终应该是6） 事务1：RL(x),R(x=4),UL(x)---------------------------->WL(x),W(x+=1)--->commit,UL(x) 事务2：RL(x),R(x=4),UL(x)-WL(x),W(x+=1)-->commit,UL(x) 读已提交解决脏读和脏写的两个方案： 方案一：解决脏读用ReadLock，解决脏写用WriteLock 方案二：解决脏读用MVCC，解决脏写用MVCC 不可重复读：一般是读-读场景 不可重复读，在某些情况下是不可接受的： 备份。备份过程中可能会有读写存在，从而造成备份时的不一致。 分析型查询和完整性检查。这个操作和备份一样耗时较长。 MVCC的基本要点为： 每个事务开始时会获取一个自增的事务txid。 该事务在修改数据时，不会修改以前版本，而会新增一个具有txid版本的数据。 该事务只能访问到所有版本≤txid的数据。 在写入时，如果发现某个数据存在>txid的版本，则存在写写冲突。 幻读：一般是读-写场景 幻读：一个事务的写入会改变另一个事务的查询结果的现象 单对象，会发生更新丢失，三个解决方案： 原子写：支持原子写的SQL：SET value = value + 1 显式上锁：select xx where xx for update; 自动检测更新丢失：PostgreSQL的可重复读，Oracle的可串行化和SQLServer的快照隔离，能自动检测更新丢失的冲突，并中止后面的事务 多对象，会发生写偏序，图例： 假设医院某天，轮到Alice和Bob两人值班，但他们都想请假 医院规定每天至少要有一名医生值班，两人并发申请请假，结果两人都成功了 多对象，会发生写偏序，它的执行模式如下： 通过select语句+条件过滤出符合条件的所有行。 依赖上述结果，应用侧代码决定是否继续。 如果应用侧决定继续，就执行更改（插入、更新或者删除），并提交事务。 写偏序，是因为幻读导致的，如果隔离级别不是可串行化，可使用显式上锁解决。 可串行化，最强隔离级别 可串行化之物理上串行：用单线程串行执行事务，缺点是没法分布式 可串行化之两阶段锁：因性能不好而被弃用，它的思路如下： 如果某个事务想读取一个对象，需要首先获取该对象的共享锁。 如果某个事务想写入一个对象，需要首先获取该对象的互斥锁。 如果某个事务要先读取，再写入某个对象，可以先获取其共享锁，然后将其升级为互斥锁。升级互斥锁和获取互斥锁的条件相同。 当某个事务获取锁之后，必须持有到事务结束（中止或者提交） 可串行化之可串行的快照隔离： 读的对象被其他事务写入： 读对象时发现有更新的未提交版本，记录为一个集合 提交时检测集合内的事务是否有提交，若有则终止事务 写的对象被其他事务读取： 读对象时把自己的事务id标记在此对象上，提交时删除标记 写对象时通知此对象上标记的事务，同时提交时发现通知的对象已提交，则终止事务 第8章 分布式系统中的麻烦事 构建大型计算系统的两种思路 高性能计算（HPC）。使用上千个CPU构建的超级计算机，本质上还是单机 分布式计算。将通用的廉价的计算资源，通过计算机网络收集起来进行池化。 不可靠的网络，可能的情景 A的请求还没有到达B，就丢了 A的请求达到了B，但是在B的应用层丢了 A的请求达到了B，B处理完后通知A，通知未达到A就丢了 不可靠的网络，实践中的网络故障 如交换机软件升级引发的拓扑重置，会导致期间网络延迟超过一分钟。 鲨鱼可能会咬断海底光缆。 有些奇葩的网口会只能发，不能收 不可靠的网络，在节点服务挂了后如何故障检测 操作系统通知。网络请求时，操作系统会通过发送RST或FIN包来关闭TCP连接。 daemon脚本通知。在本机服务进程死掉之后，主动通知其他节点。 数据链路层面。如果能访问到数据中心的网络交换机，可以在数据链路层判断远端机器是否宕机。 IP不可达。如果路由器发现你要发送请求的IP地址不可达，它会直接回你一个ICMP不可达包。 电话电路和互联网线路 电话电路：假设有10000路通话的线路，最多承载10000通话，通话时线路是独占的 互联网线路：共享网络资源，数据包的发送由交换机来动态决定 电话电路：资源静态分配，由于电路是独占的，所以端到端的最大延迟是固定的，称为有界延迟 互联网线路：资源动态分配，由于排队问题，端到端的最大延迟是不定的，称为无界延迟 日历时钟和单调时钟 日历时钟，和NTP同步时，可能会往前或者往后跳拨 单调时钟，NTP可以调整单调时钟频率 真相由多数派定义 领导者和锁，可能出现的问题：老的leader在故障恢复后仍然向其他节点发送决策命令 防护令牌，锁服务授予锁的同时附带防护令牌，防护令牌单调递增，存储服务每次存储都记录防护令牌 拜占庭将军问题：A提议进攻，B提议撤退，C->A进攻，C->B撤退，导致A将军进攻战死 拜占庭：对于本书中讨论的大部分系统，我们都可以假设不存在拜占庭故障。 分布式算法具有的性质：唯一性、单调有序性、可用性 安全性和存活性 唯一性和单调有序性属于安全性，但可用性属于存活性。 安全性，通俗的可以理解为没有坏事发生；存活性，可以理解为好的事情最终发生了 如果违反了安全性，我们一定可以找到一个其被破坏的具体时间点 存活性正好相反，可能在某个时刻不满足，但是在将来总会被满足 对于分布式系统算法，我们通常会比较关注安全性 线性一致性和因果一致性 线性一致性：全局全序，写事务后，读任何副本都是相同的新数据 线性一致性：属于强一致性，但非常影响性能和可用性 因果一致性：很多系统会舍弃线性一致性以换取更好的性能 因果一致性是线性一致性的必要条件 一，Lamport时间戳 假设购物网站有两个节点A和B，用户请求A产生下单记录日志，接着请求B产生付款记录日志，日志汇总到X，X如何定义日志的先后顺序呢？ 1. 每次的日志都会附带二元组(counter, nodeID)，假设最开始A的counter=29，B的counter=13 2. 请求A产生下单记录日志，A将本地的counter更新为30，日志加上二元组(30, nodeA) 3. 请求B产生付款记录日志，请求头带上(30, nodeA)，B先将本地的counter更新为31，日志加上二元组(31, nodeB) 4. 日志汇总到X，X根据日志的counter进行排序，若counter相等则按nodeID排序 二，全序广播：如何实现线性一致，以用户名的唯一性约束的例子： 1. 节点A收到注册Ringo的请求，通过单Leader多Follower机制发送全局广播消息 2. 全序广播保证了，消息是以相同的顺序传递给所有节点，节点顺序消费消息 3. 节点A同步等待，监听“注册Ringo”的消息 4. 收到第一条消息，看看是不是自己发出的，是则写入数据库 鸡生蛋、蛋生鸡： 实现全序广播，我们需要单Leader多Follower机制(需要选主) 而实现选主，我们需要共识算法(需要全序广播) 2PC的流程： 当应用想开启一个分布式事务时，它会首先向协调者要一个事务ID。 应用通过协调者向所有的参与者发起一个单机事务，所有节点会各自完成读写请求。 协调者会向所有参与者发送准备提交（prepare）请求，如果有请求失败或者超时，则协调者宣告事务失败。 当参与者收到准备提交请求时，它必须确认该事务能够在任何情况下都能被提交，才能回复“可以”。 当协调者收到所有参与者准备提交的回复后，会决定提交还是中止该事务，然后通知所有的参与者。 2PC两个不可回退点： 当某个参与者回复“可以”时，就做出了肯定可以提交的承诺。 当协调者决定提交时，该决定一旦做出（写入磁盘日志），就是不可撤回的。 2PC在不可回退点会阻塞：因为事务中可能持有锁 2PC的协调者问题 如果协调者没有使用多副本机制，则存在单点故障 如果协调者放在应用层，因为应用层一般是无状态的，而协调者要求能持久化决策日志 即使协调者放在数据库层，因为要求所有的参与者都必须回应，因而只要有一个参与者故障则服务不可用 共识协议必须满足以下条件： 全局一致性：节点在相同的条件下，必定做成相同的决策 正直性：讲信用，一旦回复“可以”，就表示事务可以提交 有效性：投票时不会弃权，或者投不能识别的票 可终止性：系统不会陷入卡死的状态，即使部分节点失效，仍能工作 PS：事实证明，任何共识算法都要求多数节点存活，以保证可终止性 共识协议在全序广播的体现： 由于全局一致性，所有节点会以同样的顺序投递同样的消息。 由于正直性，具有同样id的消息不会重复。 由于有效性，消息不会是损坏的，也不会是凭空捏造的。 由于可终止性，消息不会丢失。 "},"docs/cache-policies.html":{"url":"docs/cache-policies.html","title":"缓存模式","keywords":"","body":"缓存模式 五种缓存模式 缓存的五种设计模式 Cache aside：cache不存在时去读db；写db，写完删cache Read Through：cache不存在时cache去读db Write through：先更新cache再更新db，都成功后返回 Write Behind：先更新cache，再异步更新db，也称Write Back Write Around：绕过cache直接更新db CPU Cache 关于 CPU 上的高速缓存 write-invalidate，Core1修改x=3，则需更新L3缓存，同时通知其他Core的L1、L2失效 写缓存策略 write through + write allocate：未命中时先cache数据再修改 write through + no write allocate：未命中则只修改下游缓存 write back + write allocate write back + no write allocate （一般采用write through + no write allocate和write back + write allocate） Server Cache 缓存模式以及缓存的数据一致性 dtm-labs缓存一致性 携程最终一致和强一致性缓存实践 方案一：Cache aside 优点：仅在cacheMiss时更新缓存 缺点：cacheMiss时读取耗时长，且存在缓存不一致问题 方案二：Read Through/Write Through 优点：cacheMiss时读取耗时短 缺点：对于读少写多的场景不友好 方案三：Read Through/Write Behind 优点：没有方案二的缺点 缺点：因为是异步更新db，可能导致数据丢失 方案四：Read Through/Write Around 优点：没有方案二的缺点 缺点：存在缓存不一致问题 基于方案一的优化1：B站的方案 请求1：cacheMiss->读v1->setNX 请求2：writeDB(v2)->setEX 写写场景的方案1：binlog异步任务补偿cache 写写场景的方案2：更新锁 基于方案一的优化2：Facebook的方案 请求1：cacheMiss并得到leaseId->读v1->set(v1, leaseId) 请求2：writeDB(v2)->delCache并使leaseId失效 基于方案一的优化3：携程的方案 请求1：加锁（cacheMiss->读v1->set） 请求2：加锁（writeDB(v2)->delCache） "},"docs/systems-performance.html":{"url":"docs/systems-performance.html","title":"性能之颠","keywords":"","body":"性能之巅 资料 作者的博客 安装Systemtap - UCloud systemtap安装 1. apt install systemtap 2. stap-prep // 检查安装是否正确，并会提示如何安装 3. echo -e \"deb http://ddebs.ubuntu.com xenial main restricted universe multiverse\\ndeb http://ddebs.ubuntu.com xenial-updates main restricted universe multiverse\\ndeb http://ddebs.ubuntu.com xenial-proposed main restricted universe multiverse\" > /etc/apt/sources.list.d/ddebs.list 4. apt install ubuntu-dbgsym-keyring 或者 apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622 5. apt update 6. apt-get install linux-image-$(uname -r)-dbgsym // 源码安装（因为ubuntu自带的systemtap版本太老了） apt remove systemtap wget https://sourceware.org/systemtap/ftp/releases/systemtap-4.4.tar.gz apt install g++ make libelf-dev libdw-dev ./configure && make && make install // 检查命令（在ubuntu 16.04，内核4.4.0-1128-aws安装成功） stap -ve 'probe begin { log(\"hello world\") exit() }' stap -ve 'probe vfs.read {printf(\"read performed\\n\"); exit()}' stap -e 'probe kernel.function(\"sys_open\") {log(\"hello world\") exit()}' systemtap使用 SystemTap使用技巧 统计函数执行耗时 动态追踪技术之SystemTap // systemtap // 输出进程a.out的main函数 stap -L 'process(\"./a.out\").function(\"main\")' // 输出进程a.out的所有函数 stap -L 'process(\"./a.out\").function(\"*\")' // 统计进程a.out函数执行次数 vim funccount.stp global top_funcs; probe process(\"./a.out\").function(\"*\"){ top_funcs[ppfunc()]++; } probe end{ printf(\"\\n%-40s %s\\n\", \"FUNC\", \"COUNT\"); foreach(func in top_funcs-) printf(\"%-40s %d\\n\", func, top_funcs[func]); } stap funccount.stp 系统分析工具 perf：用于分析哪些方法调用cpu比较高、cpu cache命中率、分支预测等 valgrind：它的helgrind工具用于分析资源竞争 gprofile：用于分析函数调用次数和耗时等(编译时需要带上-pg)，原理就是在函数入口、出口加hook，对源码是侵入式的。 oprofile：用于分析cpu cache命中率等 Dtrace：不支持linux，适合Solaris、MacOS、FreeBSD SystemTap：可以分析内核函数、用户函数 eBPF 常用的两个工具：BCC和bpftrace BCC：利用linux的eBPF功能，因此需要使用linux 3.15+/4.1+。 bpftrace 类似于Dtrace的linux 翻版，支持使用自定义的脚本语言 eBPF 入门之初体验 # 在wsl2的ubuntu18.04和ubuntu20.04安装成功 # 参考：https://oftime.net/2021/01/16/win-bpf/ 1. 先安装linux-header，需要源码安装，我的内核版本是4.19.104-microsoft-standard 2. ubuntu20.04直接apt-get install bpfcc-tools 3. ubuntu18.04官方的bpfcc-tool版本太老，需要源码安装bpfcc-tools v0.12（选择src-with-submodule版本） 4. sudo mount -t debugfs debugfs /sys/kernel/debug // 统计进程a.out函数执行次数 /usr/share/bcc/tools/funccount ./a.out:* "},"docs/head-first-design-patterns.html":{"url":"docs/head-first-design-patterns.html","title":"Head First设计模式","keywords":"","body":"Head First设计模式 重写、重载、面向对象四大特性 Java基础之多态的实现重载 vs 重写 重写（override）：参数和返回值都必须和父类相同 重载（overload）：参数必须不同，返回值可以相同 面向对象四大特性： 封装 抽象 继承：子类使用父类的方法 多态：父类使用子类的方法（重写） UML的六个箭头，参考1，参考2 实现：虚线空心三角；接口实现 泛化：实线空心三角；继承 依赖：虚线箭头；人--------->车；人的方法传参需要车这个对象 关联：实线箭头；唐僧——>徒弟；唐僧有个属性关联了徒弟这个对象 聚合：实线空心菱形；has-a；学生——⟡班级 组合：实线实心菱形；contains-a；四肢——◆人，人没了，四肢也不存在了 15个常用设计模式的分类： 创建型：单例模式、简单工厂、工厂方法、抽象工厂 结构型：装饰者模式、适配器模式、外观模式、组合模式、代理模式 行为型：策略模式、观察者模式、命令模式、模板方法、迭代器模式、状态模式 23种设计模式 - CSDN 七个设计原则 《Head First 设计模式》读书笔记 设计原则一：封装变化。找出应用中可能需要变化之处，把它们独立出来，不要和那些不需要变化的代码混在一起。如策略模式。 设计原则二：针对接口编程，而不是针对实现编程。 设计原则三：多用组合，少用继承。如观察者模式。 设计原则四：为了交互对象之间的松耦合设计而努力。 设计原则五：类应该对扩展开放，对修改关闭。 设计原则六：依赖倒置原则。要依赖抽象，不要依赖具体类。 设计原则七：最少知识原则。只和你的密友谈话。如外观模式。 策略模式 案例：鸭有绿头鸭、红头鸭、橡皮鸭；鸭的特性有飞、叫 坏的设计1：基类有鸭（包含方法fly、quack），橡皮鸭继承基类（重写方法fly、quack） 坏的设计2：基类有鸭，接口有Flyable、Quackable，子类通过setFlyBehavior、setQuackBehavior来实现飞、叫 好的设计： 基类有鸭（包含方法fly、quack，包含属性flyBehavior、quackBehavior） 每个子类都继承基类（构造函数赋值不同的flyBehavior、quackBehavior） oo原则： 封装变化 多用组合，少用继承 针对接口编程，不针对实现编程 oo模式：策略之间可以相互替换，让策略的变化独立于使用策略的客户 观察者模式 案例：主题有温度、湿度、气压；显示屏有三个 坏的设计：面向过程的写法，当主题变化时，初始化三个显示屏并执行update方法 好的设计： 接口有Subject（包含方法registerObserver、removeObserver、notifyObservers），对应的实现类是WeatherData（包含属性Temperature、Humidity、Pressure） 接口有Observer（包含方法update），对应的实现类是三个显示屏 oo原则：为交互对象之间的松耦合设计而努力 oo模式：在对象之间定义一对多的依赖，这样一来，当一个对象改变状态，依赖它的对象都会收到通知 装饰者模式 案例：星巴克的咖啡有室内混搭、焦炒、脱咖啡因，调料有牛奶、豆浆、摩卡 坏的设计1：基类有Beverage（包含方法getDescription、cost），子类是HouseBlendWithMilk、HouseBlendWithSoy等等 坏的设计2：基类有Beverage（包含方法getDescription、cost，包含属性Milk、Soy、Mocha），子类HouseBlend（通过setter修改属性Milk、Soy、Mocha，重写cost方法） 好的设计： 基类有Beverage（包含方法getDescription、cost），子类有HouseBlend、DarkRoast、Decaf和CondimentDecorator（包含属性beverage） CondimentDecorator的子类有Milk、Soy、Mocha 例如要一个HouseBlendWithMilk类，先实例化HouseBlend，再用Milk类来装饰 oo原则：对扩展开放，对修改关闭 oo模式：动态的将责任附加到对象上（而不是通过继承） 工厂模式 案例：披萨店生成各种口味披萨（简单工厂）；纽约店和芝加哥店同口味的披萨做法不同（工厂方法）；纽约店和芝加哥店需要各种本地原料（抽象工厂） 坏的设计：对比简单工厂模式，用面向过程的写法，在客户端写if-else语句来创建不同的披萨 好的设计：简单工厂模式 oo原则：依赖抽象，不要依赖具体类 oo模式： 工厂方法：定义了创建对象的接口，由子类来决定如何创建 抽象工厂：定义了创建产品家族的接口，同时产品也是抽象 单例模式 案例：用锅炉融化牛奶和巧克力，锅炉只能有一个 坏的设计：用全局变量来保存类实例 好的设计：用单例模式，可以延迟实例化，需注意并发导致实例化多次 oo模式：确保一个类只有一个实例 命令模式 案例1：用户点菜下单，服务员把单子交给厨师，厨师做好菜。服务员和厨师解耦，服务员不需要知道是哪个厨师做、如何做这些菜 案例2：一个遥控器控制五种家电的开和关：卧室灯、厨房灯、吊扇、车库门、音响 坏的设计：面向过程的写法，遥控器写大量的if-else来实现按钮和对应的事件 好的设计：控制器是Invoker，Command数组绑定5个Command，Command关联卧室灯、厨房灯、吊扇、车库门、音响 oo模式：将请求封装成对象，让请求成为标准化的处理物品 适配器模式 案例：把火鸡当作鸭子，需要一个继承鸭类的适配器类 坏的设计：直接修改现有的火鸡类 好的设计：设计一个继承鸭类的适配器类，这样就不用修改原有的代码 oo模式：将一个类转换成用户期望的另一个类 外观模式 案例：打开家庭影院模式：打开爆米花机、灯光10%、屏幕放下、打开投影机、音响设置环绕立体音、DVD播放影片 坏的设计：面向过程的写法，客户端直接写打开爆米花机、灯光10%、屏幕放下、打开投影机、音响设置环绕立体音、DVD播放影片 好的设计：设计一个外观类，提供简单的操作接口，客户端只需要和外观类打交道 oo原则：最少知道原则 oo模式：封装内部子系统，对外提供统一的、简单的接口 模板方法 案例：星巴克泡咖啡/茶的秘方共同点：把水煮沸、泡咖啡/茶、泡好倒入被子、加上调料 坏的设计：泡咖啡和泡茶独自写一个类，缺点是两者有重复的代码 好的设计：设计一个公共的抽象类，泡咖啡和泡茶继承它并实现有差异的部分 oo原则：好莱坞原则（别找我，我会找你），由高层决定when、how使用低层组件 oo模式：定义一个算法的骨架，把变化的部分延迟到子类去实现 迭代器模式 案例：服务员需要将两个餐厅的菜单合并，A餐厅使用ArrayList，B餐厅使用数组 坏的设计：面向过程的写法，先展示A餐厅的菜单，再展示B餐厅的菜单 好的设计：两个餐厅仅暴露一个获取迭代器的方法，服务员据此获取迭代器，并展示数据 oo原则：单一职责原则，一个类只有一个引起变化的原因 oo模式：提供一个方法顺序访问聚合对象内部的元素，而不暴露其内部的实现 组合模式 案例：服务员需要提供一个树状菜单：A菜单、B菜单、C菜单，C菜单的一个子项是D菜单 好的设计：每个节点可以是menu也可以是menuItem，两者继承menuComponent类 oo模式：让客户端以一致的方式处理对象或对象组合 状态模式 案例：糖果机有4个按钮4个状态：投币、退币、转动曲柄、发放糖果、；已投币、未投币、售罄、售出 坏的设计：糖果机实现四个方法：投币、退币、转动曲柄、发放糖果，每个都需要写if-else判断 好的设计：糖果机有一个表示状态属性，由状态去处理四个动作 oo模式：允许对象在内部状态改变时改变它的行为，对象看起来像修改了它的类 代理模式 代理模式控制客户端对对象的访问，有多种方式： 远程代理：实现远程访问对象 虚拟代理：控制实例化开销大的对象 保护代理：设置对对象的访问规则 oo模式：为另一个对象提供替身或者占位符以访问这个对象 "},"docs/talk-about-network-protocol.html":{"url":"docs/talk-about-network-protocol.html","title":"趣谈网络协议","keywords":"","body":"趣谈网络协议 参考资料 趣谈网络协议 第1章 通讯协议概述 大前提：两台机器之间必须知道mac地址才能点对点通讯 局域网内如何知道对方的mac地址？发送arp广播，对方回应mac地址 什么是二层设备？就是对比mac，看看是接收、丢弃还是转发 什么是三层设备？就是对比mac，再对比ip，看看是接收、丢弃还是转发 机器配置的网关ip必须保证和自己的某一个网卡是同一个网段的 net-tools：ifconfig命令，已经停止维护 iproute2：ip addr命令 CIDR块：如16.158.165.91/22，子网掩码前22位都是1，则ip是16.158.164.0~16.158.167.255 DHCP：机器没有配置DHCP地址，发送DHCP广播，DHCP服务器会应答并返回它的ip和你的新ip 第2章 从二层到三层 mac是局域网的定位，ip是跨网络的定位 已知对方ip地址求mac地址？发送arp广播 两台电脑网线直连：先发送ARP(内核包含此逻辑)获取到mac再通讯 三台电脑Hub通讯：Hub每次收到数据就转发给所有的电脑 交换机学习的过程： 最开始不知道每台电脑的mac，所以转发给所有的电脑，记住发送方的mac 一段时间后，记住了所有电脑的mac，存入转发表 后续收到数据就转发给指定mac的电脑 交换机的vlan： vlan是为了保证隔离，避免局域网内被人抓包 ARP欺骗攻击 MAC地址泛洪攻击 链路层的mac头包含：目标mac、源mac、vlan_id 手动设置交换机上每个网口所属的vlan_id，vlan_id相同的包才会互相转发 交换机有个特殊的网口称为Trunk口，可以无视vlan_id转发包，一般用于对接其他交换机 ping命令：使用了icmp的echo request和echo reply类型 traceroute命令：发送带ttl的udp包，途径最后一个路由器，路由器返回icmp包 转发网关：A机器——X网关左手——X网关右手——B机器 A机->X左：macA机，ipA -> macX左，ipB X左->X右：macX左，ipA -> macX右，ipB X右->B机：macX右，ipA -> macB机，ipB NAT网关：A机器——X网关——Y网关——B机器 A机->X关：macA机，ipA -> macX关，ipY X关->Y关：macX关，ipX -> macY关，ipY Y关->B机：macY关，ipY -> macB机，ipB 其中A机器，ipA是它的内网ip，ipX是它的外网ip，B机器同理 第二步中X网关把源ipA变成ipX的过程是SNAT：源地址转换 第三步中Y网关把目标ipY变成ipB的过程是DNAT：目标地址转换 静态路由配置：源ip是？目标ip是？——>经XX网口，下一跳ip是XX 基于距离矢量路由算法的BGP协议： 基于Bellman-Ford算法 如果新路由器加入很快就广播了，而下线则不知道 某路由器更新时发送整个路由表 适合数据中心之间的连接 使用TCP协议，端口是179 基于链路状态路由算法的OSPF协议： 基于Dijkstra算法 路由器下线也会广播 某路由器更新时发送变更的部分 适合数据中心内部的连接 使用IP协议，协议编号是89 第3章 最重要的传输层 TCP和UDP的区别 TCP面向连接，接收方和发送方都要维护对应的数据结构；UDP是无连接的，发送数据之前不需要建立连接 TCP保证可靠传输；UDP不保证可靠 TCP面向字节流；UDP是面向报文的 TCP连接是一对一；UDP支持一对一和多播 TCP首部开销20~60字节；UDP的首部开销只有8个字节 UDP定制化的五个例子 Google的QUIC，在应用层实现可靠传输、拥塞控制 直播协议，网络不好允许丢包 实时游戏，只在乎丢包但在乎实时响应 IOT物联网，芯片上内存资源有限，UDP开销小 移动通讯领域4G的GTP-U，因为GTP协议本身就保证了通讯的可靠 TCP的四次挥手，以A和B打电话为例： A说“我没啥要说的了”，B回答“我知道了” B可能还会有要说的话，于是B可能又巴拉巴拉说了一通 最后B说“我说完了”，A回答“知道了”。B说完需要等ack后才能关闭连接，A回答完要等2MSL才能关闭： B如果没有收到ack(ack包丢了)，会再发送一次“我说完了” A为什么要等2MSL，因为2MSL内B都没有再发送“我说完了”，证明已经收到ack包了 顺序问题和丢包问题： 累计确认，不用一个包一个ack 超时重传，超时时间应>RTT(往返时间) 快速重传，需重传序号7的包：连续三个序号7的ack SACK(选择确认)：ACK=10,SACK=15-20表示15~19已收到，10~14没有 流量控制： 更新滑动窗口，接收方返回ack的同时返回AdvertiseWindow 若接收方AdvertiseWindow=0，发送方停止发送，定时发送窗口探测包看是否会调整窗口 拥塞控制： 慢开始：cwnd=1，每次指数增长 拥塞避免：窗口内包的总大小>ssthresh，每次cwnd+=1/cwnd (重新慢开始)：发生丢包，ssthresh=cwnd/2 && cwnd=1 快重传：收到连续3个ack提示丢包，快速重传 快恢复：快重传时丢包并不严重，cwnd=cwnd/2 && ssthresh=cwnd 第4章 最重要的应用层 Http keep-alive机制： http 1.0：客户端头带上Connection: Keep-Alive，服务器头带上Connection: Keep-Alive http 1.1：默认已经是keep-alive，除非指定Connection: Close Keep-Alive: timeout=5, max=1000 表示空闲时长5秒，可发送的请求量是1000 TCP keep-alive机制：可对单个socket设置，否则使用内核默认配置 setsockopt(sockfd, SOL_SOCKET, SO_KEEPALIVE, (void *)&keepAlive, sizeof(keepAlive)); 开启keepalive setsockopt(sockfd, SOL_TCP, TCP_KEEPIDLE, (void*)&keepIdle, sizeof(keepIdle)); 空闲时长 setsockopt(sockfd, SOL_TCP, TCP_KEEPINTVL, (void *)&keepInterval, sizeof(keepInterval)); 探测包间隔时间 setsockopt(sockfd, SOL_TCP, TCP_KEEPCNT, (void *)&keepCount, sizeof(keepCount); 失败后尝试几次 Http 2.0 解决了Http 1.1队首阻塞问题，同一个连接可并行发送多个请求和响应 每个请求可以有多个stream Magic stream是发送方三次握手后的第一帧，接收方ack后意味着H2正式连接，内容固定24B：PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n 不同类型的stream的头部固定是9字节(Magic类型除外)： length(3B)：整个stream的长度 type(1B)：类型，0~9依次是DATA/HEADERS/PRIORITY/RST_STREAM/SETTINGS/PUSH_PROMISE/PING/GOAWAY/WINDOW_UPDATE/CONTINUATION flags(1B)：stream类型不同代表的含义也不同 streamId(4B)：stream id，最高的1位是预留位 Http 3.0：基于使用UDP的QUIC协议 H2的问题1：受限于TCP重组，虽然stream2和stream1没有关联，但是stream1没有到达stream2不能提交给用户，称为TCP层的队首阻塞 H2的问题2：受限于TCP四元组，如果发送方网络变化导致IP变化则需要重连，QUIC不使用四元组而是随机数 H2的问题3：受限于TCP，拥塞控制粒度是连接，H3的粒度是连接的stream HTTPS 加密传输流程： 客户端先client hello发给服务端随机数randomClient 服务端再server hello发给客户端随机数randomServer 服务端发送公钥证书 客户端利用根证书验证此公钥证书 客户端使用公钥证书加密传输随机数pre-master给服务端 后续双方就使用randomClient、randomServer、pre-master加密传输数据 流媒体协议、P2P下载 第5章 陌生的数据中心 cdn一般有glsb，用户->权威ns得到cname->cdn的ns得到cname->cdn的glsb->cdn节点 httpdns：必须要有客户端sdk，httpdns的服务地址需写死在sdk里 动态cdn：1.定时同步db，部署边缘计算；2.优化用户和源站的线路 机房中的2层网络 IPSec VPN（ip层的加密传输） DH（diffie-hellman）算法：在不安全的网络交换对称密钥K A和B都有黄色（指数p和q） A有蓝色（私钥a），B有红色（私钥b） A这边黄色+蓝色=绿色，B这边黄色+红色=橙色，AB交换绿色、橙色 A这边橙色+蓝色=棕色，B这边绿色+红色=棕色，棕色是对称密钥K https为什么不用DH算法？DH算法不能验证身份，不能防止中间人攻击 在巴塞罗那手机上网为什么不能访问脸书？上网时巴的运营商中转给国内运营商了 第6章 云计算中的网络 网络模式之桥接： 同主机的虚机A和虚机B通讯：A和B分别有虚拟网卡A和B，再建立一个网桥bridge0，A、B、主机都在一个网段 主机1的虚机A和主机2的虚机C通讯：主机1和主机2用交换机连接，A、C、主机1、主机2都处于同一个网段 网桥与交换机的区别 网络模式之NAT： 同主机的虚机A和虚机B通讯：通过虚拟交换机。A、B通过NAT设备(路由器)与主机通讯，和主机不在一个网段 主机1的虚机A和主机2的虚机C通讯：需要使用overlay方案 主机防火墙的五个关卡： PREROUTING：数据包必过 INPUT：数据包进入主机 FORWARD：转发数据包 OUTPUT：数据包从主机出来 POSTROUTING：数据包必过 主机防火墙的4个规则表优先级高到低：raw –> mangle –> nat –> filter raw，不常用 mangle，修改数据包 nat，网络地址转换，DNAT和SNAT filter，过滤数据包 主机防火墙规则有匹配条件和处理动作组成 链路层匹配条件：源mac、目标mac、vlan_id 链路层处理动作：源mac、目标mac、vlan_id的修改 网络层匹配条件：源ip、目标ip 网络层处理动作：源ip、目标ip的修改 传输层匹配条件：源port、目标port 传输层处理动作：源port、目标port的修改 k8s的kube-proxy就是利用的iptables做流量转发和负载均衡的 service利用nat将相应的流量转发到对应的pod中，另外iptables有一个probability特性，可以设置probability的百分比是多少，从而实现负载均衡 underlay和overlay： underlay是底层网络，由物理网络设备组成 overlay是基于隧道技术实现的，overlay的流量需要跑在underlay之上 overlay的三种技术方案： Calico网络方案 GRE：外层IP头 + GRE头 + 内层IP包，缺点是只能点对点通讯 VXLAN：外层UDP头 + UDP主体(VXLAN头 + 内层IP包)，支持组播(多对多通讯) IPIP：IP in IP，ipip包头较vxlan小，安全性不如vxlan 第7章 容器中的网络 Docker的网络模式默认使用NAT Docker容器与主机的端口映射的两种方式（主机的10080->容器的80）： 主机建立docker-proxy进程，监听10080端口，把网络包转发到容器的80端口 主机建立一条DNAT，把10080的网络包转发到容器的80端口 Flannel项目的UDP模式：主机1的容器A(172.17.8.2)访问主机2的容器B(172.17.9.2) 容器A先发给默认网关，即网桥docker0(172.17.8.1) docker0读取主机1的路由策略，再发给flannel.1网卡 主机1的flanned读取flannel.1网卡的网络包，封装一层UDP头，发给主机2 主机2的flanned收到UDP，解UDP，把原始数据包发给flannel.1网卡 flannel.1读取主机2的路由策略，把包发给docker0，再发给容器B Flannel项目的VXLAN模式： 容器A先发给默认网关，即网桥docker0(172.17.8.1) docker0读取主机1的路由策略，再发给flannel.1网卡(内核建立的VTEP) 主机1的flannel.1根据主机的ARP表、FDB表封装好VXLAN数据包，发给主机2 主机2的flannel.1解VXLAN数据包，把原始数据包发给flannel.1网卡 flannel.1读取主机2的路由策略，把包发给docker0，再发给容器B (主机的route表、ARP表、FDB表由flanneld来维护) Calico项目-主机同网段：纯三层网络 去掉网桥docker0，容器配置路由到主机的网卡 主机的网卡充当路由器功能 主机之间用交换机连接 Calico项目-主机跨网段：IPIP模式 第7章 微服务相关协议 ONE RPC 协议约定：每次改动都要重写生成stub 传输协议：二进制 服务发现：portmapper SOAP(simple object access protocol) 协议约定：服务地址+?wsdl，xml描述文件 传输协议：http + post xml 文本 服务发现：UDDL注册中心 Spring Cloud 协议约定：Restful接口协议 传输协议：http 服务发现：eureka Dubbo 协议约定：Hessian2 传输协议：Netty网络框架 服务发现：各种注册中心如Zookeeper、Redis、Etcd gRPC 协议约定：Protocol Buffers 传输协议：http2.0 服务发现：各种注册中心如Envoy Dubbo和SpringCloud的优缺点 功能：Dubbo只实现了服务治理，而SpringCloud覆盖了微服务架构下的众多部件 性能：Dubbo使用RPC，SpringCloud使用Http Restful，Dubbo略胜 "},"docs/advanced-java.html":{"url":"docs/advanced-java.html","title":"Java工程师进阶知识","keywords":"","body":"Java工程师进阶知识 参考资料 Java工程师进阶知识 消息队列 优点1：解耦，假设功能A完成一个操作后，需要通知BCD，需要考虑失败处理或者部分失败的情况，用MQ就方便多了 优点2：异步，提高接口的响应速度，慢操作可以异步去处理 优点3：消峰，在高峰时缓冲待处理操作，提高吞吐 缺点：多引用了MQ这个组件，多了一个故障点，系统复杂度增加 kafka的高可用性：每个partition有多个replica副本，其中一个副本是leader 写数据：只写leader，当所有的follower都同步了消息后，leader通知生产者写入成功 消费：只读leader，当所有的follower都同步了消息后，这个消息才可见 重复消费问题：消费消息时要保证消息的幂等 RabbitMQ如何不丢消息： 生产者：开启异步confirm模式 MQ：开启镜像集群模式，消息持久化导磁盘 消费者：关闭自动ack，使用手动ack MQ积压了几个小时怎么处理？ 停掉原有consumer程序，上新的consumer程序A把消息消费到新的10倍大小的MQ中 上10倍的consumer程序B来消费新的MQ 处理完挤压数据后，恢复原有的consumer程序 ElasticSearch es写入数据： 1秒后可被搜索：因为数据定时一秒从buffer写入到segment file(即使在os cache也能被搜索) 5秒后可持久化：日志实时从buffer写入到translog，定时5秒执行一次fsync 数十亿级别的数据量优化： 机器的内存至少要能容纳数据量的一半 垂直拆分：es只存储搜索字段，查出id后再去DB查询详细字段 写脚本先把数据预热在cache 冷热分离，冷热数据用不同的index es的表设计：先join好数据了再写入es，减少es的查询复杂度 分页性能优化：使用search_after参数 Redis缓存 redis的过期策略： 定期删除：每100ms随机检查10w个key 惰性删除：请求key的时候判断是否过期 allkey-lru：所有key，最近最少使用 allkey-lfu：所有key，最近访问频次最少 allkey-random：所有key，随机删除 volatile-lru：在设置了过期时间的键空间中，最近最少使用 volatile-lfu：在设置了过期时间的键空间中，最近访问频次最少 volatile-random：在设置了过期时间的键空间中，随机删除 redis的持久化 rdb：fork一个子线程备份，恢复速度快，但是备份大约要5分钟 aof：定时1秒执行fsync，最多丢失1秒数据，恢复速度慢 混合持久化：定时rdb，rdb时间点之后用aof redis集群模式： 哨兵+主从：3个哨兵，1主2从。主节点挂了，哨兵会选择一个新的主节点 cluster：3个主3个备，主节点挂了就换备节点。3个主同时提供读写服务，根据hash槽分配key 缓存穿透、缓存击穿、缓存雪崩 缓存穿透：缓存不存在，请求落到db：设置空缓存 缓存击穿：缓存失效的瞬间请求都落到db：用singleflight保证只有一个线程请求db 缓存雪崩：缓存服务挂了，大量请求落到db：提高缓存服务的可用性，设置降级策略，缓存节点预热后加入集群 Mysql相关 分库分表如何平滑过渡： 所有写操作的地方进行双写：既可老库也写新库 写导数据脚本把老数据导入新库，判断gmt_modified字段避免覆盖新数据 检查新库和老库是否一致，一致后改双写为单写 海量数据处理 两个各320G的文件存储大量URL，4G内存如何找出两者重复的url？ 方案1：A文件、B文件各对url哈希切成320个文件，依次对比A1B1...（把A1存哈希表，遍历B1的url去哈希表查找） 方案2：把A文件的url存进前缀树，遍历B文件的url去前缀树查找 一个1G的文件存储大量单词，1M内存如何找到重复次数最多的单词Top100？ 对单词哈希切成1024个文件，保证每个文件小于1M 依次对小文件进行统计，存储一个map结构的文件，key是单词，value是重复次数 遍历这个map文件，使用一个小顶堆来统计Top100 在2.5亿个整数中找出不重复的整数 使用位图法：假设整数取值范围在2^32，用2b来表示一个数的重复次数：00不存在，01出现一次，10出现多次 计算需要2^32个2b内存，即1GB，若内存够则使用位图法，不够则用分治思路 1000w个字符串，最长255B，1G内存如何查出热门字符串Top10？ 使用前缀树，最后一个节点存储重复次数。最后用小顶堆来计算Top10 如何从5亿个数中找出中位数？ 方案1：用小顶堆存大于中位数的数，用大顶堆存小于中位数的数，5亿*4B≈2GB 方案2：分治法，根据数的最高位分成两堆，中位数在总数多的那一堆，然后根据次高位分成两堆... 有10个1G文件存放用户的query，把它们按照query的频次排序 方案1：内存足够先用map得到query队友的频次，再快排 方案2：遍历这10个文件对query哈希到另10个文件中，再遍历这10个文件到10个map文件，再使用归并排序 有20个数组，每个数组有500个已排序元素，求Top500？ 初始化长度为500的数组 从20个数组取最大数并排序，取最大值放入新数组 取该最大值所在数组的下一个元素，继续上述操作 "},"docs/clean-code.html":{"url":"docs/clean-code.html","title":"整洁代码","keywords":"","body":"整洁代码 第2章 有意义的命名 名副其实：变量、函数、类名应该已经答复了所有的大问题 避免误导：用户组最好用accountGroup而不是accountList 不要用前缀：例如属性m_hasChild、接口IShapeFactory 类名应该是名词或者名称短语：如WikiPage 方法名应该是动词或者动词短语：如DeletePage 每个抽象概念选一个词：如fetch、retrieve、get，固定用get 第3章 函数 函数的行数不要超过20行 每个函数只做一件事 switch语句的示例，违反了单一原则和开闭原则，当需要增加一个新的Employee类型时，需要修改多处代码 零参数函数是最理想的 单参数函数常见的两种情况： 需要询问关于那个参数的问题：如bool fileExists(\"MyFile\") 使用改参数修改系统状态：如void includeSetupPage(pageText) 双参数函数和三参数函数，除非正好是需要平面坐标或者立体坐标这样的需求 函数要么做什么事，要么回答什么事，不可兼得，否则就是做了两件事 使用异常替代返回错误码 新异常可以从异常类派生出来，这样就无需重新编译 第4章 注释 尽量用代码去表达意图而不是注释，因为注释可能没有及时维护 像javadoc对每个变量都添加注释的规则是可笑的，只会让代码更加散乱 能用代码版本控制表达的，就无需在代码里表达，如注释是代码谁写的 注释掉的代码应该直接删除 第5章 格式 变量声明：尽可能的靠近其使用位置 实体变量：即类属性，应该放在类开头 相关函数：a调用b，b调用c，那么a在前，b居中，c在后 概念相关：概念相关的代码应该放在一起 代码一行最多120个字符 第6章 对象和数据结构 对象的定义：充血模型，具有行为的类 数据结构的定义：贫血模型，只带属性的类或者只有函数的聚合 对象和数据结构的优点： 对象：不需要给对象添加新的行为的前提下，添加新的对象 数据结构：不增加新的对象的前提下，添加新的行为 得墨忒耳定律： 模块不应该了解它所操作对象的内部情形 只跟朋友交谈，不和朋友的朋友交谈 第7章 错误 使用异常替代返回错误码 异常的特点： 错误不可忽略，如果忽略将终止程序 happy-path和bad-path容易分离 缺点是破坏了封装性，高层得知道底层可能会抛的异常 错误码的特点 缺点1：由于没有约束，如果没有处理可能出现不可预测的情况 缺点2：主流程中充斥着大量检查错误的代码，代码容易混乱 别返回null值：如getEmployees() []Employee 结果为空不要返回nil，而是空切片，这样就省去了nil判断 别传递null值：因为需要nil判断，不然容易出现运行时错误 第8章 边界 服务提供者追求普适性，这样能吸引广泛的用户 服务使用者则希望满足特定的需求 例如想要在只读的map中实现getSensor(key string) Sensor 可以直接使用map，但是不能防止其他程序对map进行修改 用一个实体类，对外只提供一个getSensor方法 当定义好接口后，对于第三方代码，用适配器模式来包装它 第9章 单元测试 TDD(Test-Driven-Development)三定律 先写单元测试，再写生产代码 单条单元测试没有通过，则编写它，通过后再写下一条单元测试 单条单元测试没有通过，则编写对应的生产代码，通过后再写下一条单元测试 FIRST原则 fast：测试要能快速运行 independent：测试是独立的，能以任何顺序运行，测试之间不应该相互依赖 repeatable：可重复测试 self-validating：测试结果以布尔值输出，而不需要人工检查输出日志 timely：写完生产代码立即编写测试 第10章 类 单一职责原则：类应只有一个职责，只有一条修改的理由，应该尽可能的短小(方法不能太多) 依赖倒置原则：调用者不再依赖具体类，而是依赖具体类的接口 第11章 系统 将构造和使用分离：使用依赖注入 POJO(Plain Ordinary Java Object)：具有一部分getter/setter方法的那种类就可以称作POJO Java Bean：是可复用的组件，具有无参的构造器，还要实现Serializable接口用于实现Bean的持久性 第12章 迭进 软件五个设计规则： 运行所有的测试 不可重复 表达了程序员的意图 尽可能的减少类和方法的数量 第13~16章 跳过 第17章 味道和启发 何时使用静态方法：它并不在特定对象上操作，操作数来自传参 如果不确定是否用静态方法，就用非静态方法 "},"docs/clean-architecture.html":{"url":"docs/clean-architecture.html","title":"整洁架构","keywords":"","body":"整洁架构 第2部分 编程范式 架构整洁之道 3~6章读书笔记 架构整洁之道-03 编程范式-函数式编程 如何评价 Bob 大叔的新书《架构整洁之道》 架构整洁之道, 看这一篇就够了 编程范式不是为程序员提供了更多的能力，而是限制了能力： 结构化编程限制了控制权的直接转移； 面向对象编程限制了控制权的间接转移； 函数式编程限制了赋值； 所谓限制控制权的直接转移，即是限制了goto语句的使用。要求用顺序结构、分支结构、循环结构这三种结构构造出任何程序。好处是方便把大项目拆分成一个个可证伪的组件。 所谓限制控制权的间接转移，即是限制了函数指针的使用。指针的使用，就是代码在原来的流程里不继续执行了，转而去执行别的代码，但具体执行了啥代码你也不知道，你只调了个函数指针或者接口。相对于goto的直接转移，这叫做控制权的间接转移。面向对象编程对于架构的启发最大在于：多态。这使得跨越组件编程变得更安全，同时也是依赖倒置的基础。 函数式编程中的变量不再改变。我们的所有并发程序（多核多线程）的问题，如果没有可变变量，就不再出现了。当然，这是不可能的，我们可以通过将需要修改状态的部分和不需要修改的部分分隔成单独的组件，在不需要修改状态的组件中使用函数式编程，提高系统的稳定性和效率。 第3部分 设计原则 单一职责SRP（Single Responsibility Principle）； 一个模块有且只能对一个角色负责，不是每个模块都只做一件事。 例如一个类既被CTO又被COO调用，COO提出修改需求导致CTO的调用出现bug 开闭原则OCP（Open Closed Principle）； 对扩展开放，对修改关闭 里氏替换LSP（Liskov Substitution Principle）； 父类出现的地方可以用子类进行替换。具体到架构层面，它指导的是接口与其实现方式。 接口隔离ISP（Interface Segregation Principle）； 不依赖任何不需要的方法、类或组件 依赖反转DIP（Dependency Inversion Principle）； 组件之间，接口放在边界的哪边，依赖就指向哪边。 第4部分 组件构建原则 组件的聚合原则 复用发布原则(REP)：只要复用一段代码就把它抽成组件。如何抽组件，需要依据共同封闭原则、共同复用原则。 共同封闭原则(CCP)：为了相同目的而同时修改的类，应该放在同一个组件中。共同封闭原则是组件视角下的单一职责原则。 共同复用原则(CRP)：不要强迫一个组件依赖它不需要的东西。共同复用原则是组件视觉下的接口隔离原则。 组件依赖原则 无循环依赖原则：如果有循环依赖，那么会导致无关组件一起发布，一起部署。 如何处理循环依赖，可以使用依赖倒置原则，解除循环依赖。 稳定依赖原则：组件应该依赖比它更稳定的依赖 不稳定性 = 出向依赖数量 / (入向依赖数量 + 出向依赖数量) 出向依赖指自己依赖外部，入向依赖指外部依赖自己 稳定抽象原则：越抽象，越稳定 抽象程度 = 组件中抽象类和接口的数量 / 组件中类的数量 类型 范式/原则 对类/架构的意义 编程范式(如何组织代码) 结构化编程 拆分不同的函数、模块、组件 面向对象编程 依赖倒置基础 函数式编程 拆分可变和不可变 设计原则(如何组织类) 单一职责 分隔不同角色依赖的代码 开闭原则 指导整体的类设计 里氏替换 指导接口和实现方式 接口隔离 指导接口设计 依赖反转 指导组件间依赖的方向 组件聚合原则(类归入哪些模块) 复用发布原则=开闭原则 指导组件拆分的粒度 共同封闭原则=单一职责 共同复用原则=接口隔离 组件依赖原则(模块相互依赖) 无循环依赖原则 指导分层 稳定依赖原则 指导分层 依赖抽象原则 有利于组件扩展 第5部分 软件架构 什么是组件？组件是一组描述如何将输入转化为输出的策略语句的集合，在同一个组件中，策略的变更原因、时间、层次相同。 架构工作有两个方针： 尽可能长时间地保留尽可能多的可选项(可选项指的是无关紧要的细节设计) 不完全边界能解决的，不要用完全边界；低层次解耦能解决的，不要用高层次解耦。 拆分维度： 变更原因拆分，例如拆分为：订单组件、结算组件、商品组件 层次拆分，例如拆分为：业务实体、用例、接口适配器、框架与驱动程序 把数据作为系统的核心（传统分层架构） 把业务实体作为系统的核心（洋葱架构、DDD架构、六边形架构、干净架构等） 按照读写拆分，演化出了CRQS架构 按照组件是否集中治理，演化出微服务架构、SOA架构 上图有四个分层，依赖方向是业务实体 层次越高，越抽象；越抽象越稳定 低层依赖高层；高层被依赖的组件越多，就越需要稳定 不完全边界能解决的，不要用完全边界；低层次解耦能解决的，不要用高层次解耦。 完全边界包括哪些内容？首先跨越组件边界进行通信的两个类都要抽象为接口，另外需要声明专用的输入输出数据模型，想一想每次进行通信时都要进行的数据模型转换，就能理解维护一个组件边界的成本有多高。 不完全边界有三种方式： 省掉最后一步：声明好接口，做好分割后，仍然放在一个组件中，等到时机成熟时再拆出来独立编译部署。 单向边界：正常的边际至少有两个接口，分别抽象调用方和被调用方。这里只定义一个接口，高层次组件用接口调用低层次组件，而低层次组件直接引用高层次组件的类。 门户模式：控制权的间接转移不用接口和实现去做，而是用门户类去做，用这种方式连接口都不用声明了。 尽量用低层次解耦（成本最低），而层次从低到高依次是： 源码层次：做了接口、类依赖上的解耦，但是放在同一个组件中，通常放在不同的路径下。和不完全边界的省略最后一步一样。 部署层次：拆分为可以独立部署的不同组件，比如iOS的静态库、动态库，真正运行时处于同一台物理机器上，组件之间通常通过函数调用通讯。 服务层次：运行在不同的机器上，通过网络数据包进行通讯。 "},"docs/fenix-architecture.html":{"url":"docs/fenix-architecture.html","title":"凤凰架构","keywords":"","body":"《凤凰架构》 参考资料 《凤凰架构》在线版 第一部分，演进中的架构（架构涉及到哪些标准方案） 1990提出分布式运算环境，以失败告终 受限于机器的硬件条件，不能做到“如同本地调用一般简单透明的”分布式系统 单体系统时代 优点：程序在同一机器同一进程，程序简单高效 缺点1：损失了各个功能模块的自治隔离能力 缺点2：靠希望每一处的代码都尽量可靠、不出错来构建可靠系统 （可靠系统是从“追求尽量不出错”到正视“出错是必然”的观念转变） SOA时代（Service-Oriented Architecture，面向服务的架构） 三个有代表性的架构： 信息孤岛系统：各个系统完全独立（现实是系统之间需要连接） 微内核架构：一个核心模块和若干插件模块（插件模块之间有时也需要连接） 事件驱动架构：一个事件管道和若干个子系统，每个子系统可以订阅和处理自己感兴趣的事件 SOA架构的“更具体”：WSDL发布服务，UDDI注册服务，EBS实现子系统的通讯 SOA架构的“更系统”：SOA不仅关心技术，还关注需求、流程、管理 SOA架构的缺点1：需要精密的流程和理论，只有专业人员才能驾驭 SOA架构的缺点2：很难作为一种广泛普适性的软件架构风格来推广 微服务的九个核心特征，以区别SOA： 围绕业务去构建组织：根据康威定律，如果把同一个产品的功能分在两个团队，将造成沟通成本 分散治理：服务归属于哪个团队，哪个团队就要全权负责 通过服务来实现独立自治的组件：对外提供服务而不是类库 产品化思维 数据去中心化：不同的服务使用独立的数据库 强终端弱管道：服务之间的通讯协议要简单，不像SOAP那样复杂 容错性设计：允许服务出错，同时做好容错性设计 演进式架构：服务是可以被替代的，存在不可替代的服务是架构设计的缺陷 基础设施自动化：减少CI/CD的复杂性 后微服务时代：解决微服务架构问题，从纯软件层面到软硬件一体 无服务时代：后端设施（数据库、消息队列、日志、存储等）和函数 第二部分，架构师的视角（理清分布式系统中新的挑战与应对） 访问远程服务 进程间通讯：管道、信号、信号量、消息队列、共享内存、UnixDomainSocket RPC的三个问题：如何表示数据(JSON/Protocol Buffer)、如何传递数据(SOAP/Http)、如何确定方法(WSDL/JSON-WSP) RPC经历的几个阶段： W3C Web Service：除了SOAP\\WSDL\\UDDI外，还有解决事务、一致性、事件、通知的协议。协议太复杂，对开发者是负担 不再最求大而全，分裂的RPC： 朝着面向对象发展 朝着性能发展：gRPC基于Protocol Buffer和Http2、Thrift是自己的序列化和基于TCP协议 朝着简化发展：JSON-RPC 不仅仅负责调用远程服务，还负责管理远程服务(负载均衡、服务注册、可观察性等等) （分布式系统真的需要RPC来调用本地方法吗？其实只要能提供服务就行了） REST风格的不足和争议： 登录和注销接口：抽象化一个session资源，登录是put、注销是delete 自定义方法：Google的REST常用自定义方法有cancel/batchGet/move/search/undelete 只查询用户的名称：REST默认返回用户的所有字段，实现此功能可以这样users/12?fields=name 批量给1000个用户名加vip前缀：抽象化一个资源VIP-Modify-Task，然后传1000个用户id 购物下单接口：涉及多个资源(用户、订单、库存、积分)的修改，抽象化一个资源来表示这个流程 事务处理之本地事务：靠支持事务的数据源如InnoDB来支持 事务处理之分布式事务 分布式系统中的一致性与共识算法 ACID专注于分布式事务；CAP和BASE是分布式通用理论 2PC用于保证多个数据分片上事务的原子性，Paxos协议用于保证同一个数据在多个副本的一致性，两者是互补关系 2PC的协调者可以通过Paxos协议来选出 2PC和TCC 2PC：准备阶段所有节点写redo日志和加锁，提交阶段所有节点commit(协调者第1个commit) TCC(Try-Confirm-Cancel)：对业务有侵入性，在Try阶段对数据做冻结，Cancel阶段对数据做恢复 透明多级分流系统 浏览器缓存原理，浏览器先检查Cache-Control/Expire，过期则带上If-None-Match/If-Modified-Since请求服务器 域名解析，有TTL缓存时间 传输链路：H2之前使用雪碧图等等；Gzip压缩；使用H2或者H3 内容分发：域名别名指向CDN厂商的glsb；CDN的主动推送或者被动回源 负载均衡之mac层：三角传输(LB和server使用同一虚拟ip)，需在二层网络 负载均衡之ip层： 方案1：三角传输(LB和server使用同一虚拟ip，使用IP隧道)，非二层网络也行 方案2：NAT模式，LB修改dIP把流量转发给server，server需配置网关地址为LB 方案3：SNAT模式，LB修改dIP把流量转发给server(同时修改sIP为LB自己)，好处是server不需要配置网关，坏处是server看不到真实ip 负载均衡之传输层：同ip层，可以根据传输协议(tcp/udp)转发 负载均衡之应用层：nginx、haproxy 服务器缓存：缓存淘汰策略(lru/lfu)，缓存穿透(db记录不存在)、缓存击穿(缓存过期了)、雪崩(db压力陡增) 架构安全性 OAuth2.0授权 授权码模式：需要有自己的应用服务器，与授权服务器交互2次，一次拿授权码，一次拿token 隐式授权模式：不需要有自己的应用服务器，通过授权服务器跳转回的url拿token，例如gtalk 密码模式：用户带用户名密码请求应用服务器，应用服务器带用户名密码请求授权服务器，要求应用服务器、授权服务器属于同一公司 客户端模式：应用服务器直接通过clientId、clientSecret请求授权服务器获得token 凭证：一般用session或者jwt 传输：https 第三部分，分布式的基石（解决分布式问题的思路、方法和工具） 强一致性共识协议： Paxos：任何节点都可以提案，所以需要解决“活锁”问题 Raft：先选主，只有主节点可以提案 最终一致性共识协议Gossip： 并不能和Paxos、Raft算法等价，只能说他们达成的目标是一致的 每个节点收到消息后，把消息同步给和它相邻的若干节点 服务的三个问题： 服务发现：基于kvdb实现、基于CoreDNS、基于框架如Eureka、Consul 网关路由：五种网络IO模型 客户端负载均衡 流量治理之容错策略：故障转移(对调用者透明)、快速失败(调用者控制)、安全失败、沉默失败、故障恢复、并行调用(有一个成功即可)、广播调用(如2PC) 流量治理之容错设计模式：断路器模式(超过阈值拒绝服务)、舱壁隔离模式(每个服务对应一个线程池)、重试模式(要有超时和次数限制) 流量控制之否决式限流：固定窗口、滑动窗口 流量控制之阻塞式限流：漏桶模式(通满就拒绝服务)、令牌桶模式(没有令牌就拒绝服务) 限流:漏桶算法和令牌桶算法 假设两桶都限流80qps，当出现qps大于80时，对于下游的qps漏桶依然保证是80，而令牌桶可短暂高于80 意味着遇到突发流量，漏桶的请求需要排队(不友好)，而令牌桶不用 流量控制之分布式限流： 单机限流适合集群网关处的限流，可以用否决式和阻塞式 分布式限流是控制集群内部服务的：来了一个请求，先从网关处领取X元，访问A服务消耗A元，访问B服务消耗B元，没钱了无法访问服务(或者再找网关要) 可靠通讯：从“边界安全”到“零信任网络” 可靠通讯服务认证的两种方式： 基于istio：可以配置针对某个namespace的所有流量开启mTLS 基于OAuth2.0的客户端模式：clientSecret通过启动参数传给服务 istio还提供终端用户认证和授权： Istio安全架构--理解身份/认证/授权 使用 Istio 进行 JWT 身份验证（充当 API 网关） 可观察性：日志、追踪、聚合 第四部分，不可变基础设施（如何隐藏技术细节使其不会干扰业务） linux的进程隔离(七种)： Mount：隔离文件系统，chroot命令 UTS：隔离主机的hostname IPC：隔离进程间通讯的渠道 PID：无法看到其他namespace的进程 Network：隔离网络，如网卡、网络栈、ip、端口等 User：隔离用户和用户组 Time：支持进程独立设置系统时间 linux的资源隔离：cgroups，隔离cpu、内存、块设备、其他设备、网卡 linux网络虚拟化： 内核控制了四层，提供socket接口给应用层 netfilter框架的5个hook，iptables工具基于框架提供5个表 虚拟网络设备之tun/tap：tun相当于三层，tap相当于二层 物理网卡一端是物理网卡，一端是网络协议栈；虚拟网卡一端是用户态程序，一端是网络协议栈 vpn程序就是利用的tun/tap 虚拟网络设备之veth pair：两个docker容器如果使用veth pair连接，不需要反复进入协议栈 虚拟网络设备之linux bridge：其实就一个虚拟交换机，bridge可以设置ip地址 比普通交换机多一个功能，当bridge接收的数据包mac和ip均是自己，即表示和宿主机通讯 虚拟网络之VXLAN：linux3.7支持 普通数据包=mac头+原始二层内容，VXLAN数据包=outer数据包(udp+vxlan)+原始二层内容 虚拟网络之MACVLAN：一个网卡可以设置多个ip、多个mac 容器间通讯： 开箱即用的方案：bridge、host、none 用户自定义方案：container、MACVLAN、overlay(即VXLAN) 容器网络接口：docker提出的CNM落败，google提出的CNI胜出 容器网络插件： Overlay模式：Flannel的VXLAN，Calico的IPIP 路由模式：Flannel的hostGW，Calico的BGP Underlay模式：MACVLAN、SR-IOV。 依赖硬件和底层网络环境，难以做到像Overlay那样开箱即用 静态存储分配：运维预置好pv，开发声明pvc，k8s进行匹配 动态存储分配：运维预置好sc，开发声明pvc和关联的sc，k8s通过sc生成pv再和pvc绑定 容器存储接口：FlexVolume已经废弃，CSI胜出 容器存储插件：从in-tree到out-tree 资源与调度： 资源模型：一切皆为资源是声明式API的必要前提，资源分为物理资源(cpu、内存、存储)和抽象资源 服务质量和优先级： Guaranteed：requests=limits、 BurstAble：requests BestEffort：没有设置requests和limits 默认调度器： 调度器并不会直接与kubelet通讯来创建Pod，而是间接借助etcd 这些Informer持续监视etcd中它关心的资源变化，一旦发生变化，就更新调度队列 Scheduler从调度队列中取任务并执行 istio代理注入：对namespace设置了istio-injection=enabled标签的pod注入sidecar istio流量劫持： Service Mesh中的iptables流量劫持 istio学习笔记 - 1 （初探数据平面） Istio中的透明代理问题 Istio对入站流量的两种拦截模式：REDIRECT(envoy和应用看到的都是127.0.0.1)、TPROXY(envoy能看到真实ip，应用看到的是127.0.0.1) istio可靠通讯：把代理转发的行为规则抽象成三种资源：Listener、Cluster、Router 服务网格之数据平面：都是CNCF成员：envoy、Linkerd 2、MOSN(蚂蚁金服) 服务网格之控制平面：微软的OSM(使用envoy)，谷歌的istio(没有加入CNCF) 第五部分，技术方法论（软件开发过程中的一些经验） 选择微服务的驱动力： 需要支持多种异构语言 技术专家带领大量普通开发者，使用微服务保证局部的容错、自愈与快速迭代 来自甲方的约束 快速发展的新业务，微服务可以保证快速迭代 历史包袱沉重的大项目，借助微服务进行拆分 使用微服务的前提条件： 根据康威定律的“系统的架构趋同于组织的沟通结构”，先要做好政治工作 组织中需要有微服务的技术专家 微服务化的目标是构建具有自治、自愈能力的基础设施生态 简单系统使用单体架构，复杂系统则用微服务 微服务的粒度： 一个微服务最少要有完备的CI/CD流程，且业务是完整和内聚的。 两个披萨原则：团队6~10人 系统复杂型两个来源： 认知负荷：蚂蚁族群和国家的人口可能一样多，但是治理国家更困难 协作成本：完成任务需要的沟通成本、管理成本 微服务的认知负荷较高，但是协作成本较低（对比单体系统，服务只依赖它需要的服务）。 "},"docs/bpf-performance-tools.html":{"url":"docs/bpf-performance-tools.html","title":"BPF之巅","keywords":"","body":"BPF之巅 参考资料 BPF之巅 bpftrace和Go语言 BPF学习路径总结 eBPF 与 Go 超能力组合 IO Visor 项目开源的 BCC、 BPFTrace 和 Kubectl-Trace： BCC 提供了更高阶的抽象，可以让用户采用 Python、C++ 和 Lua 等高级语言快速开发 BPF 程序； BPFTrace 采用类似于 awk 语言快速编写 eBPF 程序； Kubectl-Trace 则提供了在 kubernetes 集群中使用 BPF 程序调试的方便操作； CloudFlare 公司开源的 eBPF Exporter 和 bpf-tools： eBPF Exporter 将 eBPF 技术与监控 Prometheus 紧密结合起来； bpf-tools 可用于网络问题分析和排查； 纯C写的bpf程序 Write eBPF program in pure C 1，在ubuntu 22.04安装环境 echo -e 'HostKeyAlgorithms ssh-rsa,ssh-dss\\nPubkeyAcceptedKeyTypes ssh-rsa,ssh-dss' >> /etc/ssh/sshd_config systemctl restart sshd apt-get install -y make clang llvm libelf-dev libbpf-dev bpfcc-tools libbpfcc-dev linux-tools-$(uname -r) linux-headers-$(uname -r) 2，把下面c程序贬义词bpf指令程序：clang -I/usr/src/linux-aws-headers-5.15.0-1022/include -O2 -c -target bpf -o mybpfobject.o mybpfcode.bpf.c #include #include \"bpf/bpf_helpers.h\" int bpf_prog(void *ctx) { char buf[] = \"Hello World!\\n\"; bpf_trace_printk(buf, sizeof(buf)); return 0; } （如果报错asm/types.h file not found则安装apt-get install -y gcc-multilib） 3，把bpf指令程序的纯指令提取出来：dd if=mybpfobject.o of=test_bpf bs=1 count=104 skip=64 4，用clang编译c程序：../bpf/test_bpf.c 5，运行a.out，它将捕获bpf的系统调用，如何查看：cat /sys/kernel/debug/tracing/trace_pipe BPF命令 辅助函数 映射类型 程序类型 06 | 事件触发：各类 eBPF 程序的触发机制及其应用场景 全部类型：bpftool feature probe | grep program_type。可分为三类： 一，跟踪类，常用类型见表格 二，网络类 XDP程序，常用类型见表格 TC程序，类型有BPF_PROG_TYPE_SCHED_CLS、BPF_PROG_TYPE_SCHED_ACT 套接字程序，常用类型见表格 cgroup程序，常用类型见表格 三，其他类，常用类型见表格 内核跟踪 // 如果/sys/kernel/debug目录不存在，执行 sudo mount -t debugfs debugfs /sys/kernel/debug // 查看可kprobe跟踪的内核函数 cat /sys/kernel/debug/tracing/available_filter_functions | wc -l bpftrace -l 'kprobe:*' | wc -l // 查看tracepoint可跟踪的syscall函数 cat /sys/kernel/debug/tracing/available_events |grep syscalls:|wc -l bpftrace -l 'tracepoint:syscalls:*' | wc -l // 查看系统调用execeve的传参 cat /sys/kernel/debug/tracing/events/syscalls/sys_enter_execve/format // 不推荐 bpftrace -lv tracepoint:syscalls:sys_enter_execve // 查看系统调用execeve的返回值 cat /sys/kernel/debug/tracing/events/syscalls/sys_exit_execve/format // 不推荐 bpftrace -lv tracepoint:syscalls:sys_exit_execve 开发BPF程序的三种方式： bpftrace：依赖BCC BCC：依赖LLVM和内核头文件 libbpf：要求内核>=5.2，并开启BTF特性(RHEL 8.2+和Ubuntu 20.10+)，是否有/sys/kernel/btf/vmlinux // 查询调用execve的进程id和名称，以及传参argv bpftrace -e 'tracepoint:syscalls:sys_enter_execve,tracepoint: { printf(\"%-6d %-8s\", pid, comm); join(args->argv);}' 如何开发一个负载均衡器 高性能网络实战（上）：如何开发一个负载均衡器？ // 将两个 eBPF 程序和映射加载到内核中，并固定到 BPF 文件系统中。 // 固定到 BPF 文件系统的好处是，即便 bpftool 命令已经执行结束，eBPF 程序还会继续在内核中运行。 bpftool prog load sockops.bpf.o /sys/fs/bpf/sockops type sockops pinmaps /sys/fs/bpf bpftool prog load sockredir.bpf.o /sys/fs/bpf/sockredir type sk_msg map name sock_ops_map pinned /sys/fs/bpf/sock_ops_map // 把 sockops 程序挂载到 cgroups bpftool cgroup attach /sys/fs/cgroup/ sock_ops pinned /sys/fs/bpf/sockops bpftool prog attach pinned /sys/fs/bpf/sockredir msg_verdict pinned /sys/fs/bpf/sock_ops_map sockops 程序类型是 sock_ops；sockredir 程序类型是 sk_msg sockops 挂载类型是 cgroup； sockredir 挂载类型是 msg_verdict 追踪go程序的调用栈 // 例如需要追踪net.Listen(\"tcp\", \":6380\")的调用栈，假设执行文件是test // 下面的命令会显示net.socket的上游调用链，它的上游有net.Listen bpftrace -e 'uprobe:./test:net.socket {printf(\"%s\\n\", ustack); }' -c ./test // 如果调用栈只显示了内存地址，则可以用addr2line转换 bpftrace -e 'uprobe:./test:net.socket {printf(\"%s\\n\", ustack); }' -c ./test | addr2line -e ./test -f -p BPF之巅的学习 BPF之巅的学习--追踪系统历史与相关技术 1. BPF的前端 Linux4.15后可以通过bpftool来查看和操作BPF对象 Linux4.17以后BCC和bpftrace都会使用perf_event_open()进行BPF程序的挂载 2. BPF的辅助函数 bpf_probe_read() 用于访问BPF之外的内存空间, 这个函数会进行安全检查并且禁止缺页中断的发生以保证probe上文中不会引发内核错误 x86上内核空间和用户空间没有重叠, 故通过地址读取不会存在问题. 而在SPARC上, 则必须通过bpf_probe_read_kernel()和bpf_probe_read_user()来区别使用 3. BPF并发控制 Linux5.1中增加了spin lock(bpf_spin_lock和bpf_spin_unlock)来确保并发一致性. 之前的版本则需要通过per-CPU的映射表来绕过并发问题. 其并发读写映射表的问题被成为“丢失的更新”问题. BPF_XADD(互斥加操作), 映射中的映射机制等都可保证原子操作. bpf_map_update_elem对常规的hash和LRU map的操作也是原子的. 4. BTF和BPF CO-RE BPF Type Format, 元数据格式, 可以内嵌到vmlinux的二进制中, 使得可以方便获得被跟踪的源代码信息. BPF CO-RE是一次编译到处运行的意思, 旨在将BPF一次性编译位字节码分发执行. 5. BPF的限制 内核中无限循环是不允许的. 解决办法包括循环展开 BPF栈大小不能超过MAX_BPF_STACK限制, 值为512. BPF指令的总数据量早期为4096, 5.2以后限制为100万. 6. 调用栈回溯 a. 基于帧指针的回溯，gcc默认不启用, 需要通过-fno-omit-frame-pointer开启. BPF支持. b. 调试信息debug info. DWARF格式的ELF调试信息, 通过.eh_frame和.debug_frame的ELF文件段提供. BPF不支持. BCC和bpftrace支持 c. 最后分支记录LBR. Intel处理器的特性, 支持有限深度的回溯4-32个. BPF不支持. d. ORC调试格式信息. 相比DWARF对处理器要求低, 使用.orc_unwind和.orc_unwind_ip的ELF段. BPF目前只支持内核态 7. kprobe插桩 插桩原理参考文章[自己动手写一个GDB](https://cloud.tencent.com/developer/article/2004708) 如果小于5字节，用int3指令；否则用jmp指令，技术称为蹦床函数，性能比int3好 3种接口可访问kprobes: a. 辅助函数, register_kprobes()等 b. 基于Ftrace的, 通过/sys/kernel/debug/tracing/kprobe_events写入字符串可起停kprobes c. 通过perf_event_open(), 与perf工具一样 8. uprobe插桩 2种接口: a. 基于Ftrace的. 通过/sys/kernel/debug/tracing/uprobe_events写入字符串可起停uprobes b. 通过perf_event_open(), 与perf工具一样, 4.17以上版本支持. 9. tracepoints 跟踪点格式: “子系统:事件名”, 如sched:context_switch. BCC中可以通过BPF.tracepoint_exists来测试是否存在某个追踪点. 原始跟踪点: BPF_RAW_TRACEPOINT, 向跟踪点暴露原始参数, 避免创建跟踪点参数的开销. 其性能要好于kprobes 工作原理参考文章[认识数据源：Tracepoint](https://www.iserica.com/posts/brief-intro-for-tracepoint/) 10. USDT 可通过readelf -n来查看目标文件的USDT探针以及获得二进制的偏移量. 原理：编译时使用nop, 激活后被修改为int3. 触发后内核会执行中断响应触发BPF程序. 符号和调试信息 Linux tracing/profiling 基础：符号表、调用栈、perf/bpftrace 示例等 Practical Linux tracing ( Part 1/5) : symbols, debug symbols and stack unwinding "},"docs/linear-algebra.html":{"url":"docs/linear-algebra.html","title":"线性代数","keywords":"","body":"线性代数 span {display:inline-block;vertical-align:middle;} sup, sub {font-size:0.6em !important;} span sup, span sub {position:relative;display:block;line-height:0.2em;text-align:center;} over {text-decoration:overline} 参考资料 数学符号及读法大全 1 introduction to vectors 2 Solving Linear Equations 线性代数 - Machine Learning 线性相关：一个向量能被向量组的其他成员线性组合出来；线性无关则不能。 基的定义：向量组中的向量互相线性无关，张成空间V，则它们是空间V的一组基。 选定基之后，向量表示对象，矩阵表示对象的运动，矩阵与向量相乘得到新的向量。一旦理解了这点，线性代数之后的各个主题，包括矩阵乘法、基变换、特征值等都会非常直观易懂。 旋转矩阵：例如二维矩阵，可以将二维向量按角度旋转，见二维旋转矩阵与向量旋转 变换矩阵：坐标系xyz中的向量v，坐标系XYZ中的向量V，存在变换矩阵R使得V = R * v 剪切矩阵：变换矩阵中的一种，例如把正方形往一边挤压，使之成为平行四边形。 线性方程组（Ax=b）求解的两种方法： 高斯消元：先得到Ux=b*，再求解出x LU分解：先由A得到LU，再由Ly=b求解y，再由Ux=y求解x （两者的时间复杂度都是n3，但在A不变的情况下，LU分解的第2、3步只需要n2） 求A的逆矩阵：将 [A I] 逐步消元成 [I A-1] 3 Vector Spaces and Subspaces 子空间：子空间任意两个向量v和w，它们的线性组合仍然在子空间内。 原点是R3的子空间 过原点的直线是R3的子空间 过原点的平面是R3的子空间 四个基本子空间： 列空间：矩阵A的列空间C(A)是其列向量的所有线性组合所构成的空间。 零空间：矩阵A的零空间N(A)是指满足Ax=0的所有解的集合(所有x的集合)。 行空间：矩阵A的行空间C(A)是其行向量的所有线性组合所构成的空间。 左零空间：矩阵AT的零空间，即是矩阵A的左零空间。 （对于mxn矩阵，列空间为Rm的子空间，零空间为Rn空间的子空间） 求解Ax=0，参考【线性代数】矩阵的零空间 A消元成U后，有r个主元列，n-r个自由列 U继续消元成新矩阵：|I F0 0|。 零空间（最终的解）：|-FI|。有列交换则要注意还原 （A的列空间的维度是r，零空间的维度是n-r） 求解Ax=b，假设有r个主元列 r=n=m：R=I，唯一解 r=n：R=|I0|，唯一解或无解 r=m：R=(I 0)，无穷多解 r：R=|I F0 0|，无穷多解或无解 4 Orthogonality(正交) 正交向量：若向量x和y正交，则xTy=yTx=0，xy默认是列向量 零向量与所有向量都正交 正交子空间：子空间S与子空间T正交，则S中的任意一个向量都和T中的任意向量正交。 0空间和过原点的直线正交； 经过原点的两条直线若夹角为直角则互相正交。 矩阵的行空间的和零空间正交 （一个空间中正交子空间的维数之和不可能超过原空间的维数） 在R3空间内，A的列空间是一个平面，向量b在此平面的投影是p 投影矩阵P=A(ATA)-1AT 若A的列向量线性无关时，矩阵ATA为可逆矩阵。 求b=C+Dt的四种求解思路： 从几何上讨论求解：直线上有三个点p1、p2、p3离原始三个点最近，根据p1、p2、p3来求C、D 最小二乘法矩阵法：向量b投影到矩阵A的列空间得到向量p，投影到矩阵零空间则是e 最小二乘法代数法：e12+e22+e32表示三个点最小误差的平方和，C代码实现 梯度下降法，见机器学习——最小二乘法 标准正交矩阵：列向量为标准正交向量 什么是标准正交向量？向量长度都是1，且彼此正交 正交矩阵：必须是标准正交矩阵，必须是方阵。(正交矩阵是可逆矩阵) 如何推导P=Q(QTQ)-1QT b向量在空间A的投影是p，b-p=e，e垂直于A，存在投影矩阵P使得p=Pb 所以有AT(b-Ax)=0，得到ATAx=ATb 两侧都左乘(ATA)-1，得到x=(ATA)-1ATb p=Ax，所以p=A(ATA)-1ATb p=Pb，所以P=A(ATA)-1AT 如何简化P=Q(QTQ)-1QT Q为可逆矩阵：P=QQ-1(QT)-1QT，P=I Q为标准正交矩阵：所以有QTQ=I，进而P=QQT 施密特正交化： 三阶矩阵的列向量a、b、c变成标准正交向量A、B、C A = a B = b-xA = b-(ATA)-1ATbA C = c-xA-yB = c-(ATA)-1ATcA-(BTB)-1BTcB 最后ABC除以自身的向量长度得到标准正交向量A、B、C 5 Determinants(行列式) 行列式十条性质(只针对方阵) det(I)=1 行交换后，行列式会反号 以二阶方阵为例： a，若某行乘以t则行列式也要乘t b，其中一行不变，另一行可根据加法结合律拆分为两个矩阵 若存在相同的行，则行列式为0(性质2可推导) 某行减另一行的t倍，行列式不变(性质3、4可推导) 某行是零向量，则行列式为0(性质3可推导) 三角阵的行列式等于对角线数值的乘积(包含上三角和下三角) 有且仅当矩阵不可逆时，行列式为0 det(AB)=det(A)*det(B) det(AT)=det(A) 行列式公式：∑n!±a1αa2β...anω 表示n阶方阵中，行列式等于n!个矩阵的行列式之和 其中列标号（α, β, ...ω）是列标号（1, 2, ...n）的某个排列 代数余子式：det(A)=a11C11+a12C12+...a1nC1n 对于aij而言，Cij就是它的代数余子式 Cij表示去掉aij的所在行和列得到的新矩阵的行列式*(-1)i+j （Cij在i+j为偶数时为正，奇数时为负数。） 行列式计算的三种方法： 通过消元得到主元，计算简单 通过行列式公式计算，计算复杂 通过代数余子式计算，计算适中 如何计算可逆矩阵的逆矩阵 高斯消元法：将 [A I] 逐步消元成 [I A-1] LU分解法：根据 A=LU 算出 A-1=U-1L-1 QR分解法：根据 A=QR 算出 A-1=R-1Q-1 代数余子式：A-1=CT/det(A) 特征值分解：A=SΛS-1，A只能是方阵，S是A的特征向量(线性无关) 奇异值分解：A=U∑VT，A可以是任意矩阵 如何证明A-1=CT/det(A) 两边都左乘A，得到ACT=det(A)I，继续证明这个等式 可以发现ACT对角线都是det(A)，非对角线都是0，所以可证。 克莱姆法则：求解Ax=b x=A-1b=CTb/det(A) xj=det(Bj)/det(A)，Bj表示矩阵A的第j列用b代替 （克莱姆法则求解效率低，中看不中用） det(A)=矩阵A构成的几何体的体积 单位矩阵：不管是几阶矩阵，体积都是1 正交矩阵：边长为1，且边相互垂直，体积都是1 6 Eigenvalues and Eigenvectors(特征值和特征向量) 矩阵的迹：矩阵主对角线元素之和。 特征值和特征向量(只针对方阵) 若存在Ax=λx，则λ是特征值，x是特征向量(特征值可为0，特征向量不能是零向量) 任意n阶矩阵有n个特征值(特征值可相同)。 任意n阶矩阵的n个特征值之和等于矩阵的迹。 任意n阶矩阵与它的转置矩阵特征值相同，特征向量可能不同。 三角阵的特征值就是对角线上的元素(包含上三角和下三角) 例1：对于投影矩阵P，它的投影平面和垂直于平面的向量都是特征向量 例2：矩阵A|0 11 0|，特征向量是(1 1)和(1 -1) 例3：矩阵A|3 10 3|，特征向量是(1 0)和(1 0)，A是退化矩阵 如果矩阵A可逆 A的行列式=A的所有特征值的乘积 A-1的特征值是A特征值的倒数 复数特征值 |1 11 1|的特征值是两个复数：i、-i 求解特征值和特征向量：先根据det(A-λI)=0求解出λ，再求A-λI的零空间 det(A-λI)=0的论证如下： 由于Ax=λx，可得Ax-λx=0，可得Ax-λIx=0，可得(A-λI)x=0 由于x不能是零向量可得A-λI是奇异矩阵，可得det(A-λI)=0 假设A为二阶方阵，由det(A-λI)=0可得特征值λ1、λ2，真题 则A的特征向量在A-λ1I和A-λ2I的零空间中 假设t为标量，A+tI的特征向量和A相同，特征值全部加t。 可对角化： 假设矩阵A的n个特征向量组成S，存在S-1AS=Λ，则表示A可对角化 如果矩阵A可对角化，则A必定存在n个线性无关的特征向量，反过来也成立 如何证明A=SΛS-1（前提是A是可对角化的） 假设矩阵A的n个特征向量组成S，则AS=A|x1 x2 ... xn| 则有AS=|Ax1 Ax2 ... Axn| 则有AS=|λ1x1 λ2x2 ... λnxn| 则有AS=S|λ1 λ2 ... λn组成的对角阵| 则有AS=SΛ，Λ是由λ1 λ2 ... λn组成的对角阵 两边左乘S-1，得到S-1AS=Λ 两边右乘S-1，得到A=SΛS-1 矩阵的幂 Ak和A的特征向量相同，特征值是λk 已知A求Ak：Ak=SΛkS-1 重特征值 A的特征值都不同，则特征向量都线性无关 A的特征值有相同，则特征向量不一定线性无关 差分方程：假设uk+1=Auk，A是可对角化的 因为A可对角化，则它存在n个线性无关的特征向量，它们可以组成S 假设u0=SC，其中由A可以求出S，SC=u0可以求出向量C 则有uk=Aku0=AkSC=SΛkS-1SC 则有uk=SΛkC 则有uk=|λk1x1 λk2x2 ... λknxn|C（S左乘对角阵Λ，即Λ的对角元素作用于S每一列） 则有uk=c1λk1x1 + c2λk2x2 + ... + cnλknxn 斐波那契数列：Fk+2=Fk+1+Fk 假定向量uk=|Fk+2Fk+1|，则uk+1=Auk，其中A=|1 11 0| 则有u0=|10|，uk=Aku0 第25讲 Symmetric Matrices(对称矩阵) 性质1：A=AT 性质2：A不一定可逆，例如|1 11 1| 性质3：A如果是实对称矩阵(元素都是实数)，则A存在n个彼此正交的特征向量 性质4：A如果是实对称矩阵，A=QΛQT，Q是由特征向量矩阵变的正交矩阵 性质5：A如果是实对称矩阵，则特征值都是实数并且正负个数和主元的正负数相等 特征值的乘积等于矩阵的行列式 主元的乘积等于矩阵的行列式 第27讲 Positive definite matrix(正定矩阵) 正定矩阵：对称矩阵满足一下任意一条即可： 特征值都是正数 主元都是正数 所有子行列式都是正数 xTAx>0（x=0除外） （任意一条可以推导出其他条） |2 62 y|，若y>18则是正定矩阵，y 7 The Singular Value Decomposition(奇异值分解) 第29讲 奇异值分解公式：A=U∑VT，其中UV是正交矩阵，∑是对角矩阵 奇异值分解：A可以是任意矩阵，不一定是方阵 实对称矩阵：A=QΛQT 可对角化矩阵：A=SΛS-1 奇异值分解步骤：A=|4 4-3 3| （假设B=ATA，则B是对称矩阵，因而B=QΛQT，见证明） 由ATA=V∑2VT，可求出∑、V 由AAT=U∑2UT，可求出∑、U 通常不用上一步来求解U，因为可能和∑顺序不匹配，而是通过AV=U∑求解U 8 Linear Transformations(线性变换) 第30讲 线性变换符合如下规则：对于任意向量v、w和标量c T(v+w)=T(v)+T(w)，加法不变性 T(cv)=cT(v)，数乘不变性 反例1：原点不变，沿x轴平移目标，例如向量v(1,1)变成(2,1) T(2v)=(3,2) 2T(v)=(4,2)，两者不相等，因此不是线性变换 反例2：T(v)=||v||，表示求v的长度 若c为正数，例如T(5v)=5*||v|| 若c为负数，例如T(-3v)!=-3*||v||，因此不是线性变换 正例1：将向量投影 正例2：矩阵乘法 正例3：矩阵乘法之将三阶矩阵变成两阶： 原始向量(c1 c2 c3)，矩阵A是|0 1 00 0 2| 转换后得(c2 2*c3) 第28讲 相似矩阵：对应n阶矩阵A、B，存在可逆矩阵M使得B=M-1AM 例如A=|2 11 2|，所有特征值是3、1的矩阵都是A的相似矩阵 若A有重特征值，则可能无法对角化(特征向量不是线性无关) 若A=|4 00 4|，则相似矩阵只有自己 若A=|4 10 4|，则没有相似矩阵 若尔当块： 若主对角线元素都不同，则其他元素都是0 若主对角线元素都相同，则除了它上一排的对角线元素都是1外，其他元素都是0 若尔当标准型：对角线是若干个若尔当块组成的 9 Complex Vectors and Matrices(复向量和矩阵) 第26讲 Complex Numbers(复数) 共轭复数：实部相等，虚部相反。例如λ=a+bi、λ=a-bi 复向量的长度|z|2=zTz。例如|1i|2=[1 -i][1i]=2 Hermitian and Unitary Matrices(厄米矩阵和酉矩阵) A的转置共轭矩阵AT，可以记作AH 厄米矩阵：满足AT=A，例如|2 3+i3-i 5| 厄米矩阵的性质1：特征值都是实数 厄米矩阵的性质2：若特征值不同，则特征向量正交 厄米矩阵的性质3：主对角线元素都是实数（如果不是实数无法满足AT=A） （实数对称矩阵也是厄米矩阵，可以看作元素虚部都是0） 复数向量标准正交，则qTjqk = {0 j≠k1 j=k 酉矩阵：满足QTQ = I = QHQ 酉矩阵的性质1：Q-1 = QH 酉矩阵的性质2：Q-1也是酉矩阵 酉矩阵的性质3：det(A)=1 The Fast Fourier Transform(快速傅里叶变换) 10 Applications(应用) 第31讲 Graphs and Networks(图形和网络) 第24讲 Markov Matrices, Fourier Series(马尔可夫矩阵、傅立叶级数) 矩阵的方幂运算能达到稳态的两个条件： λ1=1是特征值之一 其它特征值的绝对值都比1小 矩阵的方幂运算能达到稳态的证明： 由于uk=c1λk1x1 + c2λk2x2 + ... + cnλknxn 而λ1之外的特征值都比1小，随着k的增大，λk趋向于0 所以uk最终趋向于c1x1 马尔可夫矩阵：任何元素非负，且每列的元素之和为1的矩阵 马尔可夫矩阵符合方幂运算能达到稳态的条件 马尔可夫矩阵与人口流动问题： u0=|01000|，表示城市1人口是0，城市2是1000 uk+1=|0.9 0.20.1 0.8|uk 经过k次人口流动后：uk=c1λk1x1 + c2λk2x2 解得：λ1=1，λ2=0.7 解得：x1=|21|，x2=|-11| 由于u0=SC，解得c1=1000/3，c2=2000/3 最终uk会稳定在|2000/31000/3| 通俗易懂的傅里叶级数和傅里叶变换(一) 傅里叶系列（一）傅里叶级数的推导 11 Numerical Linear Algebra(数值线性代数) Gaussian Elimination in Practice Norms and Condition Numbers(标准和条件值) Iterative Methods and Pre conditioners(迭代方法和预条件) 12 Linear Algebra in Probability & Statistics(概率统计中的线性代数) Mean, Variance, and Probability(均值、方差和概率) Covariance Matrices and Joint Probabilities(协方差矩阵与联合概率) Multivariate Gaussian and Weighted Least Squares(多元高斯和加权最小二乘) "},"docs/highlights-of-calculus.html":{"url":"docs/highlights-of-calculus.html","title":"微积分重点","keywords":"","body":"微积分重点 MathJax = { tex: { inlineMath: [['$', '$'], ['\\\\(', '\\\\)']], displayMath: [[\"$$\", \"$$\"], [\"\\\\[\", \"\\\\]\"]], }, svg: { fontCache: 'global' } }; 参考资料 如果要认真学微积分，其实应该学MIT的1801和1802，但是两门课加起来有70节课，所以选择了本课，本课主要涉及单变量微积分。 LaTeX公式手册(全网最全) 学习笔记1 学习笔记2 课程笔记1 自然常数e：e = 2.718... $(1 + \\frac{1}{x})^x$无限趋近于e P2.三个重要函数的斜率 $y = x^n \\quad=> \\frac{dy}{dx} = nx^{n-1}$ $y = \\sin x => \\frac{dy}{dx} = \\cos x$ $y = e^x \\quad=> \\frac{dy}{dx} = e^x$ P3.极值和二阶导数 一阶导数可以找到极值，二阶导数告知它是极大值还是极小值 例：$y = x^2 \\quad\\quad=> y' = 2x \\quad\\quad\\quad=> y'' = 2 $ 例：$y = \\sin x \\quad=> y' = \\cos x \\quad\\quad=> y'' = -\\sin x $ 例：$y = x^3 - x^2 => y' = 3x^2 - 2x => y'' = 6x -2 $ P4.指数函数 $e = (1 + \\frac{1}{x})^x$。在银行存￥1，年利率100%，求一年后的复利 假设一年计息4次，最后本息是$(1 + \\frac{1}{4})^4$ 假设一年计息x次，最后的本息无限趋近于e 课程笔记2 P5.积分总览 求积分的方法A：例如知道2x的导数是2，则已知导数2就可以反推 求积分的方法B：函数一y的值 = 函数二的面积 P6.求sinx和cosx的导数 $f'(\\sin x)=\\cos x$ $f'(\\cos x)=\\lim\\limits_{\\Delta x \\to 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x}$ $\\quad\\quad\\quad\\quad=\\lim\\limits_{\\Delta x \\to 0} \\frac{\\cos(x+\\Delta x)-\\cos x}{\\Delta x}$ $\\quad\\quad\\quad\\quad=\\lim\\limits_{\\Delta x \\to 0} \\frac{\\cos x\\cos\\Delta x-\\sin x\\sin \\Delta x-\\cos x}{\\Delta x}$ $\\quad\\quad\\quad\\quad=\\lim\\limits_{\\Delta x \\to 0} \\frac{\\cos x(\\cos\\Delta x-1)-\\sin x\\sin \\Delta x}{\\Delta x}$ $\\quad\\quad\\quad\\quad=\\lim\\limits_{\\Delta x \\to 0} \\left[\\cos x\\frac{(\\cos\\Delta x-1)}{\\Delta x}-\\sin x\\frac{\\sin \\Delta x}{\\Delta x}\\right]$ $\\quad\\quad\\quad\\quad=\\cos x\\cdot0-\\sin x\\cdot1$ $\\quad\\quad\\quad\\quad=-\\sin x$ P7.乘法法则和除法法则 $(f + g)' = f' + g'$ $(f - g)' = f' - g'$ $(f * g)' = f'g + g'f$ $(f / g)' = \\frac{f'g - g'f}{g^2}$ P8.链式法则：$z = f(y) \\quad y = g(x) => \\frac{dz}{dx} = \\frac{dz}{dy} \\frac{dy}{dx}$ P9.极限和连续 四种极限的特殊情况： $a_n - b_n$：∞ - ∞ $a_n * b_n$：0 * ∞ $a_n / b_n$：0 / 0 或者 ∞ / ∞ $(a_n)^{b_n}$：0 ^ 0 或者 1 ^ ∞ 函数连续性的定义：对于任意的ϵ > 0，存在δ > 0，如果∣x − a∣ P10.逆函数和对数函数 逆函数：y=f(x)的逆函数是x=f−1(y) 例1：$y=x^2 \\quad=> x=\\sqrt{y}$ 例2：$A=πr^2 \\; => r=\\sqrt{\\frac{A}{π}} $ 例3：$y=e^x \\quad=> x=\\ln y$ 对数函数 性质1：$\\ln (AB) = \\ln A + \\ln B$ 性质2：$\\ln (y^n) = n\\ln y$ P11.对数函数和反三角函数的导数 对数函数：$\\frac{d}{dx} (\\ln x) = \\frac{1}{x}$，推导如下： $x=ln y$的构造函数：$y=e^x => y=e^{\\ln y}$，两边分别求导可得 $1 = \\frac{d}{dy} (e^{\\ln y})$ $e^{\\ln y} \\frac{d}{dy} (\\ln y) = 1$ $y \\frac{d}{dy} (\\ln y) = 1$ $\\frac{d}{dy} (\\ln y) = \\frac{1}{y}$ 反三角函数1：$\\frac{d}{dx}(\\sin^{-1}x)=\\frac{1}{\\sqrt{1-x^2}}$，推导如下： $x = \\sin^{-1}y$的构造函数：$y = \\sin x => y = \\sin(\\sin^{-1}y)$，两边分别求导可得 $1 = \\cos(\\sin^{-1}y) \\frac{d}{dy} \\sin^{-1}y $ $1 = \\sqrt{1-y^2} \\frac{d}{dy} \\sin^{-1}y $ $\\frac{d}{dy}(\\sin^{-1}y)=\\frac{1}{\\sqrt{1-y^2}}$ （证明$\\cos(\\sin^{-1}y) = \\sqrt{1-y^2}$） $(\\sin θ)^2 + (\\cos θ)^2 = 1$，令sinθ=y，则cosθ=cos(sin-1y) 可得：$\\cos(\\sin^{-1}y) = \\sqrt{1-y^2}$ 反三角函数2：$\\frac{d}{dx}(\\cos^{-1}x)=-\\frac{1}{\\sqrt{1-x^2}}$ 课程笔记3 P12.增长率和对数图 y=x1.5，两边同时求对：log y=1.5 * log x 对数图：x轴是log x，y轴是log y，是一条直线 y=B * 10cx，两边同时求对：log y=log B + cx 对数图：x轴是x，y轴是log y，是一条直线 P13.线性近似和牛顿法 线性近似：假设选定一个x，求f(x)的值 $f'(a) ≈ \\frac{f(x) - f(a)}{x - a}$，a为x附近的一个点 例如：求$\\sqrt{9.06}$，取a=9可得： $\\frac{1}{2\\sqrt{9}} ≈ \\frac{f(x) - \\sqrt{9}}{9.06 - 9}$ 最终f(x) ≈ 3.01 牛顿法：求f(x)=0的解 由线性近似的公式可得：$x ≈ a - \\frac{f(a)}{f'(a)}$ 例如：求x2 - 9.06 = 0的解，取a=3可得 $x = 3 - \\frac{-0.06}{2 * 3} = 3.01$ 可令a = 3.01继续求解，则可以得到更精确的值 课程笔记4 P14.幂级数及欧拉公式 x=a的幂级数：$a_0 + a_1(x - a) + a_2(x - a)^2 + a_3(x - a)^3 + ...$ x=0的幂级数：$a_0 + a_1(x) + a_2(x)^2 + a_3(x)^3 + ...$ 泰勒级数的定义 f(x)关于x=0的泰勒级数：$f(x) = f(0) + f'(0)x + \\frac{f''(0)}{2!}x^2 + \\frac{f'''(0)}{3!}x^3 + ...$ $e^x = 1 + x + \\frac{1}{2!}x^2 + \\frac{1}{3!}x^3 + ...$，ex的所有导数在x=0处都是1 $\\sin x = x - \\frac{1}{3!}x^3 + \\frac{1}{5!}x^5 - \\frac{1}{7!}x^7 + ...$ $\\cos x = 1 - \\frac{1}{2!}x^2 + \\frac{1}{4!}x^4 - \\frac{1}{6!}x^6 + ...$ 欧拉公式：$e^{ix} = \\cos x + i\\sin x$，推导如下： $e^{ix} = 1 + ix + \\frac{1}{2!}(ix)^2 + \\frac{1}{3!}(ix)^3 + \\frac{1}{4!}(ix)^4 + ...$ $e^{ix} = 1 + ix - \\frac{1}{2!}x^2 - \\frac{i}{3!}x^3 + \\frac{1}{4!}x^4 + ...$ $e^{ix} = (1 - \\frac{1}{2!}x^2 + \\frac{1}{4!}x^4 + ...) + i(x - \\frac{1}{3!}x^3 + ...) $ $e^{ix} = \\cos x + i\\sin x$ 几何级数及其积分 $\\frac{1}{1-x} = 1 + x + x^2 + x^3 + ...$，当|x| $-\\ln(1-x) = x + \\frac{x^2}{2} + \\frac{x^3}{3} + ...$，当|x| 课程笔记5 P15.关于运动的微分方程 本节讲的是常系数线性二阶微分方程：$m\\frac{d^2y}{dt^2} + 2r\\frac{dy}{dt} + ky = 0$ 常系数：指y和n阶导数前的系数都是常数 线性：指y和n阶导数的幂都是1 二阶微分：最多是二阶导数 当m=0时，$\\frac{dy}{dt} = ay$，该微分方程的解为：$y = Ce^{at}$，C为任意值 当r=0时，$\\frac{d^2y}{dt^2} = -ω^2y$，该微分方程的解为：$y = C\\cos (wt)$或$y = D\\sin (wt)$ 当r=0,k=0时，$\\frac{d^2y}{dt^2} = 0$，该微分方程的解为：y = C + Dt 求解常系数线性二阶微分方程，令$y = e^{λt}$可得： $mλ^2e{λt} + 2rλe^{λt} + ke^{λt} = 0$ $mλ^2 + 2rλ + k = 0$ $λ_{1,2} = \\frac{-r±\\sqrt{r^2-km}}{m}$ 求解1：y'' + 6y' + 8y = 0 $λ^2 + 6λ + 8 = 0$，可得λ=-2或λ=-4 $y = Ce^{-2t} + De^{-4t}$ 求解2：y'' + 6y' + 10y = 0 $λ = \\frac{-6±\\sqrt{36-40}}{2}$，可得λ=-3±i $y = Ce^{(-3+i)t} + De^{(-3-i)t}$ 求解3：y'' + 6y' + 9y = 0 $λ^2 + 6λ + 9 = 0$，可得λ=-3 $y = Ce^{-3t} + Dte^{-3t}$ P16.关于人口增长的微分方程 存款利息问题：$\\frac{dy}{dt} = cy$，可得$y = Ae^{ct}$ $y(0) = A$，可得$y = y(0)e^{ct}$ y(t)：存储账号的钱；y(0)初始金额；c：年利息 假设y(0)=10000, c=0.03，则y(1)=10304.545 增长可积累或者有消耗：$\\frac{dy}{dt} = cy + s$，s>0表示增长可积累，s $\\frac{d}{dt}(y + \\frac{s}{c}) = c(y + \\frac{s}{c})$ $y + \\frac{s}{c} = (y(0) + \\frac{s}{c})e^{ct}$ $y = -\\frac{s}{c} + (y(0) + \\frac{s}{c})e^{ct}$ 人口增长模型：$\\frac{dP}{dt} = cP - sP^2$，c是出生率-死亡率，s是人口因竞争而减少的系数 令$y = \\frac{1}{P}$可得：$\\frac{dy}{dt} = \\frac{dy}{dP}\\frac{dP}{dt} = -\\frac{1}{P^2}(cP - sP^2)$ $\\frac{dy}{dt} = -(\\frac{c}{P} - s) = -(cy - s)$ $y = \\frac{s}{c} + (y(0) - \\frac{s}{c})e^{ct}$，再带入$y = \\frac{1}{P}$可得P 捕食-猎物模型：$\\frac{du}{dt} = -cu + suv \\quad \\frac{dv}{dt} = cv - suv$ u(t)：捕食者的种族数量变化；v(t)：猎物的种族数量变化 课程笔记6 积分 六函数 导数 $x^{n+1}/(n+1)$ $x^n$ $nx^{n-1}$ $-\\cos x$ $\\sin x$ $\\cos x$ $\\sin x$ $\\cos x$ $-\\sin x$ $\\rm e^{cx}/c$ $\\rm e^{cx}$ $c\\rm e^{cx}$ $x\\ln x - x$ $\\ln x$ $1/x$ 斜坡函数Ramp function 阶跃函数Step function 冲激函数Delta function 六法则 加法法则：$af(x)+bg(x)$ 的导数为$a\\frac{df}{dx} + b\\frac{dg}{dx}$ 乘法法则：$f(x)g(x)$ 的导数为$\\frac{df}{dx}g(x) + f(x)\\frac{dg}{dx}$ 除法法则：$f(x)/g(x)$ 的导数为$(\\frac{df}{dx}g - f\\frac{dg}{dx})/{g^2}$ 链式法则：$f(g(x))$ 的导数为$\\frac{df}{dy}\\frac{dy}{dx}$，其中y=g(x) 逆函数法则：$x=f^{-1}(y)$ 的导数为$\\frac{dx}{dy}=\\frac{1}{dy/dx}$ 洛必达法则：当x→a，f(x)→0和g(x)→0时，如何求f(x)/g(x)：$\\lim\\limits_{x\\to a}\\frac{f(x)}{g(x)}=\\frac{df/dx}{dg/dx}=\\frac{f'(x)}{g'(x)}$ 六定理 微积分的第一基本定理：若$f(x)=\\int^x_a s(t)dt$，则$\\frac{df}{dx}=s(x)$，$\\int$是积分符号 微积分的第二基本定理：若$\\frac{df}{dx}=s(x)$，则$\\int^b_a s(t)dt=f(b)-f(a)$ 全值定理：假设函数f(x)在闭区间[a,b]内连续，f(x)可以取到的最大值M最小值m，那么f(x)可以取到M和m之间的所有值。 中值定理：假设函数f(x)在闭区间[a,b]内连续，在开区间(a,b)可导，则(a,b)内至少有一点c使得$f'(c)=\\frac{f(b)-f(a)}{b-a}$ 泰勒级数：f(x)关于x=a的泰勒级数：$f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)}{2!}(x-a)^2 + \\frac{f'''(a)}{3!}(x-a)^3 + ...$ 两项式定理：$(1+x)^p$在x=0处的导数是：p、p(p-1)、p(p-1)(p-2)...，用泰勒公式展开可得：$(1+x)^p=1+px+\\frac{p(p-1)}{2!}x^2+...$ p=1则有$(1+x)^1 = 1 + x$ p=2则有$(1+x)^1 = 1 + 2x + x^2$ p=3则有$(1+x)^1 = 1 + 3x + 3x^2 + x^3$ p=4则有$(1+x)^1 = 1 + 4x + 6x^2 + 4x^3 + x^4$ "},"docs/fft.html":{"url":"docs/fft.html","title":"傅里叶变换","keywords":"","body":"傅里叶变换 一维离散傅里叶变换DFT 2022-04-16 一维离散傅里叶变换DFT - 手算过程 使用python进行傅里叶FFT-频谱分析详细教程 # python实现的一维离散傅里叶变换，结果和上述手算的结果一样 # DFT_slow等价于np.fft.fft import numpy as np def DFT_slow(x): x = np.asarray(x, dtype=float) N = x.shape[0] n = np.arange(N) k = n.reshape((N, 1)) M = np.exp(-2j * np.pi * k * n / N) return np.dot(M, x) x = np.array([1,2,3]) y = DFT_slow(x) print(y) print(np.fft.fft(x)) "},"docs/saa-1.html":{"url":"docs/saa-1.html","title":"1.AWS知识点","keywords":"","body":"AWS认证 资料 udemy.com 网站排名127 ACloudGuru 的视频依然是最好的学习材料，它把它的竞争对手 Linux Academy 收购了。 Learning Path - https://jayendrapatil.com/aws-certified-solution-architect-professional-exam-learning-path/ AWS Github Study Guide - https://github.com/keenanromain/AWS-SAA-C02-Study-Guide AWS FAQs https://aws.amazon.com/faqs/ WhitePapers https://aws.amazon.com/cn/whitepapers/ HTML转PDF：先转word，再用wps转pdf 中国区AWS价格计算器 视频：https://www.udemy.com/course/aws-certified-solutions-architect-associate-saa-c02/ 练习1：https://www.udemy.com/course/aws-certified-solutions-architect-associate-amazon-practice-exams-saa-c02/ 练习2：https://www.udemy.com/course/practice-exams-aws-certified-solutions-architect-associate 如何通过console的System Managers登录ec2： ec2需要附加一个role（带2个policy），参考 ec2需要安装amazon-ssm-agent，参考 ec2如果不能访问外网，则需要建立内网Endpoints，参考 存储相关 block storage（容量16T）： General Purpose SSD （gp2/gp3）：1.6w IOPS，适合随机IO Provisioned SSD（io1/io2）：6.4w IOPS，适合随机IO，适合数据库 io2 Express：25.6w IOPS Throughput Optimized HDD （st1）：500 IOPS，适合顺序IO，频繁访问 Cold HDD （sc1）：250 IOPS，适合顺序IO，非频繁访问 Instance Store：200w IOPS，关机数据丢失；hibernate数据也会丢失 特点1：io1/io2 现在支持Multi-Instance-Attach（最多支持16个EC2） 特点2：st1和sc1不能作为启动卷，其他包括上一代的磁介质都可以；Instance Store是附带的启动卷，但是不能作为系统盘 EBS加密卷，卷与实例之间的传输也是加密的 EBS卷可以不停机的更改类型和增加size，除了磁介质；但不能减小size 在EC2 Dashboard可以设置ebs默认开启加密 file storage： Amazon Elastic File System：50w IOPS，多ec2共享，容量不限。pay-as-you-use；使用NFS协议 Amazon FSx for Windows：network filesystem for Windows，容量64T Amazon FSx For Lustre：100w IOPS，容量不限；可和S3高度集成；适合 HPC(high-performance computing) EFS的模式：性能模式（GP、MAX IO）、吞吐量模式（Provisioned、Bursting）、存储模式（Standard、Infrequent Access） EFS的配置：EFS Access Points to manage access；Attach an IAM policy；VPC security groups object storage：S3，如果出现file storage则不能选S3 Standard Intelligent：智能 Standard-IA：不经常访问、取回有费用；上传后等30天、文件>128K才能切到此类型 One Zone-IA：单AZ；上传后等30天、文件>128K才能切到此类型 Glacier：>90天，取回时间1m~12h；不能被Athena查询；默认是加密的 Glacier Deep Archive：>180天，取回时间12h~48h 特点1：S3 cross-Region replication 只能复制新增文件；s3 sync命令可以跨region复制 特点2：可以通过default setting或者显式设置文件保留时长，同一个文件不同版本的保留时长可以不一样 特点3：S3 is strongly consistent for all GET, PUT and LIST operations 特点4：S3 event notification 只支持Standard SQS不支持FIFO SQS 特点5：S3 的 Metadata 不能被加密 EBS 的优点： 自动在当前AZ备份，单block failure后自动替换 不停机的更换 type, size, IOPS capacity S3 生命周期 标准 > IA > IT > One-Zone-IA > Glacier > Glacier-Deep，低层不能转换到高层 转换到 IA 和 One-Zone-IA 需要文件大于128K、30天后才能转 Auto Scaling Group Auto Scaling Group 特性 launch configuration 使用了就不能修改，要修改就新建一个 launch configuration，只能新建一个type的ec2 launch template 比lc新，有版本控制，能新建多个type的ec2 lifecycle hooks 可以对一个实例使用 custom script 删除 ASG，会附带删除所有 EC2 Auto Scaling Group scaling 策略 simple scaling：只有一个门槛，超过会新增实例，为了防止频繁新增，默认有冷却时间（300秒） step scaling：可设多个门槛，例如>50%加1个实例，>60%加2个实例，没有冷却时间 target tracking：只设一个门槛（1分钟检查一次，3次超标就xx），傻瓜式的，目的是保持在这个门槛值附近 scheduled scaling：支持cron表达式 特点1：scaling activity，先terminate unhealthy instance，再起新的instance；re-balancing activity 则相反 特点2：多个策略同时被触发，scale-out取最大数量的实例 Auto Scaling Group terminate 策略 多AZ选择AZ中ec2最多的 ec2中配置项最老的 ec2中最接近账单周期的 满足以上条件的ec2随机terminate 健康检查： ec2 健康检查：running状态的ec2就是health elb 健康检查：running状态的ec2，且ping检查合格 账号集成 Access AWS resources using on-premises credentials stored in Active Directory ！！！ Amazon Cognito 两大组件 user pools：提供用户登录和directory service，为了安全可启用多重验证(MFA)作为二次验证 identity pools：provide AWS credentials to grant your users access to other AWS services 常见组件： web identity federation：可以和idp服务集成 identity provider (IdP)：提供登录认证 RDS、Aurora、DynamoDB Amazon RDS automatically performs a fail-over when： Loss of availability in primary Availability Zone. Loss of network connectivity to primary. Compute unit failure on primary. Storage failure on primary. Amazon RDS Metrics： regular items：CPU Utilization, Database Connections, Freeable Memory Enhance items：OS processes, RDS processes, RDS child processes RDS fail-over： 启用了Multi-AZ：Amazon RDS points CNAME to the standby, promoted it an new primary 启用了Read Replica（须先启用自动备份）：主节点不可用时，手动提升Read Replica为主节点 Aurora fail-over： if 启动了 Aurora Replica，将CNAME指向不同AZ的副本 elseif 启动了 Aurora Serverless，在不同AZ重建一个实例 else，在相同AZ重建一个实例 Aurora 可跨5个region建只读副本（延迟在1秒内）；双写功能不能跨region。 Aurora 性价比：相同的吞吐量，Aurora 比 DynamoDB 便宜，存储价格两者差不多。 RDS 只有 MySQL 和 PostgreSQL 支持 IAM auth；SQL Server 不支持，安全连接的方法： 设置 rds.force_ssl 开启 ssl 下载 RDS Root CA 到实例内 存储数据库密码、API密钥的方案： AWS Secrets Manager：manage database credentials, passwords, API keys, arbitrary text. encrypted and regular rotated. Systems Manager Parameter Store：可以存明文、密文，但是不会 regular rotated. RDS 特点 RDS Multi-AZ follows synchronous replication and spans at least two AZ. Read replicas follow asynchronous replication RDS 一个没有加密的instance，不能更改加密；不能创建一个加密的replica；只能先创建snapshot，从snapshot创建一个加密的instance RDS 没有自签名证书 RDS Multi-AZ 更新补丁：先更新standby把它提为primary，再更新旧primary把它提为standby RDS Multi-AZ 升级版本：standby和primary同时更新，会有downtime RDS 和 Aurora 都有storage auto-scaling RDS 修改存储大小需要重启、而设置自动扩容不需要 共享数据库给审计部门：共享 encrypted snapshot, 再共享 KMS encryption key 备份还原： RDS 需开启自动备份（间隔5分钟），可设置保留时间（0~35天，默认7天），还原的时候选择还原点（snapshot）创建一个新实例 Aurora 自动备份是默认开启的，可设置保留时间（1~35天，默认1天），可恢复到保留时间内的任意时间点，可选择创建一个新实例（需几小时）或直接回溯（需几分钟） 手动快照 RDS 和 Aurora 都支持，保留时间随意 SQS、SNS、SWF、Step functions SQS retention period is from 1 minute to 14 days SQS 的 ReceiveMessageWaitTimeSeconds 默认是0，表示 Short polling，如果大于0，则是 Long polling SQS FIFO support 3000 messages per second with batching, or up to 300 messages per second；可以消息分组(最多100组) SNS 也能触发lambda，也有FIFO类型 Simple Workflow Service (SWF)：creating a decoupled architecture in AWS；不会重复消费任务；适合ec2，已过时，除非有父子进程信号才用 Step functions：适合lambda、ECS、API Gateway；替代SWF 特点1：SQS message timers 可以针对单个消息设置延迟；delay queues则针对全局 防火墙 AWS Firewall Manager：simplifies your AWS WAF and AWS Shield and VPC Security Groups administration across multiple accounts and resources. Amazon GuardDuty：一种智能威胁检测服务，通过 CloudTrail 日志、VPC 流日志、DNS 日志分析出账户盗用、存储桶入侵、异常 API 调用、恶意 IP 、挖矿病毒等活动，并自动化响应。 Amazon Macie：在S3中分析出敏感内容，如密钥、密码、身份证等然后提醒你 Amazon Inspector：检查EC2实例是否存在意外的网络可访问性和漏洞。 AWS WAF：七层协议的防护（ALB, API Gateway, CloudFront），功能有ACL（封ip、header、url）、SQL注入、XSS、Rate-based for DDoS、Block with IPs or geo。 AWS Shield：三层/四层协议、高级的DDoS防护，标准版免费、高级版可以用于EIP、ELB、CloudFront、Global Accelerator、Route53。没有rate-based rules 负载均衡器 同ip多域名https支持(SNI)：CLB不支持，ALB、ELB、CloudFront支持 支持websocket：ALB支持；ELB仅支持HTTP、HTTPs、TCP、UDP、TLS，可以在ec2层实现websocket，然后用TCP->ws，TLS->wss。 只有ALB支持 path-based and host-based routing，ELB不支持Weighted Target Groups Connection Draining：实例会多一种unregistering状态（健康检查异常但没有完全确认），new或者in-flight请求会导到其他机器 cross-zone 特性：默认LB只有单zone的能力（假设AZ1有2个ec2，AZ2有8个ec2，AZ1和AZ2只能同时分配50%） ALB、CLB有安全组；NLB、NAT Gateway没有安全组；安全组只有allow rule，没有deny rule；NCALs有deny rule 加速传输 Snowball：80T，可用多个；如果用100Mb带宽传，得200天；不能直接存S3 Glacier！！！ Snowmobile：100P AWS Storage Gateway：使用S3、FSx等扩展本地机房的存储（不支持EFS）；local caching可以加速访问； File Gateway：接口是NFS/SMB，底层存储对应S3 Volume Gateway：接口是iSCSI Tape Gateway：接口是iSCSI 要记住：block protocols 是 iSCSI and file protocols 是 NFS AWS DataSync：不能加速，接口比较广泛：S3, EFS, Fsx for Windows S3 Transfer Acceleration：全球各地的客户需要上传S3，还能提升下载速度；CloudFront也有相同功效（限1G以内文件） AWS Direct Connect（DX）：需要最少一月的搭建 AWS Site to Site VPN（IP-sec） 加速全球访问 AWS Global Accelerator：给节点（NLB、ALB、EC2、EIP）加速；good fit for gaming(UDP), IoT(MQTT), static IP(Http)；可以跨region蓝绿部署 AWS CloudFront 网络连通 VPC endpoints 有三类 gateway endpoints：把S3、DynamoDB变成私网服务，免费 Private Link（Interface endpoints, Gateway Load Balance endpoints）：把非S3、DynamoDB服务等变成私网服务，有ENI，付费 Direct Connect Gateway：打通一个本地机房到多个 AWS 的区域 AWS VPN CloudHub：打通多个本地机房的连接（依赖VPN或DX） AWS Transit Gateway：可以理解为云上的路由器，在每一个 Region 中创建一个 TGW，就可以将它们 Peering 起来 大数据 AWS Kinesis Firehose：是一个消化管道，延迟60秒，不加处理的传给S3、Redshift、ElasticSearch；程序不能直接消费它 AWS Kinesis Streams：是实时和自定义的，延迟1秒，可以自定义处理数据；默认保留数据1天；程序可以直接消费它；关键字：real-time analytics；消息是有序的 AWS Redshift：支持OLAP，不支持ACID，是最终一致性；不能动态扩容；亚秒级响应 AWS DynamoDB：支持毫秒级响应 特点1：Kinesis Agent可以写入Kinesis Streams、Kinesis Firehose，但是如果Kinesis Streams已经连接了Kinesis Firehose，此时不能直接写Kinesis Firehose 容灾 active-active：每个节点都是主节点；active-passive：一般都是主节点提供服务，从节点容灾 High Availability：不间断服务；Fault Tolerance：假设需要4个ec2，目前AZ1有2个，AZ2有2个，如果AZ1挂了，虽然是不间断，但是容错能力不够，最好是两个AZ都4个ec2 Disaster recovery 级别（从低到高） Backup & Restore：RPO in hours Pilot Light 最小环境（通常也称为 Cold Standby）：RPO in minutes Warm Standby 小规模热备环境：RPO in seconds Multi-Site active-active部署（通常也称为 Hot Standby）：RPO near 0 EC2 ec2：不是running状态无需付费，但从stopping到hibernate状态需要；预留实例terminated状态也要付费 EC2 Spot Block 可以有1-6小时固定预留时间 EC2 Scheduled Reserved 必须是每天有固定时间段（周末不用可以允许） EC2 的AMI镜像依赖snapshot的存在 EC2 Default instances的母机是不确定的，Dedicated instances的母机是属于同一账号的，Host instances 母机是独享的；Host instances和Dedicated instances可以互相切换 EC2 的spread placement group，一个AZ最多放7个实例 其他 metadata的Tags配合IAM可以针对用户区分资源 CloudTrail默认把日志存S3且SSE加密 Amazon ElasticCache for Redis 默认没有开启 Redis AUTH CloudFront 使文件失效的最佳实践是使用新路径；刷新CDN缓存需要付费 跨 AZ 的流量也会收费 lambda 最长执行时间是15分钟，默认只有1000 qps的并发；没有Caching机制 lambda 默认在一个全局的VPC网络，一旦启用VPC，则必须借助NAT Gateway连接外网 AWS Organization 能用 Service Control Policy (SCP) 控制子账号的资源，比如ec2的型号 CloudFormation 可以为 template 配置 security configuration 保证网络安全 CloudFormation StackSets can deploy the same template across AWS accounts and regions ECS 的AmazonECSTaskExecutionRolePolicy是用于agent的（拉取镜像、写日志），taskRoleArn 则是运行时的角色 ECS 底层除了EC2还可以用Fargate Route 53 的 geo-location：绝对的地理；geo-proximity：基于地理位置的偏移设置 VPC sharing 可以实现同组织的账号间共享子网 AWS CloudWatch alarms 可以触发ec2重启、sns、Auto Scaling；要触发lambda需要借助sns Amazon API Gateway 利用令牌桶算法来限制请求数；启用API Gateway Caching可以当缓冲层 AWS DMS as a bridge between Amazon S3 and Amazon Kinesis Data Streams IAM 三驾马车：Organization SCP、IAM permission boundaries(不能作用于用户组)、IAM permissions route 53 alias可以设置根域名CNAME不能，alias只能指向AWS的资源或者同zone的其他记录 Amazon EventBridge is the only event-based service that integrates directly with third-party SaaS partners. "},"docs/saa-2.html":{"url":"docs/saa-2.html","title":"2.AWS认证英语学习","keywords":"","body":"AWS认证英语学习 Chapter 2 Amazon Elastic Compute Cloud and Amazon Elastic Block Store Tenancy To meet special regulatory requirements, your organization’s instances might need an extra level of isolation. The Dedicated Instance option ensures that your instance will run on a dedicated physical server. This means that it won’t be sharing the server with resources owned by a different customer account. The Dedicated Host option allows you to actually identify and control the physical server you’ve been assigned to meet more restrictive licensing or regulatory requirements. dedicated 美[ˈdedɪkeɪtɪd] adj. 专用的 restrictive 美[rɪˈstrɪktɪv] adj. 限制的 tenancy 美[ˈtɛnənsi] n. 租用 Resource Tags The more resources you deploy on your AWS account, the harder it can be to properly keep track of things. Having constantly changing numbers of EC2 instances—along with accompanying storage volumes, security groups, and elastic IP addresses—all spread across two or three VPCs can get complicated. constantly 美[ˈkɑːnstəntli] adv. 时常地 accompanying 美[ə'kʌmpənɪɪŋ] adj. 陪伴的 complicated 美[ˈkɑːmplɪkeɪtɪd] adj. 复杂的 NAT Devices One solution is to use network address translation (NAT) to give your private instance access to the Internet without allowing access to it from the Internet. AWS gives you two ways to do that: a NAT instance and a NAT gateway (see Figure 2.2). They’ll both do the job, but since a NAT gateway is a managed service, it doesn’t require that you manually launch and maintain an instance. Both approaches will incur monthly charges. NAT Gateway 是VPC共享的，AZ1和AZ2都能用，只需建一个，如果考虑容灾可以每个AZ都建一个。 approach 美[əˈproʊtʃ] n. 方法 charge 美[tʃɑːrdʒ] n. 收费 Health Checks Against Application Instances A good design practice is to have a few recovery actions that work for a variety of circumstances. An instance may crash due to an out-of-memory condition, a bug, a deleted file, or an isolated network failure, but simply terminating and replacing the instance using Auto Scaling resolves all these cases. There’s no need to come up with a separate recovery action for each cause when simply re-creating the instance solves them all. variety 美[vəˈraɪəti] n. 多种多样 circumstance 美[ˈsɜːrkəmstæns] n. 条件；环境 separate 美[ˈsepəreɪt] adj. 独立的 Summary EC2 Auto Scaling can help you avoid application failures caused by overloaded instances. By implementing dynamic scaling policies, you can ensure that you always have enough instances to handle increased demand. In the event of some failure, a well-designed Auto Scaling group will ensure that you always have a minimum number of healthy instances. When an instance becomes unhealthy, Auto Scaling will terminate and replace it. Chapter 3 AWS Storage Introduction In this chapter, you’re going to learn the following: ■ How S3 objects are saved, managed, and accessed ■ How to choose from among the various classes of storage to get the right balance of durability, availability, and cost ■ How to manage long-term data storage lifecycles by incorporating Amazon Glacier into your design ■ What other AWS services exist to help you with your data storage and access operations durability 美[ˌdjʊrəˈbɪlətɪ] n. 持久性 incorporate 美[ɪnˈkɔːrpəreɪt] vt. 使混合 Eventually Consistent Data It’s important to bear in mind that S3 replicates data across multiple locations. As a result, there might be brief delays while updates to existing objects propagate across the system. Uploading a new version of a file or, alternatively, deleting an old file altogether can result in one site reflecting the new state with another still unaware of any changes. To ensure that there’s never a conflict between versions of a single object—which could lead to serious data and application corruption—you should treat your data according to an eventually consistent standard. That is, you should expect a delay (usually just two seconds or less) and design your operations accordingly. Because there isn’t the risk of corruption when creating new objects, S3 provides read-after-write consistency for creation (PUT) operations. （针对new object，把请求发给固定的副本，保证客户端写后能立马读到它。） bear 美[ber] v. 带有，拥有 replicate 美[ˈreplɪkeɪt] vt. 复制 brief 美[briːf] adj. 短暂的 propagate 美[ˈprɑːpəɡeɪt] vt. 扩散；使蔓延 reflect 美[rɪˈflekt] v. 反映；反射 conflict 英[ˈkɒnflɪkt] n. 争执；冲突 serious 美[ˈsɪriəs] adj. 严重的 corruption 美[kəˈrʌpʃn] n. 腐败 accordingly 美[əˈkɔːrdɪŋli] adv. 相应地 Accessing S3 Objects There is more than a little overlap between those three approaches. In fact, ACLs are really leftovers from before AWS created IAM. As a rule, Amazon recommends applying S3 bucket policies or IAM policies instead of ACLs. overlap 英[ˌəʊvəˈlæp] vt. 重叠 approach 美[əˈproʊtʃ] n. 方法 Summary You can reduce the size and cost of your requests against S3 and Glacier-based data by leveraging the SQL-like Select feature. You can also provide inexpensive and simple static websites through S3 buckets. Amazon Glacier stores your data archives in vaults that might require hours to retrieve but that cost considerably less than the S3 storage classes. leverage 美[ˈlevərɪdʒ] v. 发挥杠杆作用；利用 Chapter 4 Amazon Virtual Private Cloud Introduction If you’re familiar with the components of a traditional network, you’ll recognize many VPC components. But although VPCs function like a traditional TCP/IP network, they are scalable, allowing you to expand and extend your network without having to add physical hardware. To make this scalability possible, some components that you’d find in a traditional network—such as routers, switches, and VLANs—don’t exist in VPCs. Instead, they’re abstracted into software functions and called by different names. traditional 美[trəˈdɪʃənl] adj. 传统的 recognize 美[ˈrekəɡnaɪz] vt. 认出 scalable 美['skeɪləbəl] adj. 可攀登的，可升级的 Subnet CIDR Blocks A subnet can’t have multiple CIDRs. Unlike a VPC that can have secondary CIDRs, a subnet can have only one. However, if a VPC has a primary CIDR and a secondary CIDR, your subnet’s CIDR can be derived from either. For example, if your VPC has the primary CIDR of 172.16.0.0/16 and a secondary CIDR of 172.17.0.0/16, a subnet in that VPC could be 172.17.12.0/24, as it’s derived from the secondary VPC CIDR. derive 美[dɪˈraɪv] v. 获得 Using Network Access Control Lists and Security Groups Together You may want to use an NACL in addition to a security group so that you aren’t dependent on AWS administrators to specify the correct security group when they launch an instance. Because an NACL is applied to the subnet, the rules of the NACL apply to all traffic ingressing and egressing the subnet, regardless of how the security groups are configured. regardless 美[rɪˈɡɑːrdləs] adv. 不顾后果地 NAT Instance One advantage of a NAT instance is that you can use it as a bastion host, sometimes called a jump host, to connect to instances that don’t have a public IP. You can’t do this with a NAT gateway. You must create a default route to direct Internet-bound traffic to the NAT instance. The target of the default route will be the NAT instance’s ID, which follows the format i-0a1674fe5671dcb00. advantage 美[ədˈvæntɪdʒ] n. 优点 bastion 美[ˈbæstʃən] n. 堡垒 Hybrid Cloud Networking 1. Site to Site VPN (Internet Protocol security, IPsec) 2. AWS Transit Gateway 3. AWS Direct Connect (DX) However, if you want to connect a large number of VPCs to your on-premises network, or if you need to connect many on-premises networks to a VPC, creating a separate VPN connection for each one can become cumbersome. In that case, you’ll want to use AWS Transit Gateway Hybrid 美[ˈhaɪbrɪd] adj. 混合 on-premises 内部部署的 transit 美[ˈtrænzɪt] adj. 中转的 Summary In each region, AWS automatically provides a default VPC with default subnets, a main route table, a default security group, and a default NACL. Many use a default VPC for a long time without ever having to configure a VPC from scratch. This makes it all the more important that you as an AWS architect understand how to configure a virtual network infrastructure from scratch. There’s a good chance you won’t be allowed to modify an infrastructure that was built on top of a default VPC. Instead, you may be tasked with replicating it from the ground up—troubleshooting various issues along the way. Practice what you’ve learned in this chapter until creating fully functional VPCs becomes second nature to you. infrastructure 美[ˈɪnfrəstrʌktʃər] n. 基础设施 Chapter 5 Database Services General-Purpose SSD Burst duration in seconds = Credit balance / 3000 - 3 * (size in GB) 如果有200GB的gp2磁盘，基准可达到600IOPS，Credit balance上限是5400000 如果Credit balance为0，每秒可以积累600个 如果Credit balance为5400000，要突发到3000IOPS，可以持续2250秒 Provisioned IOPS SSD (io1) The ratio of storage in gigabytes to IOPS must be at least 50:1. For example, if you want 32,000 IOPS, you must provision at least 640 GB of storage. The st1 and sc1 volume types are appropriate for frequent, sequential reads and writes, such as you might see with data warehousing, extract, transform, and load (ETL), and Elastic MapReduce (EMR) applications. These volume types are not appropriate for random I/O. For that, gp2 is a better choice. Both RDS MySQL and Aurora MySQL support Cross-Region. Aurora MySQL support maximum of 4 instances in a multi-master cluster, can't enable cross-Region replicas. IAM authentication isn’t supported for MS-SQL, Oracle. Multi-region failover, isn’t supported for MS-SQL, PostgreSQL, or Oracle. Multi-region failover, standby instance is not a read replica and cannot serve read traffic. When a failover occurs, RDS changes the DNS record of the endpoint to point to the standby. Point-in-time recovery for RDS, should enable automatic backups, recovery to fixed backup snapshot. Point-in-time recovery for Aurora, recovery to any time with-in the backup retention period. DynamoDB https://www.modb.pro/db/65288 https://stackoverflow.com/questions/56051481 表有三种索引： Table Primary Key（必须） Global Secondary Index（可选，可以选择任意属性作为HashKey和RangeKey） Local Secondary Index（可选，只能选择与表相同的HashKey，创建表时指定，和表共享吞吐量，最大10G） 索引的两种组成类型： 只包含HashKey：HashKey又称为分区键 包含HashKey+RangeKey组合，RangeKey也称排序键 HashKey、RangeKey的类型只能是String、Number、Binary DynamoDB的where查询超过2个字段，则建一个冗余的联合字段，然后设置Global Secondary Index或Local Secondary Index DynamoDB Global Tables To use global tables, your table must be configured in on-demand mode or provisioned mode with Auto Scaling enabled. A global table is a collection of replica tables, and a global table can have only one replica table per region. Whenever you write an item to a replica table, it’s replicated to replica tables in other regions. Global tables don’t support strongly consistent read across regions. Summary Whether you implement a relational or nonrelational database depends solely on the application that will use it. Relational databases have been around a long time, and many application developers default to modeling their data to fit into a relational database. Applications use database-specific SDKs to interact with the database, so often the needs of the application mandate the specific database engine required. This is why AWS RDS offers six of the most popular database engines and sports compatibility with a wide range of versions. The idea is to let you take an existing database and port it to RDS without having to make any changes to the application. solely 美[ˈsoʊlli] adv. 唯一地 mandate 美[ˈmændeɪt] vt. 托管；批准 Chapter 6 Authentication and Authorization—AWS Identity and Access Management User and Root Accounts You may be forgiven for wondering why giving a user the AdministratorAccess policy is any safer than leaving your root account in active service. After all, both seem to have complete control over all your resources, right? Wrong. There are some powers that even an AdministratorAccess holder doesn’t have, including the ability to create or delete account-wide budgets and enable MFA Delete on an S3 bucket. Roles You create a new role by defining the trusted entity you want given access. There are four categories of trusted entity: an AWS service; another AWS account (identified by its account ID); a web identity who authenticates using a login with Amazon, Amazon Cognito, Facebook, or Google; and Security Assertion Markup Language (SAML) 2.0 federation with a SAML provider you define separately. Once your entity is defined, you give it permissions by creating and attaching your own policy document or assigning one or more preset IAM policies. When a trusted entity assumes its new role, AWS issues it a time-limited security token using the AWS Security Token Service (STS). authenticate 英[ɔ:ˈθentɪkeɪt] vt. 证明是真实的 federation 美[ˌfedəˈreɪʃn] n. 联邦 assume 美[əˈsuːm] v. 假设 Authentication Tools 登录协议有（https://zhuanlan.zhihu.com/p/105674989）： LDAP：角色有用户、应用Server、LADP server。LADP server只负责认证登录。 SAML 2.0：角色有用户、应用Server、LDP server。LDP server负责登录认证和授权。 OAuth 2.0：角色有用户、应用Server、第三方Server。第三方Server负责登录认证和授权。 OpenID：角色有用户、应用Server、用户的LDP Server。用户的LDP Server只负责认证登录。 Handling user authentication 1. Amazon Cognito 2. AWS Managed Microsoft AD 3. AWS Single Sign-On Administration of encryption keys and authentication secrets 1. AWS Key Management Service (KMS)。CMK 仅仅支持导入对称密钥，不支持非对称密钥。 2. AWS Secrets Manager 3. AWS CloudHSM 代码保存db password的方法有： 1. 使用AWS Secrets Manager 2. 使用AWS Systen Manager的Parameter Store，可存明文或者KMS加密的密文，免费 3. 使用AWS Systen Manager的AppConfig Summary The IAM root user that’s automatically enabled on a new AWS account should ideally be locked down and not used for day-to-day account operations. Instead, you should give individual users the precise permissions they’ll need to perform their jobs. All user accounts should be protected by strong passwords, multifactor authentication, and the use of encryption certificates and access keys for resource access. Once authenticated, a user can be authorized to access a defined set of AWS resources using IAM policies. It’s a good practice to associate users with overlapping access needs into IAM groups, where their permissions can be centrally and easily updated. Users can also be assigned temporary IAM roles to give them the access they need, when they need it. Access keys should be regularly audited to ensure that unused keys are deleted and active keys are rotated at set intervals. Identities (including users, groups, and roles) can be authenticated using a number of AWS services, including Cognito, Managed Microsoft AD, and Single Sign-On. Authentication secrets are managed by services such as AWS Key Management Service (KMS), AWS Secrets Manager, and AWS CloudHSM. precise 美[prɪˈsaɪs] adj. 清晰的 associate 英[əˈsəʊʃieɪt] v. 使与有关系 Chapter 7 CloudTrail, CloudWatch, and AWS Config Introduction CloudTrail, CloudWatch, and AWS Config are three services that can help you ensure the health, performance, and security of your AWS resources and applications. These services collectively help you keep an eye on your AWS environment by performing the following operational tasks: 1. Tracking Performance 2. Detecting Application Problems 3. Detecting Security Problems 4. Logging Events 5. Maintaining an Inventory of AWS Resources CloudWatch does not automatically provide memory and disk utilization metrics of your instances. trail 美[treɪl] n. 踪迹 detect 美[dɪˈtekt] v. 发现；查明 inventory 美[ˈɪnvəntɔːri] n. 存货清单；财产目录 Metric Filters You would create a metric filter to track the number of times the string “404” appears in the HTTP status code section of the log. Every time CloudWatch Logs receives a log event that matches the filter, it increments a custom metric. You might name such a metric HTTP404Errors and store it in the custom Apache namespace. CloudWatch Alarms - Threshold Static Threshold. You define a static threshold by specifying a value and a condition. If you want to trigger an alarm when CPUUtilization meets or exceeds 50 percent, you would set the threshold for that alarm to >= 50. Or if you want to know when CPUCreditBalance falls below 800, you would set the threshold to CloudWatch Alarms - Alarm States As an example, if the period is five minutes and the data points to alarm is 3, then the data points to monitor must cross and remain crossing the threshold for 15 minutes before the alarm goes into an ALARM state. CloudWatch Alarms - Data Points to Alarm and Evaluation Period To give an illustration, let’s say you create an alarm with a threshold of >= 40. The data points to alarm is 2, and the evaluation period is 3, so this is a 2 out of 3 alarm. Now suppose CloudWatch evaluates the following three consecutive data points: 46, 39, and 41. Two of the three data points exceed the threshold, so the alarm will transition to the ALARM state. Following that, CloudWatch evaluates the consecutive data points 45, 30, and 25. Two of the three data points fall below the threshold, so the alarm transitions to an OK state. Notice that CloudWatch must evaluate three data points (the evaluation period) before it changes the alarm state. evaluation 美[ɪˌvæljuˈeɪʃn] n. 评估 transition 美[trænˈzɪʃn] v. 转变，过渡 Amazon EventBridge (CloudWatch Events) For example, a running EC2 instance entering the stopped state would be an event. An IAM user logging into the AWS Management Console would be another event. EventBridge can automatically take immediate action in response to such events. Summary You must configure CloudWatch and AWS Config before they can begin monitoring your resources. CloudTrail automatically logs only the last 90 days of management events even if you don’t configure it. It’s therefore a good idea to configure these services early on in your AWS deployment. CloudWatch, CloudTrail, and AWS Config serve different purposes, and it’s important to know the differences among them and when each is appropriate for a given use case. CloudWatch tracks performance metrics and can take some action in response to those metrics. It can also collect and consolidate logs from multiple sources for storage and searching, as well as extract metrics from them. CloudTrail keeps a detailed record of activities performed on your AWS account for security or auditing purposes. You can choose to log read-only or write-only management or data events. AWS Config records resource configurations and relationships past, present, and future. You can look back in time to see how a resource was configured at any point. AWS Config can also compare current resource configurations against rules to ensure that you’re in compliance with whatever baseline you define. consolidate 美[kənˈsɑːlɪdeɪt] v. 合并 compliance 美[kəmˈplaɪəns] n. 遵守 Chapter 8 The Domain Name System and Network Routing: Amazon Route 53 and Amazon CloudFront Routing Policies 1. Simple is the default routing policy for new record sets. 2. Weighted Routing 3. Latency Routing. Base on your resources running in multiple AWS regions 4. Failover Routing. Set to redirect traffic to a backup resource when primary resource is offline 5. Geolocation Routing. Restrict content to regions where it’s legally permitted 6. Multivalue Answer Routing. 每个A记录对应一个ip和一个healthCheck, failover就剔除，类似ALB Summary Weighted routing policies let you direct traffic among multiple parallel resources pro\u0002portionally according to their ability to handle it. Latency routing policies send traffic to multiple resources to provide the lowest-latency service possible. Failover routing moni\u0002tors a resource and, on failure, reroutes subsequent traffic to a backup resource. Geoloca\u0002tion routing assesses the location of a request source and directs responses to appropriate resources. Amazon CloudFront is a CDN that caches content at edge locations to provide low\u0002latency delivery of websites and digital media. parallel 美[ˈpærəlel] adj. 并行的 subsequent 美[ˈsʌbsɪkwənt] adj. 随后的 appropriate 美[əˈproʊprieɪt] adj. 适当的 edge 美[edʒ] n. 边线；刀锋 Chapter 9 Simple Queue Service and Kinesis Kinesis Data Firehose vs. Kinesis Data Streams Kinesis Data Firehose, on the other hand, is not an open-ended producer-consumer model where a consumer can simply subscribe to a stream. Instead, you must specify one or more destinations for the data. Kinesis Data Firehose is tightly integrated with managed AWS services and third-party applications, so it’s generally more appropriate for streaming data to services such as Redshift, S3, or Splunk. Kinesis Data Streams, on the other hand, is usually the better choice for streaming data to a custom application. Refer to Table 9.1 for a comparison of SQS and Kinesis services. open-ended 美[ˈopənˈɛndɪd] adj. 广泛的，无限度的 specify 美[ˈspesɪfaɪ] vt. 指定 tightly 美[ˈtaɪtli] adv. 紧紧地 integrated 美[ˈɪntɪɡreɪtɪd] adj. 结合的 Summary SQS acts as a highly available buffer for data that must move between different application components. On the other hand, the Kinesis services collect, process, and store streaming, real-time binary data such as audio and video. Both SQS and the Kinesis services enable loose coupling. loose 美[luːs] adj. 松散的 coupling 美[ˈkʌplɪŋ] n. 耦合 "},"docs/saa-3.html":{"url":"docs/saa-3.html","title":"3.AWS的其他服务","keywords":"","body":"AWS的其他服务 资料 通俗解释 AWS 50个云服务每个组件的作用 Device Farm（编程使用云设备、Device Farm） # test_demo.py # 运行：pytest -s import boto3, pytest from selenium.webdriver import DesiredCapabilities from selenium.webdriver import Remote class TestDemo: def setup_method(self, method): devicefarm_client = boto3.client(\"devicefarm\", region_name=\"us-west-2\") testgrid_url_response = devicefarm_client.create_test_grid_url( projectArn=\"arn:aws:devicefarm:us-west-2:223422645499:testgrid-project:0a72e439-4fa2-48d4-9950-83764338e1e8\", expiresInSeconds=300) self. driver = Remote(testgrid_url_response[\"url\"], DesiredCapabilities.FIREFOX) def test_passing(self): assert (1, 2, 3) == (1, 2, 3) def teardown_method(self, method): self.driver.quit() AppStream（类似Citrix） Windows 远程桌面，按小时付费 1核Windows每小时 0.075 USD，空闲时 0.019 USD 用浏览器或者AppStream客户端访问 Workspaces Windows、Linux 远程桌面，按月/小时付费 1核Windows每小时 0.22 USD 用浏览器或者Workspaces客户端访问 WorkDocs 企业服务，类似DropBox Service Catalog 企业服务，用户可以访问你构建的预设应用目录 XRay Lambda 启动XRay： Console界面-Lambda-配置，启动启动XRay python语言需要定制的layer层：https://github.com/awsdocs/aws-lambda-developer-guide/tree/main/sample-apps/blank-python 默认ApiGateway没有集成XRay，需要在Console界面启动XRay（需要是REST Api） Single Sign-On（SSO） 启用AWS全球的SSO作为身份提供商，把AWS中国作为应用，见教程 AWS全球的SSO控制台添加应用，下载SAML文件 AWS中国的IAM控制台添加身份提供商（需要步骤1的SAML文件）和登录角色，下载SAML：https://signin.amazonaws.cn/static/saml-metadata.xml AWS全球的SSO控制台编辑应用，上传步骤2的SAML文件 AWS全球的SSO控制台编辑应用，Role栏类型是uri，值是步骤2的提供商和登录角色的arn，用逗号隔开；RoleSessionName栏是{user:email} 上例是本地的Identity Store支持SAML的/OpenID场景，如果不支持，则需要一个Identity Broker，它的作用是： 请求本地的Identity Store，验证登录 请求AWS的STS获取temporary security credentials Client 使用temporary security credentials使用cli操作或者在console操作 Step Functions（替代SWF） CloudFormation OpsWorks 批量服务器配置、部署和管理。 OpsWorks 是一款配置管理服务，提供 Chef 和 Puppet 的托管实例。Chef 和 Puppet 是自动化平台。 MediaConvert（原名 Elastic Transcoder） 视频转码 VPC 相关 PrivateLink Egress Internet Gateway VPC peering "},"docs/saa-4.html":{"url":"docs/saa-4.html","title":"4.AWS Github Study Guide","keywords":"","body":"AWS Github Study Guide 资料 AWS SAA-C02 Study Guide 学习 Introduction Identity Access Management (IAM) You cannot nest IAM Groups. IAM 用户组没有层级。 Simple Storage Service (S3) 内网ec2访问s3方法1：用NAT Gateway，$0.045/h，$0.045/GB 内网ec2访问s3方法2：用Gateway Endpoint，$0.01/GB CloudFront An Origin Access Identity (OAI) is used for sharing private content via CloudFront Snowball Planes sometimes fly with snowball edges onboard so they can store large amounts of flight data Storage Gateway Cached Volumes differ as they do not store the entire dataset locally like Stored Volumes. Elastic Compute Cloud (EC2) EC2 Not billed if preparing to stop. Billed if preparing to hibernate Elastic Block Store (EBS) The easiest way to move an EC2 instance and a volume to another availability zone is to take a snapshot. Elastic Network Interfaces (ENI) You can attach the ENI to a hot standby instance. Security Groups Security Groups are regional and can span AZs Web Application Firewall (WAF) WAF can either allow the request by serving the requested content or return an HTTP 403 Forbidden status. CloudWatch CloudWatch Alarms Actions can be an Amazon EC2 action, Auto Scaling action, or SNS. CloudTrail By default, CloudTrail Events log files are encrypted using Amazon S3 SSE. Elastic File System (EFS) EFS using the NFSv4 protocol. This makes it required to open up the NFS port for our security group. Amazon FSx for Windows You can use Microsoft Active Directory to authenticate into the file system. Amazon FSx for Lustre FSx Lustre has the ability to store and retrieve data directly on S3 on its own. Relational Database Service (RDS) RDS is not serverless. There is Aurora serverless however which serves a niche purpose. A SQS queue however ensures that writes to the DB do not become lost. Multi-AZ creates a primary DB instance and synchronously replicates the data to a standby instance in a different AZ. Multi-AZ is supported for all DB flavors, Aurora is completely fault-tolerant on its own. Multi-AZ RDS configuration, backups are taken from the standby. If the master DB were to fail, there is no automatic failover. You can manually promote read replicas to be the master. IAM database authentication works with MySQL and PostgreSQL. You can only enable encryption for an Amazon RDS DB instance when you create it. Encrypted instance can't be modified to disable encryption. Aurora Aurora serverless uses for this service are infrequent, intermittent, and unpredictable workloads. DynamoDB DAX does more than just increase read performance by having write through cache. This improves write performance as well. Global Table failover is as simple as redirecting your application’s DynamoDB calls to another AWS region. Replication latency with Global Tables is typically under one second. Redshift ElasticCache Route53 Elastic Load Balances (ELB) Auto Scaling Virtual Private Cloud (VPC) Simple Queuing Service (SQS) Simple Workflow Service (SWF) Simple Notification Service (SNS) Kinesis Lambda API Gateway CloudFormation ElasticBeanstalk AWS Organizations Miscellaneous "},"docs/tidb-1.html":{"url":"docs/tidb-1.html","title":"1.TiDB 基础知识","keywords":"","body":"TiDB 基础知识 基础知识 TiDB 系统管理基础 - 视频 18年的压测和19年的压测表明：TiDB的性能只有MySQL的一半 新一代数据库TiDB在美团的实践 美团对TiDB的定位：支持二级索引；跨region failover；跨region双写 TiDB对比ClickHouse：ClickHouse跑低频SQL可以，跑高频SQL不行，且跑全量低频SQL会发生overkill；TiDB则可以胜任。 传统分库分表方案的弊端：业务无法友好的执行分布式事务；跨库的查询需要在中间层上组合(不支持跨库join)；再次拆分的成本高 CatKang - NewSQL数据库概述 分库分表：part1是中间件，part2是单机。代表有阿里云DRDS。 Spanner：part1是server层，part2是engine层。代表有TiDB、OceanBase。分布式事务的四个特性： Atomicity：单机靠redo+undo；分布式靠redo+undo+2PC Consistency Isolation：单机靠2PL+MVCC(本地时钟)；分布式靠2PL+MVCC(Lamport or TrueTime时钟) Durability：单机靠redo；分布式靠redo+Multi-Paxos Partition Storage：part1是server、engine层，part2是存储。代表有Aurora、PolarDB。 // undo 的流程 日志1记录t=0，数据t=1，标记* 日志2记录t=1，数据t=2 日志3记录t=2，数据t=3，标记* 日志4记录t=3，数据t=4 标记为*后表示事务已提交，此时日志1和日志3可以删除 数据恢复时，只需要恢复日志4和日志2即可 // redo的流程 日志1记录t=1，标记为*，数据t=1 日志2记录t=2 日志3记录t=3，标记为* 日志4记录t=4 标记为*后表示事务已提交，此时需要等数据落盘后才能删除，日志1可以删除，日志3不能 数据恢复时，只需要恢复标记为*日志即可 热点问题处理思路 TiDB 最佳实践系列（一）高并发写入常见热点问题及规避方法 高并发批量插入会有region热点问题，可以通过预先split region解决 7.2 热点问题处理思路 · TiDB in Action 确认热点问题：Grafana 的 TiKV-Trouble-Shooting 的 Dashboard 的 Hot Read 和 Hot Write 面板 确认热点表或索引：pd-ctl region topwrite|topread 3；TiDB Dashboard的流量可视化。 写入热点的业务场景通常有： 有自增主键：去掉自增主键并设置 SHARD_ROW_ID_BITS（可动态设置，SHARD_ROW_ID_BITS=4表示16个分片）。 存在递增索引，比如时间索引等：手工切分热点 Region。 高并发更新小表：改造小表为 hash 分区表。 秒杀场景下的单行热点问题：业务层面用内存缓存解决。 TiKV 架构 TiKV 简介 | PingCAP Docs RocksDB 简介 | PingCAP Docs Region 副本(Peer)的三个角色：Leader负责读写可投票；Follower可随时替换Leader可投票；Learner是不完整的副本，不可投票。 每个 TiKV 实例中有两个 RocksDB 实例 一个用于存储 Raft 日志（通常被称为 raftdb） 一个用于存储用户数据以及 MVCC 信息（通常被称为 kvdb） TiDB Cluster 部署 安装：pd是大脑（3台）、tidb是无状态的server（2台）、tikv（3台，默认3个副本） 安装：需先安装numactl。tiup cluster template > topology.yaml，去掉TiFlash配置 考试大纲 TiDB 数据库体系架构 分布式数据库原理 分布式 SQL 引擎：不支持MySQL的存储过程与函数、触发器、事件、外键 分布式存储系统 基于分布式架构的 HTAP 数据库 TiDB 典型应用场景及用户案例 TiDB 集群管理 TiDB Cluster 部署：tiflash的扩容和缩容略有不同 TiDB 的连接管理：MyCli也可以连接 TiDB 的配置： 集群配置（tidb、tikv、pd，需修改配置文件并重启） 系统配置（存在tikv中，有作用域，session只对当前会话生效，global对新启的会话生效） 用户管理与安全：mysql分用户和角色，attach角色后，用户登录需要执行set role all TiDB 文件与日志管理：tikv和pd有日志和数据、tidb只有日志 TiDB 的监控：pd内置Dashboard，Prometheus内置Alert-manager TiDB Cluster的升级：升级TiUP->升级TiUP Cluster->检查集群状态->升级TiDB Cluster TiDB 备份恢复 备份恢复策略 热备不会锁定如何的读写操作 适用备份恢复工具 BR 进行备份恢复 br是热备、物理备份。不需要额外安装组件。 br可增量备份，指定参数--lastbackupts将备份last_backup_ts到current_ts之间的数据。 br backup all命令把数据备份在各个tikv节点的硬盘下。 br restore all需要各个tikv的硬盘下有全量的备份文件。 TiDB 数据迁移 数据导出工具 Dumpling Dumpling是热备、逻辑备份。不需要额外安装组件。不能增量备份。 指定参数--consistency snapshot：按照指定的ts导出（ts由--snapshot参数指定） 指定参数--consistency flush：适合备份MySQL，会短暂的中断DML和DDL操作 Lightning是对应的还原命令 数据导入工具 TiDB Lightning 不需要额外安装组件。 数据迁移工具 TiDB Data Migration 需要安装DM集群：包含DM-master、DM-worker组件。 DM可以配置多个源库，把分库分表汇聚到一个TiDB中。 Block/Allow Table Lists 用于过滤库/表的所有操作 Binlog event filter 用于过滤特定表的特定操作 Table routing 指定源库和目标库的对应关系 TiDB 数据同步与复制 数据同步工具 TiDB Binlog（已废弃，请使用TiCDC） 需要在TiDB集群中增加组件：pump（收集binlog），drainer（归并pump的binlog） 数据同步工具 TiCDC 需要在TiDB集群中增加组件：cdc_server CDC是基于tikv的change log来实现同步的 CDC的目标库可以是TiDB、MySQL、Kafaka "},"docs/tidb-2.html":{"url":"docs/tidb-2.html","title":"2.TiDB in Action: 原理和特性","keywords":"","body":"TiDB in Action: 原理和特性 2.讲存储 TiDB 高并发写入场景最佳实践 TiDB Best Practice 三篇文章了解 TiDB 技术内幕 - 讲存储 Raft 是一个一致性协议，提供几个重要的功能： Leader 选举 成员变更 日志复制 每个数据变更都会落地为一条 Raft 日志，再通过 Raft 的日志来同步副本数据 3.说计算 三篇文章了解 TiDB 技术内幕 - 说计算 TiDB 最底层用 Raft 来同步数据。每次写入都要写入多数副本，才能对外返回成功。 比如最大 3 副本的话，每次写入 2 副本才算成功。写入的延迟取决于最快的两个副本，而不是最慢的那个副本。 分布式事务采用的乐观锁。缺点只有在真正提交的时候，才会做冲突检测，所以在冲突严重的场景下性能低下。 数据表的数据或者索引具有相同的前缀，这些 Key-Value 会在相邻的位置。批量写入会在很少的几个 Region 上形成写入热点，成为整个系统的瓶颈。 二级索引的特点：尽量用区分度比较大的列；最左原则；数据分散在很多Region上，并发查询的Region数可配 建议每个事务的行数不超过 200 行，且单行数据小于 100k，否则可能性能不佳。 主键索引：key：tableID、rowID；value：\\[col1, col2, col3, col4...] 唯一索引：key：tableID、indexID、indexedColumnsValue；value：rowID 非唯一索引：key：tableID、indexID、indexedColumnsValue、rowID；value：null // 举例有张Age，tableID=10，它的非唯一索引indexID=1，它的唯一索引indexID=2，有三条数据如下 ID Name Role Age 1, \"TiDB\", \"SQL Layer\", 10 2, \"TiKV\", \"KV Engine\", 20 3, \"PD\", \"Manager\", 30 // 主键索引 t10_r1 --> [\"TiDB\", \"SQL Layer\", 10] t10_r2 --> [\"TiKV\", \"KV Engine\", 20] t10_r3 --> [\"PD\", \"Manager\", 30] // 唯一索引[Name] t10_i2_TiDB --> 1 t10_i2_TiKV --> 2 t10_i2_PB --> 3 // 非唯一索引[Age] t10_i1_10_1 --> null t10_i1_20_2 --> null t10_i1_30_3 --> null 4.谈调度 三篇文章了解 TiDB 技术内幕 - 谈调度 TiDB 最佳实践系列（二）PD 调度策略最佳实践 相关概念 Store：即TiKV实例 Region：若Region有3个副本，也即3个Peer。每个Region有1个raft实例，也称Raft Group。 Pending / Down：是Peer可能出现的两种特殊状态 Pending 表示 Follower 或 Learner 的 raft log 与 Leader 有较大差距，Pending 状态的 Follower 无法被选举成 Leader。 Down 是指 Leader 长时间没有收到对应 Peer 的消息，可能是宕机或者网络隔离。 Scheduler：是PD的调度器，常用的调度器有： balance-leader-scheduler：保持不同节点的 Leader 均衡。 balance-region-scheduler：保持不同节点的 Peer 均衡。 hot-region-scheduler：保持不同节点的读写热点 Region 均衡。 evict-leader-{store-id}：驱逐某个节点的所有 Leader。（常用于滚动升级） TiKV 节点周期性地向 PD 上报 StoreHeartbeat 和 RegionHeartbeat 两种心跳消息。 StoreHeartbeat 包含了 Store 的基本信息，由 Store 定期向 PD 汇报。 总磁盘容量 可用磁盘容量 承载的 Region 数量 数据读写速度 发送/接受的 Snapshot 数量（副本之间可能会通过 Snapshot 同步数据） 是否过载 标签信息 RegionHeartbeat 包含了 Region 的相关信息，由 Raft Group 的 Leader 定期向 PD 汇报。 Leader 的位置 Followers 的位置 掉线副本的个数 数据读写速度 5.TiDB 和 MySQL 的区别 MySQL 的时区由环境变量 TZ 或命令行参数 --timezone 决定 TiDB 的时区由 TiDB 节点环境变量配置 TZ 决定 6.TiDB 事务模型 6.TiDB 事务模型 · TiDB in Action 快照隔离。TiDB 使用 PD 作为全局授时服务（TSO）来提供单调递增的版本号（timestamp） 事务开始时获取 start timestamp 事务提交时获取 commit timestamp，同时也是数据的版本号 事务只能读到在事务 start timestamp 之前的数据（已提交的） 事务在提交时会根据 timestamp 来检测数据冲突 TiDB 开始两阶段提交 TiDB 向 TiKV 发起 Prewrite 请求。TiKV 检查冲突并加锁。 TiDB 收到所有 Prewrite 响应且所有 Prewrite 都成功。 TiDB 向 TiKV 发起第二阶段提交。TiKV 执行提交。 TiDB 收到所有成功响应则 Success，否则回滚。 乐观锁大事务的缺点：一个事务内包含向10000人转账，过程中有另一个事务向其中一人转账并成功，此大事务提交失败并回滚。 悲观锁性能不如乐观锁：事务内每个 DML 时都需要向 TiKV 发送加锁请求（建议将多条 DML 合并成 一条） 4.0 版本之前对大事务有严格限制，原因有： Prewrite 写下的锁会阻塞其他事务的读，Prewrite 时间长，阻塞的时间也就长。 大事务 Prewrite 时间长，可能会被其他事务终止导致提交失败。 7.TiDB DDL 7.TiDB DDL · TiDB in Action 表结构设计最佳实践 设置 SHARD_ROW_ID_BITS 来把 rowID 打散写入多个不同的 Region 中 设置 AUTO_RANDOM 代替 AUTO_INCREMENT 插入数据时自动为整型分配一个随机值 4.0 版本的 PD 会提供 Load Based Splitting 策略，除了根据 Region 的大小进行分裂，还可以根据 QPS。 按日期删除老数据，正常的删除会很慢。如果按日期建立分区表则很快：避免了往TiKV写delete记录，避免了RocksDB的compaction引发的抖动 修改表不允许降低字段长度 不要设计过大的宽表 DDL命令： ADMIN SHOW DDL JOBS 5; 显示最近5条DDL命令 ADMIN SHOW DDL JOB QUERIES {job_id}; 显示DDL详细信息 ADMIN CANCEL DDL JOBS {job_id}; 取消DDL命令 DDL 处理流程： 每个 DDL 命令有一个 job_id 并保存在 tikv TiDB 实例会竞选出一个 Owner 节点来执行实际 DDL 任务 两个队列：ADD_INDEX 和非 ADD_INDEX；job_id 小的 DLL 先执行； DDL 变更原理 schema 最多有两个版本，版本状态有absent、delete only、write only、public 删除操作如DROP INDEX，DROP TABLE，DROP DATABASE，TRUNCATE TABLE等，先记录到gc_delete_range表，再通过GC机制删除 DELETE COLUMN代价比较大，所以只在schema上标记删除 DDL 变更原理 Add column operation：只更新schema，新的row是新结构，查询老的row就依据schema的默认值返回 Modify column operation：转换column的类型只支持整型(lengthened)；auto_increment只能在新建表的时候设置；如果索引有用到此column，索引的schema也需改变(但原始数据不变) Add index operation：先生成好index再把index设置为可用，耗时较长 Sequence 自增序列 CREATE SEQUENCE seq_for_unique START WITH 1 INCREMENT BY 1 CACHE 1000 NOCYCLE; 创建序列 SHOW CREATE SEQUENCE seq_for_unique；获取创建序列的SQL DROP SEQUENCE seq_for_unique；删除序列 SELECT NEXT/PREVIOUS VALUE FOR seq_for_unique; 获取下一个/上一个自增值 CREATE TABLE user ( auto_id int(11) DEFAULT 'nextval(test.seq_for_unique)' ); 表字段使用自增序列 AutoRandom 只能用在主键上，不能用在唯一索引 8.Titan 简介与实战 Titan 简介与实战 · TiDB in Action Titan 利用SSD随机IO的优势，以牺牲硬盘空间和范围查询的性能为代价，换取更高的写入性能。 Titan 磁盘空间占用可能比 RocksDB 多一倍。 Titan 范围查询性能相比 RocksDB 下降 40% 到数倍不等。 Titan 适合大value的插入，大于512B即为大value，默认设定是大于1KB。 9.TiFlash 简介与 HTAP 实战 TiFlash 简介与 HTAP 实战 · TiDB in Action TiFlash 以Raft Learner的方式接入Multi-Raft组，使用异步的方式同步数据，同时将行格式拆解为列格式 TiFlash 的使用： ALTER TABLE tpch50.lineitem SET TIFLASH REPLICA 2; 设置2个TiFlash副本 SELECT * FROM information_schema.tiflash_replica WHERE TABLE_SCHEMA='tpch50' and TABLE_NAME='lineitem'; 查看副本 TiFlash 的使用，手工Hint > 会话级别 > Engine级别 > CBO CBO (Cost Based Optimization)：根据优化器来决定是读TiKV还是TiFlash 会话级别：SET SESSION tidb_isolation_read_engines = \"tikv,tiflash\"; Engine级别，实例配置：isolation-read.engines = [\"tikv\", \"tiflash\"] 手工Hint：SELECT /+ read_from_storage(tiflash[t]) / * FROM t; 10.TiDB 安全 权限管理 创建用户：CREATE USER 'developer'@'192.168.0.%' IDENTIFIED BY 'password'; 授权用户：GRANT SELECT ON db1.table1 TO 'developer'@'192.168.0.%'; 修改密码：ALTER USER 'developer'@'192.168.0.%' IDENTIFIED BY 'password'; RBAC 创建角色：create role reader@'%'; 授权角色：grant select on db1.table1 to reader'%'; 角色给用户：grant reader to developer'192.168.0.%'; 连接后：set role reader; 使角色生效 证书管理与数据加密 证书来确认身份，登陆后使用加密连接来传输数据。越来越多的用户使用证书鉴权来代替用户名密码验证。 用户需要生成：服务端密钥和证书，客户端密钥和证书。再用CA密钥和证书对服务端证书和客户端证书进行签名。 生成CA密钥和证书：ca-key.pem、ca-cert.pem 生成服务器密钥和证书：server-key.pem、server-cert.pem(CA密钥和证书) 生成客户端密钥和证书：client-key.pem、client-cert.pem(CA密钥和证书) 验证证书是否正确：openssl verify -CAfile ca-cert.pem server-cert.pem client-cert.pem 服务器需要存放CA证书、服务端密钥和证书 客户端需要存放CA证书、客户端密钥和证书 CA密钥则需要离线保管 TiSpark 的简介和实战 Spark架构与原理这一篇就够了 Hadoop和Spark的区别 Spark 是为了跟 Hadoop 配合而开发出来的，不是为了取代 Hadoop Hadoop 一次 MapReduce 之后结果写入磁盘中，二次 MapReduce 时从磁盘读取，瓶颈在2次运算多余的 IO 消耗 Spark 则是将数据一直缓存在内存中直到计算得到最后的结果，再写入磁盘 Hadoop 集群的 Hive 表廉价，稳定且成熟，不适合存放频繁变化的数据。 "},"docs/tidb-3.html":{"url":"docs/tidb-3.html","title":"3.TiDB in Action: 部署与管理","keywords":"","body":"TiDB in Action: 部署与管理 1.部署安装和常见运维 TiUP 命令 升级TiUP：tiup update --self 扩容：配置scale.yaml填上要扩容的节点ip和端口，执行tiup cluster scale-out tidb-test scale.yaml 缩容：tiup cluster scale-in prod-cluster -N 172.16.5.140:20160 升级 PD：优先升级非 Leader 节点；再将 Leader 迁移到升级完成的节点上；再升级旧的 Leader 节点 升级 TiKV： 先在 PD 中添加一个迁移对应 TiKV 上 region leader 的调度 再对该 TiKV 节点进行升级更新 等更新后的 TiKV 正常启动之后再移除迁移 Leader 的调度 备份恢复和导入导出 增量数据订阅工具 CDC 工作原理：TiKV 负责拼装 KV 变更日志（Change Logs），并输出到 TiCDC 集群。 数据导入工具 Lightning 分布式备份和恢复工具 BR 数据导出工具 Dumpling "},"docs/tidb-4.html":{"url":"docs/tidb-4.html","title":"4.TiDB in Action: 故障排查","keywords":"","body":"TiDB in Action: 故障排查 1.SQL 调优原理 EXPLAIN：执行计划由一系列的算子构成。 id：后缀带Build总是先于Probe执行 estRows：估算的输出条数 task：有两种，root在tidb执行，cop在tikv上并发执行 access object：算子所访问的数据项，如table、partition、index operator info：算子的其它信息 EXPLAIN ANALYZE：真实执行SQL，和执行计划一并返回出来，可以视为EXPLAIN语句的扩展 actRows：真实的输出条数 execution info：time:总时间, loops:此算子循环了几次 算子读盘或者读TiKV： TableFullScan：这是大家所熟知的 “全表扫” 操作 TableRangeScan：带有范围的表数据扫描操作，通常扫描的数据量不大 TableRowIDScan：根据上层传递下来的 RowID 精确的扫描表数据的算子 IndexFullScan：另一种 “全表扫”，只不过这里扫的是索引数据，不是表数据 IndexRangeScan：带有范围的索引数据扫描操作，通常扫描的数据量不大 算子读TiDB： TableReader：汇总 TiKV 上底层扫表算子是 TableFullScan 或 TableRangeScan 的算子。 IndexReader：汇总 TiKV 上底层扫表算子是 IndexFullScan 或 IndexRangeScan 的算子。 IndexLookUp：先汇总Build端TiKV扫描上来的RowID，再去Probe端上根据RowID取TiKV。Build端是IndexFullScan、IndexRangeScan，Probe端是TableRowIDScan。 IndexMerge：和IndexLookup类似，不过支持多个build和Probe 3 种最基本的算子： Selection： 代表了相应的过滤条件，select * from t where a = 5 中的 where a = 5。 Projection：投影操作，也用于表达式计算， select c, a + b from t 里面的 c 和 a + b就是投影和表达式计算操作。 Join：两个表的连接操作 2.TiDB Dashboard 流量可视化：查看热点region SQL 语句分析：查看所有的sql语句的平均执行时间，平均影响行数，执行次数 生成集群诊断报告 日志搜索：搜索集群的系统日志 3.诊断系统表 集群信息表：select type, instance, status_address, uptime from information_schema.cluster_info; 慢查询：select query_time, SUBSTR(query,1,50) from information_schema.slow_query 当前的会话：SHOW FULL PROCESSLIST; Statement Summary 系统表，对同类SQL进行汇总 Statement Summary Tables 是内存表 tidb_enable_stmt_summary：打开或关闭该功能 tidb_stmt_summary_refresh_interval：监控指标的刷新周期 tidb_stmt_summary_history_size：历史表保存的历史数量 max-stmt-count：保存的 SQL 的种类数量 max-sql-length：显示的 SQL 的最大长度 4.TiDB 集群监控与报警 Prometheus主动pull数据，在Grafana展示，用Alertmanager报警 TiDB层： token-limit配置控制并发的session数量，建议小于500，且99.9%的请求小于0.5秒 Get Token Duration 需小于2纳秒 Parse SQL to AST 需小于10毫秒 AST to Physical Execution Plan 需小于30毫秒 tidb_max_chunk_size配置控制一次函数调用返回的数据条数，默认1000 生成的物理执行计划会在【Executor模块】中进行执行 如果是DML语句，先缓存在【Transaction模块】，等待事务提交时进行2PC提交 如果是复杂查询，则需通过【DistSQL模块】并发查多个region tidb_distsql_scan_currency配置控制每次并发查多少个region，默认15 Get TSO from PD 需小于30毫秒，为了减少PD的压力，TiDB通过单个线程一次为多个事务分配时间 TiKV主要由5个模块构成 gRPC 是所有请求的入口，写事务给scheduler线程，读事务给unified-readpool scheduler 检测冲突，将复杂的事务转换为简单的kv插入、删除，发送给raftstore线程 raftstore 将raft日志复制给多个副本，当日志在多个副本上达成一致后，会发送给apply线程 apply 将scheduler线程的kv操作写入RocksDB，通知gRPC线程返回结果给客户端 unified-readpool 处理single get、batch get等简单的查询请求 RocksDB 的三种基本文件格式 Memtable 内存文件系统，新数据会被写进Memtable WAL Write Ahead Log 写操作先写入logfile，再写入Memtable SST 在Memtable写满以后，将数据写入磁盘中的SST文件，对应logfile里的log会被安全删除。 RocksDB 查询流程：先在Memtable内存查找，SST先用布隆过滤器查 5.灾难快速恢复 执行了错误的更新、删除操作【利用 GC 快照读恢复数据】 MVCC 当更新/删除数据时，不会做真正的数据删除，只会添加一个新版本数据，并以时间戳来区分版本，后台GC清理久远版本 tikv_gc_life_time 默认是10m，即能恢复最近10分钟内的数据，也改成24h 执行了drop或truncate，【Recover/Flashback 命令秒恢复误删表】 在gc时间内，直接执行recover table flashback table不仅支持drop操作，还支持truncate操作 多数副本不可用【多数副本丢失数据恢复指南】 Region至少还有1个副本：移除故障节点的peer，让Region重新选举和补充副本 Region所有副本都丢失了：创建1个空Region来解决Region不可用的问题 丢失数据处理：检查数据的一致性 "},"docs/tidb-5.html":{"url":"docs/tidb-5.html","title":"5.TiDB in Action: 最佳实践","keywords":"","body":"TiDB in Action: 最佳实践 1.适用场景介绍 分库分表的缺点： 业务需要提供切分维度 不支持在线 DDL 操作，不能在线进行扩缩容 不能跨维度 Join / 聚合 / 子查询，不支持分布式事务。 业务程序从单机数据库迁移到分库分表方案时，通常要完成大量的开发适配改造。 不能实现一致性的备份还原，难以实现异地容灾等。 2.硬件选型规划 TiDB server 组件 整个系统的瓶颈大概率先出现在 tidb-server tidb-server 的 cpu 高一点，数量多一点是一个更好的选择。 PD 组件 推荐使用 SSD 磁盘。至少三个节点。单独部署。 TiKV 组件 建议你为 TiKV 多分配或预留些资源 实例个数推荐是副本数的倍数 监控组件：8GB 内存、2核 CPU 在大多数情况下已经够用 3.常见性能压测 TPC-C 测试模型给基准测试提供了一种统一的测试标准。 BenchmarkSQL 内嵌了 TPC-C 测试脚本，可以测试 PostgreSQL、MySQL、Oracle、TIDB NewSql的tpcc测试 percona的sysbench-tpcc测试CRDB和TiDB percona的tpcc-mysql可以测试TiDB TiDB的自家方案：改造BenchmarkSQL CRDB的自家方案：自己开发的，也可以用BenchmarkSQL // 新建配置sysbench/tidb_conf mysql-host=192.168.xxx.xxx mysql-port=4000 mysql-user=sysbench mysql-password=****** mysql-db=test time=30 //总测试时间 threads=4 //线程数 report-interval=10 //10秒出一次报告 db-driver=mysql //mysql或pgsql // 测试insert，若--tables=2，表示插入2张表sbtest1、sbtest2，分别插入10000条数据 sysbench --config-file=sysbench/tidb_conf oltp_point_select --tables=1 --table-size=10000 prepare // 测试select sysbench --config-file=sysbench/tidb_conf oltp_point_select --tables=1 --table-size=10000 run // 测试update index sysbench --config-file=sysbench/tidb_conf oltp_update_index --tables=1 --table-size=10000 run 4.跨数据中心方案 两中心方案： 两中心副本数相同：两中心同时对外提供读写 两中心副本数是2:1：一个是主机房，一个是灾备机房 两地三中心：其中两个机房在同城市，一个机房在其他城市 集群1采用两地三中心，分别为北京 IDC1，北京 IDC2，西安 IDC3，是主集群 集群2从集群1通过binlog复制，机房在西安 IDC3，是从集群 5.数据迁移方案 6.业务适配最佳实践 乐观锁的缺点如下： 两阶段提交，网络交互多。 需要一个中心化的版本管理服务。 事务在 commit 之前，数据写在内存里，数据过大内存就会暴涨 减少乐观锁写写冲突 使用TiDB悲观锁, 或者redis分布式锁 使用消息队列时，将同一行的读写分配到同一个队列，这样就会串行写入TiDB 将大事务拆解成多个小事务以减少单个事务的运行时间 tidb的一个事务转化到tikv的查询次数： 一次insert：1次数据insert+相关索引insert 一次delete：1次数据delete flag+相关索引delete flag 一次update：1次数据update+相关索引delete flag和insert 雪花算法uid-generator六十四位方案 sign：固定为 0，表示生成的 ID 始终为正数。 delta seconds：默认 28 位。基于2016-05-20开始的秒数。最多可支持约 8.7 年。 worker node id：默认 22 位。从一个集中式的ID生成器取得(Zookeeper)。最多可支持约420万次启动。 sequence：默认 13 位。表示每秒的并发序列，13 位可支持每秒 8192 个并发。 批量update的方案： 坏的：set field1=value1 order by id limit 0,1000 好的：set field1=value1 where id between 100000 and 102000（需事先分好范围） SQL 调优案例 大批量Delete。改成分批Delete 统计信息不准导致查询计划不准。修复：analyze table test.t1; TiDB 分区表 主键和唯一索引必须包含分区表达式中用到的所有列 Range 分区可以用于解决业务中大量删除带来的性能问题，支持快速删除分区 Hash 分区表来一定程度上解决写热点问题 清理分区：ALTER TABLE employees_attendance TRUNCATE PARTITION p20200306; 更新统计信息：ALTER TABLE employees_attendance ANALYZE PARTITION p20200306; 7.常见问题处理思路 TiKV 只执行过 INSERT 而没有 UPDATE 和 DELETE 的话（不考虑索引的大小） 单节点 10GB 数据最多占据 (512MB + 1GB + 10GB) * 3 的物理空间 每一层的大小是上一层的十倍，所以倒数第一层是 10GB，倒数第二层是 1GB 512MB 为 L0 的 SST 文件大小 TiKV 的写入性能周期性下降问题（10～20 分钟一轮） 由 TiKV 的 GC 引起，可以控制 GC 的速度 TiKV 的配置 gc.max-write-bytes-per-sec 建议在 128KB ~ 512KB，默认是 0。 RocksDB 中被 GC 删除的数据会很快被 compact 到下一层。 TiKV 提供 snappy，zlib，bzip2，lz4，lz4hc，zstd 等六种压缩算法。默认为 [\"no\", \"no\", \"lz4\", \"lz4\", \"lz4\", \"zstd\", \"zstd\"] 只有当数据量超过 500G 时 RocksDB 的层数才会超过 4。 只有当数据量超过 500G 部分的数据才会启动 ZSTD 压缩算法。 8.TiDB 调优指南 TiDB 常见配置优化 max_execution_time，执行时间，超过则终止执行 tidb_mem_quota_query，一条查询语句的内存使用阈值，超过则记log tidb_retry_limit，事务重试次数，默认是10 tidb_disable_txn_auto_retry，禁用事务重试，默认是On tidb_distsql_scan_concurrency，算子的并发个数 TiKV 常见配置优化 Raftstore 线程性能问题：增加TiKV节点；调高raftstore.store-pool-size；merge region。 创建索引：通过 admin show ddl 命令来查询 RowCount 和 START_TIME 字段 START_TIME表示开始执行时间，RowCount表示已经创建的行数，由此可以判断剩余执行时间 "}}