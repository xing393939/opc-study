### åˆ˜äºŒå¤§äºº

<script>
Â Â MathJaxÂ =Â {
Â Â Â Â tex:Â {
Â Â Â Â Â Â inlineMath:Â [['$',Â '$'],Â ['\\(',Â '\\)']],
Â Â Â Â Â Â displayMath:Â [["$$",Â "$$"],Â ["\\[",Â "\\]"]],
Â Â Â Â },
Â Â Â Â svg:Â {
Â Â Â Â Â Â fontCache:Â 'global'
Â Â Â Â }
Â Â };
</script>
<scriptÂ type="text/javascript"Â id="MathJax-script"Â async
Â Â src="https://static-621585.oss-cn-beijing.aliyuncs.com/mathjax-v3.js">
</script>

#### å‚è€ƒèµ„æ–™
* [PyTorch-1.8.0æ–‡æ¡£](https://devdocs.io/pytorch)
* [åˆ˜äºŒå¤§äºº-cnblog](https://www.cnblogs.com/zhouyeqin/category/2231506.html)
* [åˆ˜äºŒå¤§äºº-zhihu](https://zhuanlan.zhihu.com/p/166104074)
* [numpyåœ¨çº¿è¿è¡Œ](https://onecompiler.com/python/3zqwrqg2r)
* [floatçš„è¡¨ç¤º](https://zhuanlan.zhihu.com/p/503336736)ï¼šç¬¦å·(1b)ã€é˜¶ç (8b)ã€å°¾æ•°(23b)
  * 0.875ï¼š0.111ï¼Œéœ€è¦å³ç§»1ä½ï¼Œé˜¶ç =127+(-1)ï¼Œå°¾æ•°=11
  * 6.360ï¼š110.01011100ï¼Œéœ€è¦å·¦ç§»2ä½ï¼Œé˜¶ç =127+2ï¼Œå°¾æ•°=10010111000010100011111
  * 2^23 = 8388608ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ‰æ•ˆæ•°å­—åœ¨Â±8388608å†…çš„æ•´æ•°å’Œå°æ•°ï¼Œç²¾åº¦ä¸ä¼šæŸå¤±
* torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd)  
  * lræ˜¯å­¦ä¹ ç‡ï¼Œmomentumæ˜¯å†²é‡ï¼Œweight_decayæ˜¯é˜²æ­¢è¿‡æ‹Ÿåˆ

#### ç¬¬äºŒè®²-çº¿æ€§æ¨¡å‹
* MSEï¼šå‡å€¼å¹³æ–¹è¯¯å·®(Mean Square Error)ï¼Œ$MSE=\frac{1}{N} \sum\limits_{n=1}^N (\hat{y}_n - y_n)^2$
* è®­ç»ƒé›†(1,2)ã€(2,4)ã€(3,6)ï¼Œç”¨ç©·ä¸¾æ³•é¢„æµ‹x=4æ—¶ï¼Œyçš„å€¼ï¼š
  * å‡è®¾æ¨¡å‹æ˜¯y = ğœ” * xï¼Œæ±‚ğœ”çš„å€¼
  * for (ğœ”=0; ğœ”<4.1; ğœ”+=0.1)ï¼Œä¾æ¬¡æ±‚å‡ºMSEï¼Œå–MSEæœ€ä½æ—¶ğœ”çš„å€¼

#### ç¬¬ä¸‰è®²-æ¢¯åº¦ä¸‹é™æ³•
* è®­ç»ƒé›†(1,2)ã€(2,4)ã€(3,6)ï¼Œç”¨æ¢¯åº¦ä¸‹é™æ³•é¢„æµ‹x=4æ—¶ï¼Œyçš„å€¼ï¼š
* æ¢¯åº¦ä¸‹é™ï¼š
  * å‡è®¾æ¨¡å‹æ˜¯y = ğœ” * xï¼Œæ±‚ğœ”çš„å€¼
  * å…ˆé€‰å®šğœ”=1
  * ä¸‹ä¸€ä¸ª$ğœ”=ğœ”-Î±\frac{ğœ•cost}{ğœ•ğœ”}$ï¼Œå…¶ä¸­Î±è¡¨ç¤ºæ­¥é•¿ï¼Œcostå³MSE
  * ä¸‹ä¸€ä¸ª$ğœ”=ğœ”-Î±\frac{1}{N}\sum\limits_{n=1}^N 2.x_n.(x_n.ğœ” - y_n)$
  * æ­¥é•¿å®šä¸º0.01ï¼Œè¿­ä»£100æ¬¡ï¼Œè§‚å¯ŸMSEå€¼æ˜¯å¦ä¼šæ”¶æ•›
* éšæœºæ¢¯åº¦ä¸‹é™ï¼š
  * å‡è®¾æ¨¡å‹æ˜¯y = ğœ” * xï¼Œæ±‚ğœ”çš„å€¼
  * å…ˆé€‰å®šğœ”=1
  * ä¸‹ä¸€ä¸ª$ğœ”=ğœ”-Î±\frac{ğœ•loss}{ğœ•ğœ”}$ï¼Œå…¶ä¸­Î±è¡¨ç¤ºæ­¥é•¿ï¼Œ$loss = (\hat{y}_n - y_n)^2 \quad \frac{ğœ•loss}{ğœ•ğœ”} = 2.x_n.(x_n.ğœ” - y_n)$
  * æ­¥é•¿å®šä¸º0.01ï¼Œè¿­ä»£100æ¬¡ï¼Œè§‚å¯Ÿlosså€¼æ˜¯å¦ä¼šæ”¶æ•›
* æ¢¯åº¦ä¸‹é™å’Œéšæœºæ¢¯åº¦ä¸‹é™
  * éšæœºæ¢¯åº¦ä¸‹é™éœ€è¦ç­‰å¾…ä¸Šä¸€ä¸ªå€¼è¿è¡Œå®Œæ‰èƒ½æ›´æ–°ä¸‹ä¸€ä¸ªå€¼ï¼Œæ— æ³•å¹¶è¡Œè®¡ç®—
  * éšæœºæ¢¯åº¦ä¸‹é™å¯ä»¥æœ‰æ•ˆè§£å†³éç‚¹é—®é¢˜
  * æŠ˜ä¸­çš„åŠæ³•æ˜¯mini_batch

#### ç¬¬å››è®²-åå‘ä¼ æ’­
* å‡è®¾æ¨¡å‹æ˜¯$y = ğœ” * x$ï¼Œæ±‚ğœ”çš„å€¼ï¼Œ[è§å›¾](../images/back-propagation.png)
* å‡è®¾æ¨¡å‹æ˜¯$y = ğœ” * x + b$ï¼Œ[äººå·¥æ™ºèƒ½åŸç†-æ›²é¢æ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­](https://blog.csdn.net/wanlin_yang/article/details/129263378)
  * $loss = (ğœ”x + b - y)^2 = x^2ğœ”^2 + (2x.b - 2x.y)ğœ” + (y^2 + b^2 - 2y.b)$
  * $\frac{ğœ•loss}{ğœ•ğœ”} = 2x(ğœ”x + b - y)$
  * $\frac{ğœ•loss}{ğœ•b} = 2(ğœ”x + b - y)$
  * æ¢¯åº¦ä¸‹é™è§£æ³•ï¼šliuer/lesson4_2.py
  * éšæœºæ¢¯åº¦ä¸‹é™ï¼šliuer/lesson4_3.py
* å‡è®¾æ¨¡å‹æ˜¯$y = ğœ” * x + b$ï¼Œè®¡ç®—æŸå¤±å‡½æ•°ç›¸å¯¹äºå„ä¸ªå‚æ•°çš„åå¯¼æ•°æ¥æ±‚è§£æ¢¯åº¦ã€‚
  * $loss = (\hat{y} - y)^2 \quad \hat{y} = ğœ” * x + b$
  * $\frac{ğœ•loss}{ğœ•ğœ”} = \frac{ğœ•loss}{ğœ•\hat{y}}.\frac{ğœ•\hat{y}}{ğœ•ğœ”} = 2(\hat{y} - y).x$
  * $\frac{ğœ•loss}{ğœ•b} = \frac{ğœ•loss}{ğœ•\hat{y}}.\frac{ğœ•\hat{y}}{ğœ•b} = 2(\hat{y} - y).1$
* å‡è®¾æ¨¡å‹æ˜¯$y = ğœ”_1.x^2 + ğœ”_2.x + b$
  * $loss = (\hat{y} - y)^2 \quad \hat{y} = ğœ”_1.x^2 + ğœ”_2.x + b$
  * $\frac{ğœ•loss}{ğœ•ğœ”_1} = \frac{ğœ•loss}{ğœ•\hat{y}}.\frac{ğœ•\hat{y}}{ğœ•ğœ”_1} = 2(\hat{y} - y).x^2$
  * $\frac{ğœ•loss}{ğœ•ğœ”_2} = \frac{ğœ•loss}{ğœ•\hat{y}}.\frac{ğœ•\hat{y}}{ğœ•ğœ”_2} = 2(\hat{y} - y).x$
  * $\frac{ğœ•loss}{ğœ•b} = \frac{ğœ•loss}{ğœ•\hat{y}}.\frac{ğœ•\hat{y}}{ğœ•b} = 2(\hat{y} - y).1$

#### ç¬¬äº”è®²-PyTorchçº¿æ€§å›å½’
* PyTorchçš„å››ä¸ªæ­¥éª¤ï¼šå‡†å¤‡æ•°æ®ã€å®šä¹‰æ¨¡å‹ã€å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ã€è®­ç»ƒå‘¨æœŸ
* è®­ç»ƒå‘¨æœŸçš„ä¸‰ä¸ªæ­¥éª¤ï¼š
  * å‰é¦ˆforwardï¼šè®¡ç®—$\hat{y} \quad loss$
  * åé¦ˆbackwardï¼šåå‘ä¼ æ’­ã€è®¡ç®—æ¢¯åº¦
  * æ›´æ–°updateï¼šæ›´æ–°å‚æ•°

#### ç¬¬å…­è®²-é€»è¾‘æ–¯è°›å›å½’
* [ä¸€ç¯‡æ–‡ç« ææ‡‚logit, logisticå’Œsigmoidçš„åŒºåˆ«](https://zhuanlan.zhihu.com/p/358223959)
* é€»è¾‘æ–¯è°›å›å½’(Logistic Regression)ï¼Œç®€ç§°LR
* sigmoidå‡½æ•°æ˜¯æŒ‡æŸä¸€ç±»å½¢å¦‚"S"çš„å‡½æ•°ï¼Œä¾‹å¦‚[è¿™äº›å‡½æ•°](../images/sigmoid-function.jpg)
* logisticå‡½æ•°ä¹Ÿæ˜¯sigmoidå‡½æ•°ï¼Œåœ¨PyTorchä¸­sigmoidå‡½æ•°å³æ˜¯logisticå‡½æ•°
* logisticå›å½’è™½ç„¶åä¸ºå›å½’ï¼Œä½†å®é™…ç”¨äºåˆ†ç±»é—®é¢˜ã€‚
* torch.nn.BCELossæ˜¯CrossEntropyLossçš„ä¸€ä¸ªç‰¹ä¾‹ï¼Œåªç”¨äºäºŒåˆ†ç±»é—®é¢˜ï¼Œè€ŒCrossEntropyLosså¯ä»¥ç”¨äºäºŒåˆ†ç±»ï¼Œä¹Ÿå¯ä»¥ç”¨äºå¤šåˆ†ç±»ã€‚
* sigmoidå‡½æ•°çš„è¾“å…¥è®°ä¸ºzï¼Œ$z = ğœ”_0.x_0 + ğœ”_1.x_1 + ... + ğœ”_n.x_n$ï¼Œz=0ä¸ºå†³ç­–è¾¹ç•Œï¼Œz>0ä¸ºçœŸï¼Œz<0ä¸ºå‡
  * ä¸Šè¿°å…¬å¼çš„å‘é‡å†™æ³•æ˜¯$z = ğœ”^T.x$ï¼Œæ¢¯åº¦ä¸‹é™å…¬å¼æ¨å¯¼è§[é€»è¾‘å›å½’(LR)ç®—æ³•è¯¦è§£å’Œå®æˆ˜](https://blog.csdn.net/Mr_Robert/article/details/88888973)
  * $loss = -y\log(\hat{y}) - (1 - y)\log(1 - \hat{y})$
  * $cost = -\frac{1}{N}\sum\limits_{n=1}^N y\log(\hat{y}) + (1 - y)\log(1 - \hat{y})$ï¼Œä»è¿™é‡Œå¼€å§‹çœç•¥ä¸‹æ ‡n
  * $\frac{ğœ•cost}{ğœ•ğœ”} = \frac{ğœ•cost}{ğœ•\hat{y}}.\frac{ğœ•\hat{y}}{ğœ•ğœ”}$ï¼Œå…¶ä¸­$\hat{y} = \frac{1}{1 + e^{-z}}$
  * $\frac{ğœ•cost}{ğœ•ğœ”} = -\frac{1}{N}\sum\limits_{n=1}^N (\frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}}) . (\frac{ğœ•\hat{y}}{ğœ•z}.\frac{ğœ•z}{ğœ•ğœ”})$ï¼Œå…¶ä¸­$\frac{ğœ•\hat{y}}{ğœ•z} = \hat{y} . (1 - \hat{y})$
  * $\frac{ğœ•cost}{ğœ•ğœ”} = -\frac{1}{N}\sum\limits_{n=1}^N (\frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}}) . \hat{y} . (1 - \hat{y}) . x$
  * $\frac{ğœ•cost}{ğœ•ğœ”} = -\frac{1}{N}\sum\limits_{n=1}^N (y - \hat{y}).x$
  * $\frac{ğœ•cost}{ğœ•ğœ”} = \frac{1}{N}\sum\limits_{n=1}^N (\hat{y} - y).x$
* $z = ğœ”_0.x_0 + ğœ”_1.x_1 + ğœ”_2.x_2$ï¼Œå…¶ä¸­$x_0$æ’ä¸º1
  * ä»£ç liuer/lesson6.pyï¼š[æœºå™¨å­¦ä¹ ä¹‹é€»è¾‘å›å½’Logistic Regression](https://blog.csdn.net/qq_41750911/article/details/124889545)
  * ä»£ç liuer/lesson6_1.pyï¼š[é€»è¾‘å›å½’æ‰‹åŠ¨å®ç°ï¼ˆlogistic regressionï¼‰](https://blog.csdn.net/qq_37055672/article/details/124779634)

#### ç¬¬ä¸ƒè®²-å¤„ç†å¤šç»´è¾“å…¥
* çº¿æ€§æ¨¡å‹ï¼šy = Axã€‚çº¿æ€§ä¹Ÿå°±æ˜¯ç›´çº¿ï¼Œæ˜¯ä¸€æ¬¡æ–¹ç¨‹ã€‚
* torch.nn.Linear(8, 1)è¡¨ç¤ºè¾“å…¥æ˜¯8ç»´ï¼Œè¾“å‡ºæ˜¯1ç»´ï¼Œå³Aæ˜¯1x8ï¼Œxæ˜¯8x1ï¼Œyæ˜¯1x1
* torch.nn.Linear(8, 6)è¡¨ç¤ºè¾“å…¥æ˜¯8ç»´ï¼Œè¾“å‡ºæ˜¯6ç»´ï¼Œå³Aæ˜¯6x8ï¼Œxæ˜¯8x1ï¼Œyæ˜¯6x1
* éçº¿æ€§æ¿€æ´»å‡½æ•°ä½¿å¾—ç¥ç»ç½‘ç»œå¯ä»¥é€¼è¿‘ä»»ä½•éçº¿æ€§å‡½æ•°
* éçº¿æ€§æ¿€æ´»å‡½æ•°[è§](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity)ï¼Œå…¶ä¸­æœ‰torch.nn.Sigmoid

#### ç¬¬å…«è®²-Datasetå’ŒDataLoader
* Datasetæ˜¯æŠ½è±¡ç±»ï¼Œéœ€è¦ç”¨æˆ·ç¼–å†™å…·ä½“ç±»
* DataLoaderéœ€è¦ä¸€ä¸ªDatasetå…·ä½“ç±»ï¼Œç”Ÿæˆä¸€ä¸ªè¿­ä»£å¯¹è±¡

#### ç¬¬ä¹è®²-å¤šåˆ†ç±»é—®é¢˜
* å…³äºæŠŠå›¾ç‰‡è½¬æˆtensoræ ¼å¼ï¼Œå‚è€ƒliuer/image2tensor.py
* ä¸ºä»€ä¹ˆè¦æ‰§è¡Œtransforms.Normalize((0.1307,), (0.3081,))ï¼Ÿ
  * å› ä¸ºToTensoræ˜¯æŠŠæ•°æ®å½’ä¸€åŒ–åˆ°0,1åŒºé—´ï¼Œè€ŒNormalizeæ˜¯è®©æ•°æ®æˆæ­£æ€åˆ†å¸ƒï¼Œ[åŠ å¿«æ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦](https://zhuanlan.zhihu.com/p/476297637)
  * transforms.Normalize(mean, std)å¯ä»¥é€šè¿‡å¯¹è¾“å…¥è¿›è¡Œtorch.mean(x)å’Œtorch.std(x)å¾—åˆ°
* æ¨¡å‹ç²¾ç¡®åº¦97%ï¼Œè®­ç»ƒè¿‡ç¨‹ï¼š
  * xï¼šæ ·æœ¬æ˜¯(0,28,28)
  * x = x.view(-1, 784)ï¼šè¾“å‡ºå˜æˆ784
  * x = F.relu(self.l1(x))ï¼šè¾“å‡ºå˜æˆ512
  * x = F.relu(self.l2(x))ï¼šè¾“å‡ºå˜æˆ256
  * x = F.relu(self.l3(x))ï¼šè¾“å‡ºå˜æˆ128
  * x = F.relu(self.l4(x))ï¼šè¾“å‡ºå˜æˆ64
  * x = self.l5(x)ï¼šè¾“å‡ºå˜æˆ10

#### ç¬¬åè®²-å·ç§¯ç¥ç»ç½‘ç»œ-åŸºç¡€ç¯‡
* CNN(Convolution Neural Network)ï¼šå·ç§¯ç¥ç»ç½‘ç»œ
* [å·ç§¯ç¥ç»ç½‘ç»œä¸­çš„æ¿€æ´»å‡½æ•°sigmoidã€tanhã€relu](https://blog.csdn.net/qq_39751352/article/details/124649762)
  * æ¿€æ´»å‡½æ•°çš„ç›®çš„ï¼šå°†ç¥ç»ç½‘ç»œéçº¿æ€§åŒ–ï¼Œå³æå‡ç¥ç»ç½‘ç»œçš„æ‹Ÿåˆèƒ½åŠ›ï¼Œèƒ½æ‹Ÿåˆæ›´å¤æ‚çš„å‡½æ•°ã€‚
  * å¦‚æœæ¨¡å‹åªæœ‰çº¿æ€§æ“ä½œï¼Œåˆ™æ°¸è¿œåªèƒ½è¡¨ç¤ºè¶…å¹³é¢ï¼Œæ— æ³•è¡¨ç¤ºæ›²é¢ç­‰
* [ç½‘ç»œå±‚ï¼šæ± åŒ–å±‚ã€å…¨è¿æ¥å±‚å’Œæ¿€æ´»å‡½æ•°å±‚](https://yey.world/2020/12/16/Pytorch-13/)  
* å·ç§¯ç¥ç»ç½‘ç»œé™¤äº†è¾“å…¥å’Œè¾“å‡ºå±‚ä¹‹å¤–è¿˜æœ‰å››ä¸ªåŸºæœ¬çš„ç¥ç»å…ƒå±‚ï¼š
  * å·ç§¯å±‚ï¼ˆConvolutionï¼‰ï¼š[torch.nn.Conv2d](https://pytorch.apachecn.org/1.0/nn/#conv2d)
  * æ± åŒ–å±‚ï¼ˆPoolingï¼‰ï¼š[torch.nn.MaxPool2d](https://pytorch.apachecn.org/1.0/nn/#maxpool2d)
  * æ¿€æ´»å±‚ï¼ˆActivationï¼‰
  * å®Œå…¨è¿æ¥å±‚ï¼ˆFully connectedï¼‰ï¼šæ¯ä¸ªç¥ç»å…ƒä¸ä¸Šä¸€å±‚æ‰€æœ‰ç¥ç»å…ƒç›¸è¿ï¼Œå¦‚æœä¸è€ƒè™‘æ¿€æ´»å‡½æ•°çš„éçº¿æ€§æ€§è´¨ï¼Œé‚£ä¹ˆå…¨è¿æ¥å±‚å°±æ˜¯å¯¹è¾“å…¥æ•°æ®è¿›è¡Œä¸€ä¸ªçº¿æ€§ç»„åˆ
* æ¨¡å‹ç²¾ç¡®åº¦98%ï¼Œè®­ç»ƒè¿‡ç¨‹ï¼š
  * xï¼šæ ·æœ¬æ˜¯(0,28,28)
  * x = F.relu(self.pooling(self.conv1(x)))ï¼šå·ç§¯åæ˜¯(10,24,24)ï¼Œæ± åŒ–åæ˜¯(10,12,12)
  * x = F.relu(self.pooling(self.conv2(x)))ï¼šå·ç§¯åæ˜¯(20,8,8)ï¼Œæ± åŒ–åæ˜¯(20,4,4)
  * x = x.view(x.size(0), -1)ï¼šè¾“å‡ºå˜æˆ320
  * x = self.fc(x)ï¼šè¾“å‡ºå˜æˆ10

#### ç¬¬åä¸€è®²-å·ç§¯ç¥ç»ç½‘ç»œ-é«˜çº§ç¯‡
* nn.Conv2d(1, 16, kernel_size=1)ï¼Œ1x1å·ç§¯æ ¸çš„ä½œç”¨ï¼šèåˆäº†æ¯ä¸ªé€šé“çš„ä¿¡æ¯
* ResidualBlockå±‚æ˜¯æŠŠè¾“å…¥å’Œè¾“å‡ºç›¸åŠ ï¼Œå³z(x) = f(x) + x
  * å¥½å¤„æ˜¯ä¸ä¼šå­˜åœ¨æ¢¯åº¦æ¶ˆå¤±çš„é—®é¢˜ï¼Œå› ä¸ºå³ä½¿f'(x)æ˜¯0ï¼Œz'(x)æ˜¯1
* æ¨¡å‹ç²¾ç¡®åº¦98%ï¼Œè®­ç»ƒè¿‡ç¨‹ï¼š
  * xï¼šæ ·æœ¬æ˜¯(0,28,28)
  * x = F.relu(self.mp(self.conv1(x)))ï¼šå·ç§¯åæ˜¯(10,24,24)ï¼Œæ± åŒ–åæ˜¯(10,12,12)
  * x = self.incep1(x)ï¼š(88,12,12)
    * åˆ†æ”¯1ï¼Œ(16,12,12)
    * åˆ†æ”¯2ï¼Œ(24,12,12)
    * åˆ†æ”¯3ï¼Œ(24,12,12)
    * åˆ†æ”¯4ï¼Œ(24,12,12)
  * x = F.relu(self.mp(self.conv2(x)))ï¼šå·ç§¯åæ˜¯(20,8,8)ï¼Œæ± åŒ–åæ˜¯(20,4,4)
  * x = self.incep2(x)ï¼š(88,4,4)
    * åˆ†æ”¯1ï¼Œ(16,4,4)
    * åˆ†æ”¯2ï¼Œ(24,4,4)
    * åˆ†æ”¯3ï¼Œ(24,4,4)
    * åˆ†æ”¯4ï¼Œ(24,4,4)
  * x = x.view(x.size(0), -1)ï¼šè¾“å‡ºå˜æˆ1408
  * x = self.fc(x)ï¼šè¾“å‡ºå˜æˆ10
* æ¨¡å‹ç²¾ç¡®åº¦99%ï¼Œè®­ç»ƒè¿‡ç¨‹ï¼š
  * xï¼šæ ·æœ¬æ˜¯(0,28,28)
  * x = F.relu(self.mp(self.conv1(x)))ï¼šå·ç§¯åæ˜¯(16,24,24)ï¼Œæ± åŒ–åæ˜¯(16,12,12)
  * x = self.rblock1(x)ï¼šResidualBlockçš„è¾“å…¥å’Œè¾“å‡ºçš„å¼ é‡ç›¸åŒ
  * x = self.mp(F.relu(self.conv2(x)))ï¼šå·ç§¯åæ˜¯(32,8,8)ï¼Œæ± åŒ–åæ˜¯(32,4,4)
  * x = self.rblock2(x)ï¼šResidualBlockçš„è¾“å…¥å’Œè¾“å‡ºçš„å¼ é‡ç›¸åŒ
  * x = x.view(in_size, -1)ï¼šè¾“å‡ºå˜æˆ512
  * x = self.fc(x)ï¼šè¾“å‡ºå˜æˆ10

#### ç¬¬åäºŒè®²-å¾ªç¯ç¥ç»ç½‘ç»œ-åŸºç¡€ç¯‡
* RNN(Recurrent Neural Network)ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ
* [æ·±åº¦å­¦ä¹ å®æˆ˜æ•™ç¨‹(äº”)ï¼šå¾ªç¯ç¥ç»ç½‘ç»œ](https://cuijiahua.com/blog/2018/12/dl-11.html)
* åŸºæœ¬å¾ªç¯ç¥ç»ç½‘ç»œï¼šè§£å†³â€œæˆ‘æ˜¨å¤©ä¸Šå­¦è¿Ÿåˆ°äº†ï¼Œè€å¸ˆæ‰¹è¯„äº†____â€ï¼Œè§[ç»“æ„å›¾](../images/simple-rnn.jpg)
  * $o_t = g(V.s_t)$ï¼Œgæ˜¯æ¿€æ´»å‡½æ•°ã€‚
  * $s\_t = f(U.x\_t + W.s\_{t-1})$ï¼ŒUæ˜¯x<sub>t</sub>çš„æƒé‡çŸ©é˜µï¼ŒWæ˜¯s<sub>t-1</sub>çš„æƒé‡çŸ©é˜µã€‚
* åŒå‘å¾ªç¯ç¥ç»ç½‘ç»œï¼šè§£å†³â€œæˆ‘çš„æ‰‹æœºåäº†ï¼Œæˆ‘æ‰“ç®—____ä¸€éƒ¨æ–°æ‰‹æœºâ€ï¼Œè§[ç»“æ„å›¾](../images/two-way-rnn.png)
  * $o_t = g(V.s_t + V'.s_t')$
  * $s\_t = f(U.x\_t + W.s\_{t-1})$
  * $s\_t' = f(U'.x\_t + W'.s\_{t+1}')$
  * æ­£å‘è®¡ç®—å’Œåå‘è®¡ç®—ä¸å…±äº«æƒé‡ï¼ŒåƒUå’ŒU'ã€Wå’ŒW'ã€Vå’ŒV'
* æ·±åº¦å¾ªç¯ç¥ç»ç½‘ç»œï¼šæ›´å¼ºå¤§çš„è¡¨è¾¾ä¸å­¦ä¹ èƒ½åŠ›ï¼Œä½†å¤æ‚æ€§æé«˜ï¼Œéœ€æ›´å¤šè®­ç»ƒæ•°æ®ã€‚è§[ç»“æ„å›¾](../images/deep-rnn.png)
  * å‡è®¾ç¬¬iä¸ªéšè—å±‚çš„å€¼åˆ†åˆ«æ˜¯$s_t^{(i)} \quad s_t^{'(i)}$
  * $o_t = g(V^{(i)}.s_t^{(i)} + V^{'(i)}.s_t^{'(i)})$
  * $s\_t^{(i)} = f(U^{(i)}.x\_t^{(i-1)} + W^{(i)}.s\_{t-1}^{(i)})$
  * $s\_t^{'(i)} = f(U^{'(i)}.x\_t^{'(i-1)} + W^{'(i)}.s\_{t+1}^{'(i)})$
* RNNçš„æ¢¯åº¦çˆ†ç‚¸å’Œæ¶ˆå¤±é—®é¢˜
  * æ¢¯åº¦çˆ†ç‚¸ï¼šç¨‹åºä¼šæŠ¥NaNé”™è¯¯ï¼Œè§£å†³åŠæ³•æ˜¯è®¾ç½®ä¸€ä¸ªæ¢¯åº¦é˜ˆå€¼ï¼Œæ¢¯åº¦ä¸èƒ½é«˜äºå®ƒ
  * æ¢¯åº¦æ¶ˆå¤±ï¼šéœ€è¦ä½¿ç”¨é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œï¼ˆLTSMï¼‰å’ŒGated Recurrent Unitï¼ˆGRUï¼‰
* å¾ªç¯ç¥ç»ç½‘ç»œæ¿€æ´»å‡½æ•°ç”¨tanhç”¨çš„å¤š
* torch.nn.Embeddingçš„å¥½å¤„ï¼š
  * å¯¹äºæ ·æœ¬ï¼ˆ0, 1, 88ï¼‰ï¼Œè‹¥ä½¿ç”¨one-hotç¼–ç ï¼Œåˆ™éœ€è¦3 * 89
  * è€Œä½¿ç”¨torch.nn.Embedding(89, 5)æ¥ç¼–ç ï¼Œåˆ™éœ€è¦3 * 5

#### ç¬¬åä¸‰è®²-å¾ªç¯ç¥ç»ç½‘ç»œ-é«˜çº§ç¯‡
* [å¾ªç¯ç¥ç»ç½‘ç»œ RNNã€é•¿çŸ­æ—¶è®°å¿†ç½‘ç»œLSTMã€é—¨æ§å¾ªç¯å•å…ƒGRUåŸç†å’Œåº”ç”¨è¯¦è§£](https://www.heywhale.com/mw/project/646d7cb1946100f2ccb8cee9)
* RNNçš„å‡ ç§å¸¸è§æ¨¡å¼
  * åºåˆ—åˆ°ç±»åˆ«æ¨¡å¼ï¼šliuer/lesson13.py
  * åŒæ­¥çš„åºåˆ—åˆ°åºåˆ—æ¨¡å¼ï¼šliuer/lesson13_2.pyã€liuer/lesson13_3.py
  * å¼‚æ­¥çš„åºåˆ—åˆ°åºåˆ—æ¨¡å¼ï¼š
    * [å¾·è¯­åˆ°è‹±è¯­](https://lifanchen-simm.github.io/2019/03/10/seq2seq/)
    * [è‹±è¯­åˆ°æ³•è¯­](https://blog.csdn.net/qq_43941037/article/details/133958279)
    * [è‹±è¯­åˆ°æ³•è¯­](https://zhuanlan.zhihu.com/p/476849075)
* [torch.nn.GRUçš„è¾“å…¥åŠè¾“å‡ºç¤ºä¾‹](https://blog.csdn.net/jiuweideqixu/article/details/109492863)
  * batch_first=Falseæ—¶ï¼š
    * `input:  (seq_len, batch, embedding_dim)`
    * `h_0:    (num_layers * num_directions, batch, hidden_size)`
    * `output: (seq_len, batch, num_directions * hidden_size)`
    * `h_n:    (num_layers * num_directions, batch, hidden_size)`
  * batch_first=Trueæ—¶ï¼š
    * `input:  (batch, seq_len, embedding_dim)`
    * `h_0:    (batch, num_layers * num_directions, hidden_size)`
    * `output: (batch, seq_len, num_directions * hidden_size)`
    * `h_n:    (batch, num_layers * num_directions, hidden_size)`





