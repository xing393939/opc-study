### TiDB系统管理基础

#### 基础
1. [TiDB 系统管理基础 - 视频](https://learn.pingcap.com/learner/course/30002)
1. [18年的压测](https://www.quora.com/How-does-TiDB-compare-with-MySQL)和[19年的压测](https://www.percona.com/blog/2019/01/24/a-quick-look-into-tidb-performance-on-a-single-server/)表明：TiDB的性能只有MySQL的一半
1. [新一代数据库TiDB在美团的实践](https://tech.meituan.com/2018/11/22/mysql-pingcap-practice.html)
  * 美团对TiDB的定位：支持二级索引；跨region failover；跨region双写
  * TiDB对比ClickHouse：ClickHouse跑低频SQL可以，跑高频SQL不行，且跑全量低频SQL会发生overkill；TiDB则可以胜任。
  * 传统分库分表方案的弊端：业务无法友好的执行分布式事务；跨库的查询需要在中间层上组合(不支持跨库join)；再次拆分的成本高
1. [CatKang - NewSQL数据库概述](http://catkang.github.io/2020/12/01/newsql.html)
  * 分库分表：part1是中间件，part2是单机。代表有阿里云DRDS。
  * Spanner：part1是server层，part2是engine层。代表有TiDB。分布式事务的四个特性：
    * Atomicity：单机靠redo+undo；分布式靠redo+undo+2PC
    * Consistency
    * Isolation：单机靠2PL+MVCC(本地时钟)；分布式靠2PL+MVCC(Lamport or TrueTime时钟)
    * Durability：单机靠redo；分布式靠redo+Multi-Paxos
  * Partition Storage：part1是server、engine层，part2是存储。代表有Aurora、PolarDB。

#### redo和undo
* [CatKang - 数据库故障恢复机制的前世今生](http://catkang.github.io/2019/01/16/crash-recovery.html)
* 数据库的四种故障类型：
  * Transaction Failure可能是主动回滚或者冲突后强制Abort；
  * Process Failure指的是由于各种原因导致的进程退出，进程内存内容会丢失；
  * System Failure来源于操作系统或硬件故障；
  * Media Failure则是存储介质的不可恢复损坏。
* WAL和机械硬盘：按Block寻址，os层面则是读一页就算一次IO；随机IO很差
* WBL和固态硬盘：按字节寻址而不是Block；随机IO和顺序IO差不多
* 什么是事务的持久化：事务一旦提交，并对客户端返回success，则数据永久保存。
* [理解数据库中的undo日志、redo日志、检查点](https://blog.csdn.net/Maxiao1204/article/details/107505537)，文章的5、6、7介绍了undo和redo
* [为什么只用 redo-log 或者只用 undo-log 不可以](https://www.jianshu.com/p/57c510f4ec28)
  * 假设只有undo-log：事务提交前数据必须落盘（随机IO），性能差
  * 假设只用redo-log：事务提交前只需要redo落盘（顺序IO）。但是数据落盘的逻辑会很复杂，如果大量数据未落盘，则需要内存；如果要保证实时落盘，则需要保证要落盘的数据页都是commit状态
  * 使用undo+redo：主体流程还是undo-log，但是数据落盘改成redo-log的形式，这样只需要undo、redo落盘即可（顺序IO）。唯一的缺点是写放大，一次事务三次IO。

```
// undo 的流程
日志1记录t=0，数据t=1，标记*
日志2记录t=1，数据t=2
日志3记录t=2，数据t=3，标记*
日志4记录t=3，数据t=4
标记为*后表示事务已提交，此时日志1和日志3可以删除
数据恢复时，只需要恢复日志4和日志2即可

// redo的流程
日志1记录t=1，标记为*，数据t=1
日志2记录t=2
日志3记录t=3，标记为*
日志4记录t=4
标记为*后表示事务已提交，此时需要等数据落盘后才能删除，日志1可以删除，日志3不能
数据恢复时，只需要恢复标记为*日志即可
```

### 三篇文章了解 TiDB 技术内幕
1. [TiDB 高并发写入场景最佳实践](https://docs.pingcap.com/zh/tidb/stable/high-concurrency-best-practices)
1. [TiDB Best Practice](https://pingcap.com/blog-cn/tidb-best-practice/)
  * TiDB 最底层用 Raft 来同步数据。每次写入都要写入多数副本，才能对外返回成功。
  * 比如最大 3 副本的话，每次写入 2 副本才算成功。写入的延迟取决于最快的两个副本，而不是最慢的那个副本。
  * 分布式事务采用的乐观锁。缺点只有在真正提交的时候，才会做冲突检测，所以在冲突严重的场景下性能低下。
  * 数据表的数据或者索引具有相同的前缀，这些 Key-Value 会在相邻的位置。批量写入会在很少的几个 Region 上形成写入热点，成为整个系统的瓶颈。
  * 二级索引的特点：尽量用区分度比较大的列；最左原则；数据分散在很多Region上，并发查询的Region数可配
  * 建议每个事务的行数不超过 200 行，且单行数据小于 100k，否则可能性能不佳。
1. [TiDB 最佳实践系列（一）高并发写入常见热点问题及规避方法](https://pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/)
  * 高并发批量插入会有region热点问题，可以通过预先split region解决

```
主键索引：key：tableID、rowID；value：\[col1, col2, col3, col4...]
唯一索引：key：tableID、indexID、indexedColumnsValue；value：rowID
非唯一索引：key：tableID、indexID、indexedColumnsValue、rowID；value：null

// 举例有张Age，tableID=10，它的非唯一索引indexID=1，它的唯一索引indexID=2，有三条数据如下
ID Name    Role         Age
1, "TiDB", "SQL Layer", 10
2, "TiKV", "KV Engine", 20
3, "PD",   "Manager",   30

// 主键索引
t10_r1 --> ["TiDB", "SQL Layer", 10]
t10_r2 --> ["TiKV", "KV Engine", 20]
t10_r3 --> ["PD", "Manager", 30]

// 唯一索引[Name]
t10_i2_TiDB --> 1
t10_i2_TiKV --> 2
t10_i2_PB --> 3

// 非唯一索引[Age]
t10_i1_10_1 --> null
t10_i1_20_2 --> null
t10_i1_30_3 --> null
```

#### 热点问题处理思路
1. [7.2 热点问题处理思路 · TiDB in Action](https://book.tidb.io/session4/chapter7/hotspot-resolved.html)
1. 确认热点问题：Grafana 的 TiKV-Trouble-Shooting 的 Dashboard 的 Hot Read 和 Hot Write 面板
1. 确认热点表或索引：pd-ctl region topwrite|topread 3；TiDB Dashboard的流量可视化。
1. 写入热点的业务场景通常有：
  * 有自增主键：去掉自增主键并设置 SHARD_ROW_ID_BITS（可动态设置，SHARD_ROW_ID_BITS=4表示16个分片）。
  * 存在递增索引，比如时间索引等：手工切分热点 Region。
  * 高并发更新小表：改造小表为 hash 分区表。
  * 秒杀场景下的单行热点问题：业务层面用内存缓存解决。

#### TiKV 架构
1. [TiKV 简介 | PingCAP Docs](https://docs.pingcap.com/zh/tidb/stable/tikv-overview)
1. [RocksDB 简介 | PingCAP Docs](https://docs.pingcap.com/zh/tidb/stable/rocksdb-overview)
1. Region 副本(Peer)的三个角色：Leader负责读写可投票；Follower可随时替换Leader可投票；Learner是不完整的副本，不可投票。
1. 每个 TiKV 实例中有两个 RocksDB 实例
  * 一个用于存储 Raft 日志（通常被称为 raftdb）
  * 一个用于存储用户数据以及 MVCC 信息（通常被称为 kvdb）

#### PD 调度策略
1. [三篇文章了解 TiDB 技术内幕 - 谈调度](https://pingcap.com/blog-cn/tidb-internal-3/)
1. [TiDB 最佳实践系列（二）PD 调度策略最佳实践](https://pingcap.com/blog-cn/best-practice-pd)
1. 相关概念
  * Store：即TiKV实例
  * Region：若Region有3个副本，也即3个Peer。每个Region有1个raft实例，也称Raft Group。
  * Pending / Down：是Peer可能出现的两种特殊状态
    * Pending 表示 Follower 或 Learner 的 raft log 与 Leader 有较大差距，Pending 状态的 Follower 无法被选举成 Leader。
    * Down 是指 Leader 长时间没有收到对应 Peer 的消息，可能是宕机或者网络隔离。
  * Scheduler：是PD的调度器，常用的调度器有：
    * balance-leader-scheduler：保持不同节点的 Leader 均衡。
    * balance-region-scheduler：保持不同节点的 Peer 均衡。
    * hot-region-scheduler：保持不同节点的读写热点 Region 均衡。
    * evict-leader-{store-id}：驱逐某个节点的所有 Leader。（常用于滚动升级）
1. TiKV 节点周期性地向 PD 上报 StoreHeartbeat 和 RegionHeartbeat 两种心跳消息。
1. StoreHeartbeat 包含了 Store 的基本信息，由 Store 定期向 PD 汇报。
  * 总磁盘容量
  * 可用磁盘容量
  * 承载的 Region 数量
  * 数据读写速度
  * 发送/接受的 Snapshot 数量（副本之间可能会通过 Snapshot 同步数据）
  * 是否过载
  * 标签信息
1. RegionHeartbeat 包含了 Region 的相关信息，由 Raft Group 的 Leader 定期向 PD 汇报。
  * Leader 的位置
  * Followers 的位置
  * 掉线副本的个数
  * 数据读写速度

#### DDL 变更原理
1. [DDL 变更原理](https://book.tidb.io/session1/chapter7/tidb-ddl-status.html)
1. Add column operation：只更新schema，新的row是新结构，查询老的row就依据schema的默认值返回
1. Modify column operation：转换column的类型只支持整型(lengthened)；auto_increment只能在新建表的时候设置；如果索引有用到此column，索引的schema也需改变(但原始数据不变)
1. Add index operation：先生成好index再把index设置为可用，耗时较长

#### TiDB 集群管理
* 安装：pd是大脑（3台）、tidb是无状态的server（2台）、tikv（3台，默认3个副本）
* 安装：需先安装numactl。tiup cluster template > topology.yaml，去掉TiFlash配置
* 配置分为系统配置（存在tikv中，有作用域，session只对当前会话生效，global对新启的会话生效）、集群配置（tidb、tikv、pd，需改配置文件并重启）
* mysql分用户和角色，attach角色后，用户登录需要执行set role all




