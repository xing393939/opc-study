
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>刘二大人 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="fft.html" />
    
    
    <link rel="prev" href="highlights-of-calculus.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">目录</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    1.数据结构和算法
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="common-algorithms.html">
            
                <a href="common-algorithms.html">
            
                    
                    数据结构、数组排序、堆操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="data-structure-and-algorithm.html">
            
                <a href="data-structure-and-algorithm.html">
            
                    
                    数据结构和算法之美
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="sword-finger-offer.html">
            
                <a href="sword-finger-offer.html">
            
                    
                    剑指Offer
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    2.数据库和缓存
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="redis5-source.html">
            
                <a href="redis5-source.html">
            
                    
                    Redis 5设计与源码分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="redis-in-depth.html">
            
                <a href="redis-in-depth.html">
            
                    
                    Redis 深度历险
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="mysql-how-it-works.html">
            
                <a href="mysql-how-it-works.html">
            
                    
                    MySQL 是怎样运行的
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="ddia.html">
            
                <a href="ddia.html">
            
                    
                    DDIA
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="cache-policies.html">
            
                <a href="cache-policies.html">
            
                    
                    缓存模式
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    3.机器学习
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="linear-algebra.html">
            
                <a href="linear-algebra.html">
            
                    
                    线性代数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="highlights-of-calculus.html">
            
                <a href="highlights-of-calculus.html">
            
                    
                    微积分重点
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.3" data-path="liu-er.html">
            
                <a href="liu-er.html">
            
                    
                    刘二大人
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="fft.html">
            
                <a href="fft.html">
            
                    
                    傅里叶变换
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    4.其他
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="systems-performance.html">
            
                <a href="systems-performance.html">
            
                    
                    性能之颠
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="head-first-design-patterns.html">
            
                <a href="head-first-design-patterns.html">
            
                    
                    Head First设计模式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="talk-about-network-protocol.html">
            
                <a href="talk-about-network-protocol.html">
            
                    
                    趣谈网络协议
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="advanced-java.html">
            
                <a href="advanced-java.html">
            
                    
                    Java工程师进阶知识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="clean-code.html">
            
                <a href="clean-code.html">
            
                    
                    整洁代码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.6" data-path="clean-architecture.html">
            
                <a href="clean-architecture.html">
            
                    
                    整洁架构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.7" data-path="fenix-architecture.html">
            
                <a href="fenix-architecture.html">
            
                    
                    凤凰架构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.8" data-path="bpf-performance-tools.html">
            
                <a href="bpf-performance-tools.html">
            
                    
                    BPF之巅
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    5.AWS SAA认证
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="saa-1.html">
            
                <a href="saa-1.html">
            
                    
                    1.AWS知识点
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="saa-2.html">
            
                <a href="saa-2.html">
            
                    
                    2.AWS认证英语学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="saa-3.html">
            
                <a href="saa-3.html">
            
                    
                    3.AWS的其他服务
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="saa-4.html">
            
                <a href="saa-4.html">
            
                    
                    4.AWS Github Study Guide
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    6.TiDB PCTA认证
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="tidb-1.html">
            
                <a href="tidb-1.html">
            
                    
                    1.TiDB 基础知识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="tidb-2.html">
            
                <a href="tidb-2.html">
            
                    
                    2.TiDB in Action: 原理和特性
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="tidb-3.html">
            
                <a href="tidb-3.html">
            
                    
                    3.TiDB in Action: 部署与管理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.4" data-path="tidb-4.html">
            
                <a href="tidb-4.html">
            
                    
                    4.TiDB in Action: 故障排查
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.5" data-path="tidb-5.html">
            
                <a href="tidb-5.html">
            
                    
                    5.TiDB in Action: 最佳实践
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >刘二大人</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h3 id="&#x5218;&#x4E8C;&#x5927;&#x4EBA;">&#x5218;&#x4E8C;&#x5927;&#x4EBA;</h3>
<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [["$$", "$$"], ["\\[", "\\]"]],
    },
    svg: {
      fontCache: 'global'
    }
  };
</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" <="" script="">

<h4>参考资料</h4>
<ul>
<li><a href="https://devdocs.io/pytorch">PyTorch-1.8.0文档</a></li>
<li><a href="https://www.cnblogs.com/zhouyeqin/category/2231506.html">刘二大人-cnblog</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/166104074">刘二大人-zhihu</a></li>
<li><a href="https://onecompiler.com/python/3zqwrqg2r">numpy在线运行</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/503336736">float的表示</a>：符号(1b)、阶码(8b)、尾数(23b)<ul>
<li>0.875：0.111，需要右移1位，阶码=127+(-1)，尾数=11</li>
<li>6.360：110.01011100，需要左移2位，阶码=127+2，尾数=10010111000010100011111</li>
<li>2^23 = 8388608。也就是说，有效数字在±8388608内的整数和小数，精度不会损失</li>
</ul>
</li>
<li>torch.optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=wd)  <ul>
<li>lr是学习率，momentum是冲量，weight_decay是防止过拟合</li>
</ul>
</li>
</ul>
<h4>第二讲-线性模型</h4>
<ul>
<li>MSE：均值平方误差(Mean Square Error)，$MSE=\frac{1}{N} \sum\limits_{n=1}^N (\hat{y}_n - y_n)^2$</li>
<li>训练集(1,2)、(2,4)、(3,6)，用穷举法预测x=4时，y的值：<ul>
<li>假设模型是y = 𝜔 * x，求𝜔的值</li>
<li>for (𝜔=0; 𝜔&lt;4.1; 𝜔+=0.1)，依次求出MSE，取MSE最低时𝜔的值</li>
</ul>
</li>
</ul>
<h4>第三讲-梯度下降法</h4>
<ul>
<li>训练集(1,2)、(2,4)、(3,6)，用梯度下降法预测x=4时，y的值：</li>
<li>梯度下降：<ul>
<li>假设模型是y = 𝜔 * x，求𝜔的值</li>
<li>先选定𝜔=1</li>
<li>下一个$𝜔=𝜔-α\frac{𝜕cost}{𝜕𝜔}$，其中α表示步长，cost即MSE</li>
<li>下一个$𝜔=𝜔-α\frac{1}{N}\sum\limits_{n=1}^N 2.x_n.(x_n.𝜔 - y_n)$</li>
<li>步长定为0.01，迭代100次，观察MSE值是否会收敛</li>
</ul>
</li>
<li>随机梯度下降：<ul>
<li>假设模型是y = 𝜔 * x，求𝜔的值</li>
<li>先选定𝜔=1</li>
<li>下一个$𝜔=𝜔-α\frac{𝜕loss}{𝜕𝜔}$，其中α表示步长，$loss = (\hat{y}_n - y_n)^2 \quad \frac{𝜕loss}{𝜕𝜔} = 2.x_n.(x_n.𝜔 - y_n)$</li>
<li>步长定为0.01，迭代100次，观察loss值是否会收敛</li>
</ul>
</li>
<li>梯度下降和随机梯度下降<ul>
<li>随机梯度下降需要等待上一个值运行完才能更新下一个值，无法并行计算</li>
<li>随机梯度下降可以有效解决鞍点问题</li>
<li>折中的办法是mini_batch</li>
</ul>
</li>
</ul>
<h4>第四讲-反向传播</h4>
<ul>
<li>假设模型是$y = 𝜔 * x$，求𝜔的值，<a href="../images/back-propagation.png">见图</a></li>
<li>假设模型是$y = 𝜔 * x + b$，<a href="https://blog.csdn.net/wanlin_yang/article/details/129263378">人工智能原理-曲面梯度下降和反向传播</a><ul>
<li>$loss = (𝜔x + b - y)^2 = x^2𝜔^2 + (2x.b - 2x.y)𝜔 + (y^2 + b^2 - 2y.b)$</li>
<li>$\frac{𝜕loss}{𝜕𝜔} = 2x(𝜔x + b - y)$</li>
<li>$\frac{𝜕loss}{𝜕b} = 2(𝜔x + b - y)$</li>
<li>梯度下降解法：liuer/lesson4_2.py</li>
<li>随机梯度下降：liuer/lesson4_3.py</li>
</ul>
</li>
<li>假设模型是$y = 𝜔 * x + b$，计算损失函数相对于各个参数的偏导数来求解梯度。<ul>
<li>$loss = (\hat{y} - y)^2 \quad \hat{y} = 𝜔 * x + b$</li>
<li>$\frac{𝜕loss}{𝜕𝜔} = \frac{𝜕loss}{𝜕\hat{y}}.\frac{𝜕\hat{y}}{𝜕𝜔} = 2(\hat{y} - y).x$</li>
<li>$\frac{𝜕loss}{𝜕b} = \frac{𝜕loss}{𝜕\hat{y}}.\frac{𝜕\hat{y}}{𝜕b} = 2(\hat{y} - y).1$</li>
</ul>
</li>
<li>假设模型是$y = 𝜔_1.x^2 + 𝜔_2.x + b$<ul>
<li>$loss = (\hat{y} - y)^2 \quad \hat{y} = 𝜔_1.x^2 + 𝜔_2.x + b$</li>
<li>$\frac{𝜕loss}{𝜕𝜔_1} = \frac{𝜕loss}{𝜕\hat{y}}.\frac{𝜕\hat{y}}{𝜕𝜔_1} = 2(\hat{y} - y).x^2$</li>
<li>$\frac{𝜕loss}{𝜕𝜔_2} = \frac{𝜕loss}{𝜕\hat{y}}.\frac{𝜕\hat{y}}{𝜕𝜔_2} = 2(\hat{y} - y).x$</li>
<li>$\frac{𝜕loss}{𝜕b} = \frac{𝜕loss}{𝜕\hat{y}}.\frac{𝜕\hat{y}}{𝜕b} = 2(\hat{y} - y).1$</li>
</ul>
</li>
</ul>
<h4>第五讲-PyTorch线性回归</h4>
<ul>
<li>PyTorch的四个步骤：准备数据、定义模型、定义损失函数和优化器、训练周期</li>
<li>训练周期的三个步骤：<ul>
<li>前馈forward：计算$\hat{y} \quad loss$</li>
<li>反馈backward：反向传播、计算梯度</li>
<li>更新update：更新参数</li>
</ul>
</li>
</ul>
<h4>第六讲-逻辑斯谛回归</h4>
<ul>
<li><a href="https://zhuanlan.zhihu.com/p/358223959">一篇文章搞懂logit, logistic和sigmoid的区别</a></li>
<li>逻辑斯谛回归(Logistic Regression)，简称LR</li>
<li>sigmoid函数是指某一类形如&quot;S&quot;的函数，例如<a href="../images/sigmoid-function.jpg">这些函数</a></li>
<li>logistic函数也是sigmoid函数，在PyTorch中sigmoid函数即是logistic函数</li>
<li>logistic回归虽然名为回归，但实际用于分类问题。</li>
<li>torch.nn.BCELoss是CrossEntropyLoss的一个特例，只用于二分类问题，而CrossEntropyLoss可以用于二分类，也可以用于多分类。</li>
<li>sigmoid函数的输入记为z，$z = 𝜔_0.x_0 + 𝜔_1.x_1 + ... + 𝜔_n.x_n$，z=0为决策边界，z&gt;0为真，z&lt;0为假<ul>
<li>上述公式的向量写法是$z = 𝜔^T.x$，梯度下降公式推导见<a href="https://blog.csdn.net/Mr_Robert/article/details/88888973">逻辑回归(LR)算法详解和实战</a></li>
<li>$loss = -y\log(\hat{y}) - (1 - y)\log(1 - \hat{y})$</li>
<li>$cost = -\frac{1}{N}\sum\limits_{n=1}^N y\log(\hat{y}) + (1 - y)\log(1 - \hat{y})$，从这里开始省略下标n</li>
<li>$\frac{𝜕cost}{𝜕𝜔} = \frac{𝜕cost}{𝜕\hat{y}}.\frac{𝜕\hat{y}}{𝜕𝜔}$，其中$\hat{y} = \frac{1}{1 + e^{-z}}$</li>
<li>$\frac{𝜕cost}{𝜕𝜔} = -\frac{1}{N}\sum\limits_{n=1}^N (\frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}}) . (\frac{𝜕\hat{y}}{𝜕z}.\frac{𝜕z}{𝜕𝜔})$，其中$\frac{𝜕\hat{y}}{𝜕z} = \hat{y} . (1 - \hat{y})$</li>
<li>$\frac{𝜕cost}{𝜕𝜔} = -\frac{1}{N}\sum\limits_{n=1}^N (\frac{y}{\hat{y}} - \frac{1-y}{1-\hat{y}}) . \hat{y} . (1 - \hat{y}) . x$</li>
<li>$\frac{𝜕cost}{𝜕𝜔} = -\frac{1}{N}\sum\limits_{n=1}^N (y - \hat{y}).x$</li>
<li>$\frac{𝜕cost}{𝜕𝜔} = \frac{1}{N}\sum\limits_{n=1}^N (\hat{y} - y).x$</li>
</ul>
</li>
<li>$z = 𝜔_0.x_0 + 𝜔_1.x_1 + 𝜔_2.x_2$，其中$x_0$恒为1<ul>
<li>代码liuer/lesson6.py：<a href="https://blog.csdn.net/qq_41750911/article/details/124889545">机器学习之逻辑回归Logistic Regression</a></li>
<li>代码liuer/lesson6_1.py：<a href="https://blog.csdn.net/qq_37055672/article/details/124779634">逻辑回归手动实现（logistic regression）</a></li>
</ul>
</li>
</ul>
<h4>第七讲-处理多维输入</h4>
<ul>
<li>线性模型：y = Ax。线性也就是直线，是一次方程。</li>
<li>torch.nn.Linear(8, 1)表示输入是8维，输出是1维，即A是1x8，x是8x1，y是1x1</li>
<li>torch.nn.Linear(8, 6)表示输入是8维，输出是6维，即A是6x8，x是8x1，y是6x1</li>
<li>非线性激活函数使得神经网络可以逼近任何非线性函数</li>
<li>非线性激活函数<a href="https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity">见</a>，其中有torch.nn.Sigmoid</li>
</ul>
<h4>第八讲-Dataset和DataLoader</h4>
<ul>
<li>Dataset是抽象类，需要用户编写具体类</li>
<li>DataLoader需要一个Dataset具体类，生成一个迭代对象</li>
</ul>
<h4>第九讲-多分类问题</h4>
<ul>
<li>关于把图片转成tensor格式，参考liuer/image2tensor.py</li>
<li>为什么要执行transforms.Normalize((0.1307,), (0.3081,))？<ul>
<li>因为ToTensor是把数据归一化到0,1区间，而Normalize是让数据成正态分布，<a href="https://zhuanlan.zhihu.com/p/476297637">加快模型的收敛速度</a></li>
<li>transforms.Normalize(mean, std)可以通过对输入进行torch.mean(x)和torch.std(x)得到</li>
</ul>
</li>
<li>模型精确度97%，训练过程：<ul>
<li>x：样本是(0,28,28)</li>
<li>x = x.view(-1, 784)：输出变成784</li>
<li>x = F.relu(self.l1(x))：输出变成512</li>
<li>x = F.relu(self.l2(x))：输出变成256</li>
<li>x = F.relu(self.l3(x))：输出变成128</li>
<li>x = F.relu(self.l4(x))：输出变成64</li>
<li>x = self.l5(x)：输出变成10</li>
</ul>
</li>
</ul>
<h4>第十讲-卷积神经网络-基础篇</h4>
<ul>
<li>CNN(Convolution Neural Network)：卷积神经网络</li>
<li><a href="https://blog.csdn.net/qq_39751352/article/details/124649762">卷积神经网络中的激活函数sigmoid、tanh、relu</a><ul>
<li>激活函数的目的：将神经网络非线性化，即提升神经网络的拟合能力，能拟合更复杂的函数。</li>
<li>如果模型只有线性操作，则永远只能表示超平面，无法表示曲面等</li>
</ul>
</li>
<li><a href="https://yey.world/2020/12/16/Pytorch-13/">网络层：池化层、全连接层和激活函数层</a>  </li>
<li>卷积神经网络除了输入和输出层之外还有四个基本的神经元层：<ul>
<li>卷积层（Convolution）：<a href="https://pytorch.apachecn.org/1.0/nn/#conv2d">torch.nn.Conv2d</a></li>
<li>池化层（Pooling）：<a href="https://pytorch.apachecn.org/1.0/nn/#maxpool2d">torch.nn.MaxPool2d</a></li>
<li>激活层（Activation）</li>
<li>完全连接层（Fully connected）：每个神经元与上一层所有神经元相连，如果不考虑激活函数的非线性性质，那么全连接层就是对输入数据进行一个线性组合</li>
</ul>
</li>
<li>模型精确度98%，训练过程：<ul>
<li>x：样本是(0,28,28)</li>
<li>x = F.relu(self.pooling(self.conv1(x)))：卷积后是(10,24,24)，池化后是(10,12,12)</li>
<li>x = F.relu(self.pooling(self.conv2(x)))：卷积后是(20,8,8)，池化后是(20,4,4)</li>
<li>x = x.view(x.size(0), -1)：输出变成320</li>
<li>x = self.fc(x)：输出变成10</li>
</ul>
</li>
</ul>
<h4>第十一讲-卷积神经网络-高级篇</h4>
<ul>
<li>nn.Conv2d(1, 16, kernel_size=1)，1x1卷积核的作用：融合了每个通道的信息</li>
<li>ResidualBlock层是把输入和输出相加，即z(x) = f(x) + x<ul>
<li>好处是不会存在梯度消失的问题，因为即使f&#39;(x)是0，z&#39;(x)是1</li>
</ul>
</li>
<li>模型精确度98%，训练过程：<ul>
<li>x：样本是(0,28,28)</li>
<li>x = F.relu(self.mp(self.conv1(x)))：卷积后是(10,24,24)，池化后是(10,12,12)</li>
<li>x = self.incep1(x)：(88,12,12)<ul>
<li>分支1，(16,12,12)</li>
<li>分支2，(24,12,12)</li>
<li>分支3，(24,12,12)</li>
<li>分支4，(24,12,12)</li>
</ul>
</li>
<li>x = F.relu(self.mp(self.conv2(x)))：卷积后是(20,8,8)，池化后是(20,4,4)</li>
<li>x = self.incep2(x)：(88,4,4)<ul>
<li>分支1，(16,4,4)</li>
<li>分支2，(24,4,4)</li>
<li>分支3，(24,4,4)</li>
<li>分支4，(24,4,4)</li>
</ul>
</li>
<li>x = x.view(x.size(0), -1)：输出变成1408</li>
<li>x = self.fc(x)：输出变成10</li>
</ul>
</li>
<li>模型精确度99%，训练过程：<ul>
<li>x：样本是(0,28,28)</li>
<li>x = F.relu(self.mp(self.conv1(x)))：卷积后是(16,24,24)，池化后是(16,12,12)</li>
<li>x = self.rblock1(x)：ResidualBlock的输入和输出的张量相同</li>
<li>x = self.mp(F.relu(self.conv2(x)))：卷积后是(32,8,8)，池化后是(32,4,4)</li>
<li>x = self.rblock2(x)：ResidualBlock的输入和输出的张量相同</li>
<li>x = x.view(in_size, -1)：输出变成512</li>
<li>x = self.fc(x)：输出变成10</li>
</ul>
</li>
</ul>
<h4>第十二讲-循环神经网络-基础篇</h4>
<ul>
<li>RNN(Recurrent Neural Network)：循环神经网络</li>
<li><a href="https://cuijiahua.com/blog/2018/12/dl-11.html">深度学习实战教程(五)：循环神经网络</a></li>
<li>基本循环神经网络：解决“我昨天上学迟到了，老师批评了<em>__</em>”，见<a href="../images/simple-rnn.jpg">结构图</a><ul>
<li>$o_t = g(V.s_t)$，g是激活函数。</li>
<li>$s_t = f(U.x_t + W.s_{t-1})$，U是x<sub>t</sub>的权重矩阵，W是s<sub>t-1</sub>的权重矩阵。</li>
</ul>
</li>
<li>双向循环神经网络：解决“我的手机坏了，我打算<em>__</em>一部新手机”，见<a href="../images/two-way-rnn.png">结构图</a><ul>
<li>$o_t = g(V.s_t + V&#39;.s_t&#39;)$</li>
<li>$s_t = f(U.x_t + W.s_{t-1})$</li>
<li>$s_t&#39; = f(U&#39;.x_t + W&#39;.s_{t+1}&#39;)$</li>
<li>正向计算和反向计算不共享权重，像U和U&#39;、W和W&#39;、V和V&#39;</li>
</ul>
</li>
<li>深度循环神经网络：更强大的表达与学习能力，但复杂性提高，需更多训练数据。见<a href="../images/deep-rnn.png">结构图</a><ul>
<li>假设第i个隐藏层的值分别是$s_t^{(i)} \quad s_t^{&#39;(i)}$</li>
<li>$o_t = g(V^{(i)}.s_t^{(i)} + V^{&#39;(i)}.s_t^{&#39;(i)})$</li>
<li>$s_t^{(i)} = f(U^{(i)}.x_t^{(i-1)} + W^{(i)}.s_{t-1}^{(i)})$</li>
<li>$s_t^{&#39;(i)} = f(U^{&#39;(i)}.x_t^{&#39;(i-1)} + W^{&#39;(i)}.s_{t+1}^{&#39;(i)})$</li>
</ul>
</li>
<li>RNN的梯度爆炸和消失问题<ul>
<li>梯度爆炸：程序会报NaN错误，解决办法是设置一个梯度阈值，梯度不能高于它</li>
<li>梯度消失：需要使用长短时记忆网络（LTSM）和Gated Recurrent Unit（GRU）</li>
</ul>
</li>
<li>循环神经网络激活函数用tanh用的多</li>
<li>torch.nn.Embedding的好处：<ul>
<li>对于样本（0, 1, 88），若使用one-hot编码，则需要3 * 89</li>
<li>而使用torch.nn.Embedding(89, 5)来编码，则需要3 * 5</li>
</ul>
</li>
</ul>
<h4>第十三讲-循环神经网络-高级篇</h4>
<ul>
<li><a href="https://www.heywhale.com/mw/project/646d7cb1946100f2ccb8cee9">循环神经网络 RNN、长短时记忆网络LSTM、门控循环单元GRU原理和应用详解</a></li>
<li>RNN的几种常见模式<ul>
<li>序列到类别模式：liuer/lesson13.py</li>
<li>同步的序列到序列模式：liuer/lesson13_2.py、liuer/lesson13_3.py</li>
<li>异步的序列到序列模式：<ul>
<li><a href="https://lifanchen-simm.github.io/2019/03/10/seq2seq/">德语到英语</a></li>
<li><a href="https://blog.csdn.net/qq_43941037/article/details/133958279">英语到法语</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/476849075">英语到法语</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="https://blog.csdn.net/jiuweideqixu/article/details/109492863">torch.nn.GRU的输入及输出示例</a><ul>
<li>batch_first=False时：<ul>
<li>input:&nbsp; (seq_len, batch, input_size)，也即embedding_dim</li>
<li>h_0:&nbsp;&nbsp;&nbsp; (num_layers * num_directions, batch, hidden_size)</li>
<li>output:(seq_len, batch, num_directions * hidden_size)</li>
<li>h_n:&nbsp;&nbsp;&nbsp; (num_layers * num_directions, batch, hidden_size)</li>
</ul>
</li>
<li>batch_first=True时：<ul>
<li>input:&nbsp; (batch, seq_len, input_size)</li>
<li>h_0:&nbsp;&nbsp;&nbsp; (batch, num_layers * num_directions, hidden_size)</li>
<li>output:(batch, seq_len, num_directions * hidden_size)</li>
<li>h_n:&nbsp;&nbsp;&nbsp; (batch, num_layers * num_directions, hidden_size)</li>
</ul>
</li>
<li>input_size一般等于hidden_size，也可以不同</li>
</ul>
</li>
</ul>
<h4>时间序列问题</h4>
<table>
<thead>
<tr>
<th>data</th>
<th>label</th>
<th>方案</th>
</tr>
</thead>
<tbody>
<tr>
<td>x1~xn</td>
<td>z</td>
<td>liuer/lesson13.py</td>
</tr>
<tr>
<td>x1</td>
<td>x2</td>
<td>liuer/lesson13_3.py</td>
</tr>
<tr>
<td>x1~xn<br/>y1~yn</td>
<td>z</td>
<td></td>
</tr>
<tr>
<td>x1,y1</td>
<td>x2,y2</td>
<td></td>
</tr>
<tr>
<td>x1,y1</td>
<td>z1</td>
<td></td>
</tr>
<tr>
<td>x1,y1,z1</td>
<td>z1</td>
<td>liuer/Myself-forecast.py</td>
</tr>
</tbody>
</table>
</script>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="highlights-of-calculus.html" class="navigation navigation-prev " aria-label="Previous page: 微积分重点">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="fft.html" class="navigation navigation-next " aria-label="Next page: 傅里叶变换">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"刘二大人","level":"1.4.3","depth":2,"next":{"title":"傅里叶变换","level":"1.4.4","depth":2,"path":"docs/fft.md","ref":"docs/fft.md","articles":[]},"previous":{"title":"微积分重点","level":"1.4.2","depth":2,"path":"docs/highlights-of-calculus.md","ref":"docs/highlights-of-calculus.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"docs/liu-er.md","mtime":"2023-12-08T03:10:42.575Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2023-12-08T03:11:07.029Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

