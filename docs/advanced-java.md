### Java工程师进阶知识

#### 参考资料
* [Java工程师进阶知识](https://doocs.gitee.io/advanced-java/#/README)

#### 消息队列
* 优点1：解耦，假设功能A完成一个操作后，需要通知BCD，需要考虑失败处理或者部分失败的情况，用MQ就方便多了
* 优点2：异步，提高接口的响应速度，慢操作可以异步去处理
* 优点3：消峰，在高峰时缓冲待处理操作，提高吞吐
* 缺点：多引用了MQ这个组件，多了一个故障点，系统复杂度增加
* kafka的高可用性：每个partition有多个replica副本，其中一个副本是leader
  * 写数据：只写leader，当所有的follower都同步了消息后，leader通知生产者写入成功
  * 消费：只读leader，当所有的follower都同步了消息后，这个消息才可见
* 重复消费问题：消费消息时要保证消息的幂等
* RabbitMQ如何不丢消息：
  * 生产者：开启异步confirm模式
  * MQ：开启镜像集群模式，消息持久化导磁盘
  * 消费者：关闭自动ack，使用手动ack
* MQ积压了几个小时怎么处理？
  * 停掉原有consumer程序，上新的consumer程序A把消息消费到新的10倍大小的MQ中
  * 上10倍的consumer程序B来消费新的MQ
  * 处理完挤压数据后，恢复原有的consumer程序

#### ElasticSearch
* es写入数据：
  * 1秒后可被搜索：因为数据定时一秒从buffer写入到segment file(即使在os cache也能被搜索)
  * 5秒后可持久化：日志实时从buffer写入到translog，定时5秒执行一次fsync
* 数十亿级别的数据量优化：
  * 机器的内存至少要能容纳数据量的一半
  * 垂直拆分：es只存储搜索字段，查出id后再去DB查询详细字段
  * 写脚本先把数据预热在cache
  * 冷热分离，冷热数据用不同的index
  * es的表设计：先join好数据了再写入es，减少es的查询复杂度
  * 分页性能优化：使用search_after参数

#### Redis缓存
* redis的过期策略：
  * 定期删除：每100ms随机检查10w个key
  * 惰性删除：请求key的时候判断是否过期
  * allkey-lru：所有key，最近最少使用
  * allkey-lfu：所有key，最近访问频次最少
  * allkey-random：所有key，随机删除
  * volatile-lru：在设置了过期时间的键空间中，最近最少使用
  * volatile-lfu：在设置了过期时间的键空间中，最近访问频次最少
  * volatile-random：在设置了过期时间的键空间中，随机删除
* redis的持久化
  * rdb：fork一个子线程备份，恢复速度快，但是备份大约要5分钟
  * aof：定时1秒执行fsync，最多丢失1秒数据，恢复速度慢
  * 混合持久化：定时rdb，rdb时间点之后用aof
* redis集群模式：
  * 哨兵+主从：3个哨兵，1主2从。主节点挂了，哨兵会选择一个新的主节点
  * cluster：3个主3个备，主节点挂了就换备节点。3个主同时提供读写服务，根据hash槽分配key
* 缓存穿透、缓存击穿、缓存雪崩
  * 缓存穿透：缓存不存在，请求落到db：设置空缓存
  * 缓存击穿：缓存失效的瞬间请求都落到db：用singleflight保证只有一个线程请求db
  * 缓存雪崩：缓存服务挂了，大量请求落到db：提高缓存服务的可用性，设置降级策略，缓存节点预热后加入集群  
  
#### Mysql相关
* 分库分表如何平滑过渡：
  * 所有写操作的地方进行双写：既可老库也写新库
  * 写导数据脚本把老数据导入新库，判断gmt_modified字段避免覆盖新数据
  * 检查新库和老库是否一致，一致后改双写为单写

#### 海量数据处理
* 两个各320G的文件存储大量URL，4G内存如何找出两者重复的url？
  * 方案1：A文件、B文件各对url哈希切成320个文件，依次对比A1B1...（把A1存哈希表，遍历B1的url去哈希表查找）
  * 方案2：把A文件的url存进前缀树，遍历B文件的url去前缀树查找
* 一个1G的文件存储大量单词，1M内存如何找到重复次数最多的单词Top100？
  * 对单词哈希切成1024个文件，保证每个文件小于1M
  * 依次对小文件进行统计，存储一个map结构的文件，key是单词，value是重复次数
  * 遍历这个map文件，使用一个小顶堆来统计Top100
* 在2.5亿个整数中找出不重复的整数
  * 使用位图法：假设整数取值范围在2^32，用2b来表示一个数的重复次数：00不存在，01出现一次，10出现多次
  * 计算需要2^32个2b内存，即1GB，若内存够则使用位图法，不够则用分治思路
* 1000w个字符串，最长255B，1G内存如何查出热门字符串Top10？
  * 使用前缀树，最后一个节点存储重复次数。最后用小顶堆来计算Top10
* 如何从5亿个数中找出中位数？
  * 方案1：用小顶堆存大于中位数的数，用大顶堆存小于中位数的数，5亿*4B≈2GB
  * 方案2：分治法，根据数的最高位分成两堆，中位数在总数多的那一堆，然后根据次高位分成两堆...
* 有10个1G文件存放用户的query，把它们按照query的频次排序
  * 方案1：内存足够先用map得到query队友的频次，再快排
  * 方案2：遍历这10个文件对query哈希到另10个文件中，再遍历这10个文件到10个map文件，再使用归并排序
* 有20个数组，每个数组有500个已排序元素，求Top500？
  * 初始化长度为500的数组
  * 从20个数组取最大数并排序，取最大值放入新数组
  * 取该最大值所在数组的下一个元素，继续上述操作

